<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-10T00:00:00Z">2024-09-10</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">61</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometric-Averaged Preference Optimization for Soft Preference Labels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hiroki Furuta, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many algorithms for aligning LLMs with human preferences assume that human
preferences are binary and deterministic. However, it is reasonable to think
that they can vary with different individuals, and thus should be
distributional to reflect the fine-grained relationship between the responses.
In this work, we introduce the distributional soft preference labels and
improve Direct Preference Optimization (DPO) with a weighted geometric average
of the LLM output likelihood in the loss function. In doing so, the scale of
learning loss is adjusted based on the soft labels, and the loss with equally
preferred responses would be close to zero. This simple modification can be
easily applied to any DPO family and helps the models escape from the
over-optimization and objective mismatch prior works suffer from. In our
experiments, we simulate the soft preference labels with AI feedback from LLMs
and demonstrate that geometric averaging consistently improves performance on
standard benchmarks for alignment research. In particular, we observe more
preferable responses than binary labels and significant improvements with data
where modestly-confident labels are in the majority.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ E2LLM: Encoder Elongated Large Language Models for Long-Context
  Understanding and Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06679v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06679v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihan Liao, Jun Wang, Hang Yu, Lingxiao Wei, Jianguo Li, Jun Wang, Wei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the realm of Large Language Models (LLMs), the ability to process long
contexts is increasingly crucial for tasks such as multi-round dialogues, code
generation, and document summarization. This paper addresses the challenges of
enhancing the long-context performance, reducing computational complexity, and
leveraging pretrained models collectively termed the "impossible triangle." We
introduce E2LLM (Encoder Elongated Large Language Models), a novel approach
that effectively navigates this paradox. The method involves splitting long
contexts into chunks, compressing each into embedding vectors via a pretrained
text encoder, and utilizing an adapter to align these representations with a
decoder-only LLM. Two training objectives, focusing on reconstruction of the
encoder output and long-context instruction fine-tuning, are employed to
facilitate the understanding of soft prompts by the LLM. Experimental results
demonstrate that E2LLM achieves superior performance in long-context scenarios
while balancing efficiency, performance, and compatibility with pretrained
models. Our framework thus represents a significant advancement in the field,
contributing to effective long-text modeling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLaMA-Omni: Seamless Speech Interaction with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, Yang Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models like GPT-4o enable real-time interaction with large language models
(LLMs) through speech, significantly enhancing user experience compared to
traditional text-based interaction. However, there is still a lack of
exploration on how to build speech interaction models based on open-source
LLMs. To address this, we propose LLaMA-Omni, a novel model architecture
designed for low-latency and high-quality speech interaction with LLMs.
LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,
and a streaming speech decoder. It eliminates the need for speech
transcription, and can simultaneously generate text and speech responses
directly from speech instructions with extremely low latency. We build our
model based on the latest Llama-3.1-8B-Instruct model. To align the model with
speech interaction scenarios, we construct a dataset named InstructS2S-200K,
which includes 200K speech instructions and corresponding speech responses.
Experimental results show that compared to previous speech-language models,
LLaMA-Omni provides better responses in both content and style, with a response
latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3
days on just 4 GPUs, paving the way for the efficient development of
speech-language models in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Project: https://github.com/ictnlp/LLaMA-Omni</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sortformer: Seamless Integration of Speaker Diarization and ASR by
  Bridging Timestamps and Tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06656v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06656v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taejin Park, Ivan Medennikov, Kunal Dhawan, Weiqing Wang, He Huang, Nithin Rao Koluguri, Krishna C. Puvvada, Jagadeesh Balam, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose Sortformer, a novel neural model for speaker diarization, trained
with unconventional objectives compared to existing end-to-end diarization
models. The permutation problem in speaker diarization has long been regarded
as a critical challenge. Most prior end-to-end diarization systems employ
permutation invariant loss (PIL), which optimizes for the permutation that
yields the lowest error. In contrast, we introduce Sort Loss, which enables a
diarization model to autonomously resolve permutation, with or without PIL. We
demonstrate that combining Sort Loss and PIL achieves performance competitive
with state-of-the-art end-to-end diarization models trained exclusively with
PIL. Crucially, we present a streamlined multispeaker ASR architecture that
leverages Sortformer as a speaker supervision model, embedding speaker label
estimation within the ASR encoder state using a sinusoidal kernel function.
This approach resolves the speaker permutation problem through sorted
objectives, effectively bridging speaker-label timestamps and speaker tokens.
In our experiments, we show that the proposed multispeaker ASR architecture,
enhanced with speaker supervision, improves performance via adapter techniques.
Code and trained models will be made publicly available via the NVIDIA NeMo
framework
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TeXBLEU: Automatic Metric for Evaluate LaTeX Format 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kyudan Jung, Nam-Joon Kim, Hyongon Ryu, Sieun Hyeon, Seung-jun Lee, Hyeok-jae Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LaTeX is highly suited to creating documents with special formatting,
particularly in the fields of science, technology, mathematics, and computer
science. Despite the increasing use of mathematical expressions in LaTeX format
with language models, there are no evaluation metrics for evaluating them. In
this study, we propose TeXBLEU, an evaluation metric tailored for mathematical
expressions in LaTeX format, based on the n-gram-based BLEU metric that is
widely used for translation tasks. The proposed TeXBLEU includes a predefined
tokenizer trained on the arXiv paper dataset and a finetuned embedding model.
It also considers the positional embedding of tokens. Simultaneously, TeXBLEU
compares tokens based on n-grams and computes the score using exponentiation of
a logarithmic sum, similar to the original BLEU. Experimental results show that
TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER,
and WER when compared to human evaluation data on the test dataset of the
MathBridge dataset, which contains 1,000 data points. The average correlation
coefficient with human evaluation was 0.71, which is an improvement of 87%
compared with BLEU, which had the highest correlation with human evaluation
data among the existing metrics. The code is available at
https://github.com/KyuDan1/TeXBLEU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancements in large language models (LLMs) have significantly
enhanced natural language processing capabilities, facilitating the development
of AudioLLMs that process and understand speech and audio inputs alongside
text. Existing AudioLLMs typically combine a pre-trained audio encoder with a
pre-trained LLM, which are subsequently finetuned on specific audio tasks.
However, the pre-trained audio encoder has constrained capacity to capture
features for new tasks and datasets. To address this, we propose to incorporate
mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE
supplements a base encoder with a pool of relatively light weight encoders,
selectively activated based on the audio input to enhance feature extraction
without significantly increasing model size. Our empirical results demonstrate
that MoWE effectively improves multi-task performance, broadening the
applicability of AudioLLMs to more diverse audio tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Practice of Post-Training on Llama-3 70B with Optimal Selection of
  Additional Language Mixture Ratio 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06624v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06624v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ningyuan Xi, Yetao Wu, Kun Fan, Teng Chen, Qingqing Gu, Peng Yu, Jinxian Qu, Chenxi Liu, Zhonglin Jiang, Yong Chen, Luo Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to
obtain the unfamiliar language skill or adapt into new domains. The huge
training cost of CPT often asks for cautious choice of key hyper-parameters
such as the mixture ratio of extra language or domain corpus. However, there is
no systematic study which bridge the gap between the optimal mixture ratio and
the actual model performance, and the gap between experimental scaling law and
the actual deployment in the full model size. In this paper, we perform CPT on
Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal
correlation between the Additional Language Mixture Ratio (ALMR) and the
Learning Rate (LR) on the 8B size which directly indicate the optimal
experimental set up. By thorough choice of hyper-parameter, and subsequent
fine-tuning, the model capability is improved not only on the Chinese-related
benchmark, but also some specific domains including math, coding and emotional
intelligence. We deploy the final 70B version of LLM on an real-life chat
system which obtain satisfying performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Italian sentence embeddings properties through multi-tasking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vivi Nastase, Giuseppe Samo, Chunyang Jiang, Paola Merlo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate to what degree existing LLMs encode abstract linguistic
information in Italian in a multi-task setting. We exploit curated synthetic
data on a large scale -- several Blackbird Language Matrices (BLMs) problems in
Italian -- and use them to study how sentence representations built using
pre-trained language models encode specific syntactic and semantic information.
We use a two-level architecture to model separately a compression of the
sentence embeddings into a representation that contains relevant information
for a task, and a BLM task. We then investigate whether we can obtain
compressed sentence representations that encode syntactic and semantic
information relevant to several BLM tasks. While we expected that the sentence
structure -- in terms of sequence of phrases/chunks -- and chunk properties
could be shared across tasks, performance and error analysis show that the
clues for the different tasks are encoded in different manners in the sentence
embeddings, suggesting that abstract linguistic notions such as constituents or
thematic roles does not seem to be present in the pretrained sentence
embeddings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 9 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Alleviating Hallucinations in Large Language Models with Scepticism
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yetao Wu, Yihong Wang, Teng Chen, Chenxi Liu, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Zhonglin Jiang, Yong Chen, Luo Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucinations is a major challenge for large language models (LLMs),
prevents adoption in diverse fields. Uncertainty estimation could be used for
alleviating the damages of hallucinations. The skeptical emotion of human could
be useful for enhancing the ability of self estimation. Inspirited by this
observation, we proposed a new approach called Skepticism Modeling (SM). This
approach is formalized by combining the information of token and logits for
self estimation. We construct the doubt emotion aware data, perform continual
pre-training, and then fine-tune the LLMs, improve their ability of self
estimation. Experimental results demonstrate this new approach effectively
enhances a model's ability to estimate their uncertainty, and validate its
generalization ability of other tasks by out-of-domain experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question
  Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06595v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06595v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sacha Muller, António Loison, Bilel Omrani, Gautier Viaud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use
Large Language Models (LLMs) alongside private and up-to-date knowledge bases.
In this work, we address the challenges of using LLM-as-a-Judge when evaluating
grounded answers generated by RAG systems. To assess the calibration and
discrimination capabilities of judge models, we identify 7 generator failure
modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a
meta-evaluation benchmark of 144 unit tests. This benchmark reveals that
existing automated RAG evaluation frameworks often overlook important failure
modes, even when using GPT-4 as a judge.
  To improve on the current design of automated RAG evaluation frameworks, we
propose a novel pipeline and find that while closed models perform well on
GroUSE, state-of-the-art open-source judges do not generalize to our proposed
criteria, despite strong correlation with GPT-4's judgement. Our findings
suggest that correlation with GPT-4 is an incomplete proxy for the practical
performance of judge models and should be supplemented with evaluations on unit
tests for precise failure mode detection.
  We further show that finetuning Llama-3 on GPT-4's reasoning traces
significantly boosts its evaluation capabilities, improving upon both
correlation with GPT-4's evaluations and calibration on reference situations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring syntactic information in sentence embeddings through
  multilingual subject-verb agreement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vivi Nastase, Chunyang Jiang, Giuseppe Samo, Paola Merlo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, our goal is to investigate to what degree multilingual
pretrained language models capture cross-linguistically valid abstract
linguistic representations. We take the approach of developing curated
synthetic data on a large scale, with specific properties, and using them to
study sentence representations built using pretrained language models. We use a
new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to
focus on a specific grammatical structural phenomenon -- subject-verb agreement
across a variety of sentence structures -- in several languages. Finding a
solution to this task requires a system detecting complex linguistic patterns
and paradigms in text representations. Using a two-level architecture that
solves the problem in two steps -- detect syntactic objects and their
properties in individual sentences, and find patterns across an input sequence
of sentences -- we show that despite having been trained on multilingual texts
in a consistent manner, multilingual pretrained language models have
language-specific differences, and syntactic structure is not shared, even
across closely related languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 tables, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From LIMA to DeepLIMA: following a new path of interoperability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06550v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06550v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Victor Bocharov, Romaric Besançon, Gaël de Chalendar, Olivier Ferret, Nasredine Semmar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this article, we describe the architecture of the LIMA (Libre Multilingual
Analyzer) framework and its recent evolution with the addition of new text
analysis modules based on deep neural networks. We extended the functionality
of LIMA in terms of the number of supported languages while preserving existing
configurable architecture and the availability of previously developed
rule-based and statistical analysis components. Models were trained for more
than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora,
and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number
of supported languages and to generate models that could be integrated into
other platforms. This integration of ubiquitous Deep Learning Natural Language
Processing models and the use of standard annotated collections using Universal
Dependencies can be viewed as a new path of interoperability, through the
normalization of models and data, that are complementary to a more standard
technical interoperability, implemented in LIMA through services available in
Docker containers on Docker Hub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 5 figures, submitted to Language Resources and Evaluation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mapping News Narratives Using LLMs and Narrative-Structured Text
  Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jan Elfes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given the profound impact of narratives across various societal levels, from
personal identities to international politics, it is crucial to understand
their distribution and development over time. This is particularly important in
online spaces. On the Web, narratives can spread rapidly and intensify societal
divides and conflicts. While many qualitative approaches exist, quantifying
narratives remains a significant challenge. Computational narrative analysis
lacks frameworks that are both comprehensive and generalizable. To address this
gap, we introduce a numerical narrative representation grounded in
structuralist linguistic theory. Chiefly, Greimas' Actantial Model represents a
narrative through a constellation of six functional character roles. These
so-called actants are genre-agnostic, making the model highly generalizable. We
extract the actants using an open-source LLM and integrate them into a
Narrative-Structured Text Embedding that captures both the semantics and
narrative structure of a text. We demonstrate the analytical insights of the
method on the example of 5000 full-text news articles from Al Jazeera and The
Washington Post on the Israel-Palestine conflict. Our method successfully
distinguishes articles that cover the same topics but differ in narrative
structure.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 13 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Questioning Internal Knowledge Structure of Large Language Models
  Through the Lens of the Olympic Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06518v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06518v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juhwan Choi, YoungBin Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have become a dominant approach in natural
language processing, yet their internal knowledge structures remain largely
unexplored. In this paper, we analyze the internal knowledge structures of LLMs
using historical medal tallies from the Olympic Games. We task the models with
providing the medal counts for each team and identifying which teams achieved
specific rankings. Our results reveal that while state-of-the-art LLMs perform
remarkably well in reporting medal counts for individual teams, they struggle
significantly with questions about specific rankings. This suggests that the
internal knowledge structures of LLMs are fundamentally different from those of
humans, who can easily infer rankings from known medal counts. To support
further research, we publicly release our code, dataset, and model outputs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06468v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06468v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi-Cheng Wang, Li-Ting Pai, Bi-Cheng Yan, Hsin-Wei Wang, Chi-Han Lin, Berlin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end (E2E) automatic speech recognition (ASR) models have become
standard practice for various commercial applications. However, in real-world
scenarios, the long-tailed nature of word distribution often leads E2E ASR
models to perform well on common words but fall short in recognizing uncommon
ones. Recently, the notion of a contextual adapter (CA) was proposed to infuse
external knowledge represented by a context word list into E2E ASR models.
Although CA can improve recognition performance on rare words, two crucial data
imbalance problems remain. First, when using low-frequency words as context
words during training, since these words rarely occur in the utterance, CA
becomes prone to overfit on attending to the <no-context> token due to
higher-frequency words not being present in the context list. Second, the
long-tailed distribution within the context list itself still causes the model
to perform poorly on low-frequency context words. In light of this, we explore
in-depth the impact of altering the context list to have words with different
frequency distributions on model performance, and meanwhile extend CA with a
simple yet effective context-balanced learning objective. A series of
experiments conducted on the AISHELL-1 benchmark dataset suggests that using
all vocabulary words from the training corpus as the context list and pairing
them with our balanced objective yields the best performance, demonstrating a
significant reduction in character error rate (CER) by up to 1.21% and a more
pronounced 9.44% reduction in the error rate of zero-shot words.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06446v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06446v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hossein Hajipour, Lea Schönherr, Thorsten Holz, Mario Fritz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown great potential for automatic code
generation and form the basis for various tools such as GitHub Copilot.
However, recent studies highlight that many LLM-generated code contains serious
security vulnerabilities. While previous work tries to address this by training
models that generate secure code, these attempts remain constrained by limited
access to training data and labor-intensive data preparation.
  In this paper, we introduce HexaCoder, a novel approach to enhance the
ability of LLMs to generate secure codes by automatically synthesizing secure
codes, which reduces the effort of finding suitable training data. HexaCoder
comprises two key components: an oracle-guided data synthesis pipeline and a
two-step process for secure code generation. The data synthesis pipeline
generates pairs of vulnerable and fixed codes for specific Common Weakness
Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing
vulnerable code. A security oracle identifies vulnerabilities, and a
state-of-the-art LLM repairs them by extending and/or editing the codes,
creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA)
method. Each example of our fine-tuning dataset includes the necessary
security-related libraries and code that form the basis of our novel two-step
generation approach. This allows the model to integrate security-relevant
libraries before generating the main code, significantly reducing the number of
generated vulnerable codes by up to 85% compared to the baseline methods. We
perform extensive evaluations on three different benchmarks for four LLMs,
demonstrating that HexaCoder not only improves the security of the generated
code but also maintains a high level of functional correctness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 16 tables, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Length Desensitization in Directed Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Liu, Yang Bai, Chengcheng Han, Rongxiang Weng, Jun Xu, Xuezhi Cao, Jingang Wang, Xunliang Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) is widely utilized in the Reinforcement
Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs)
with human preferences, thereby enhancing both their harmlessness and efficacy.
However, it has been observed that DPO tends to over-optimize for verbosity,
which can detrimentally affect both performance and user experience. In this
paper, we conduct an in-depth theoretical analysis of DPO's optimization
objective and reveal a strong correlation between its implicit reward and data
length. This correlation misguides the optimization direction, resulting in
length sensitivity during the DPO training and leading to verbosity. To address
this issue, we propose a length-desensitization improvement method for DPO,
termed LD-DPO. The proposed method aims to desensitize DPO to data length by
decoupling explicit length preference, which is relatively insignificant, from
the other implicit preferences, thereby enabling more effective learning of the
intrinsic preferences. We utilized two settings (Base and Instruct) of
Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various
benchmarks including MT-Bench and AlpacaEval 2. The experimental results
indicate that LD-DPO consistently outperforms DPO and other baseline methods,
achieving more concise responses with a 10-40\% reduction in length compared to
DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can
indeed achieve length desensitization and align the model more closely with
human-real preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coarse-Grained Sense Inventories Based on Semantic Matching between
  English Dictionaries 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06386v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06386v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masato Kikuchi, Masatsugu Ono, Toshioki Soga, Tetsu Tanabe, Tadachika Ozono
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  WordNet is one of the largest handcrafted concept dictionaries visualizing
word connections through semantic relationships. It is widely used as a word
sense inventory in natural language processing tasks. However, WordNet's
fine-grained senses have been criticized for limiting its usability. In this
paper, we semantically match sense definitions from Cambridge dictionaries and
WordNet and develop new coarse-grained sense inventories. We verify the
effectiveness of our inventories by comparing their semantic coherences with
that of Coarse Sense Inventory. The advantages of the proposed inventories
include their low dependency on large-scale resources, better aggregation of
closely related senses, CEFR-level assignments, and ease of expansion and
improvement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 11th International Conference on Advanced Informatics: Concepts,
  Theory and Applications (ICAICTA 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Sequential Recommendations through Multi-Perspective
  Reflections and Iteration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06377v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06377v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Xiao Zhang, Ming He, Jianping Fan, Jun Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequence recommendation (SeqRec) aims to predict the next item a user will
interact with by understanding user intentions and leveraging collaborative
filtering information. Large language models (LLMs) have shown great promise in
recommendation tasks through prompt-based, fixed reflection libraries, and
fine-tuning techniques. However, these methods face challenges, including lack
of supervision, inability to optimize reflection sources, inflexibility to
diverse user needs, and high computational costs. Despite promising results,
current studies primarily focus on reflections of users' explicit preferences
(e.g., item titles) while neglecting implicit preferences (e.g., brands) and
collaborative filtering information. This oversight hinders the capture of
preference shifts and dynamic user behaviors. Additionally, existing approaches
lack mechanisms for reflection evaluation and iteration, often leading to
suboptimal recommendations. To address these issues, we propose the Mixture of
REflectors (MoRE) framework, designed to model and learn dynamic user
preferences in SeqRec. Specifically, MoRE introduces three reflectors for
generating LLM-based reflections on explicit preferences, implicit preferences,
and collaborative signals. Each reflector incorporates a self-improving
strategy, termed refining-and-iteration, to evaluate and iteratively update
reflections. Furthermore, a meta-reflector employs a contextual bandit
algorithm to select the most suitable expert and corresponding reflections for
each user's recommendation, effectively capturing dynamic preferences.
Extensive experiments on three real-world datasets demonstrate that MoRE
consistently outperforms state-of-the-art methods, requiring less training time
and GPU memory compared to other LLM-based approaches in SeqRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First 3 authors contributes equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpeechTaxi: On Multilingual Semantic Speech Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06372v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06372v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lennart Keller, Goran Glavaš
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in multilingual speech encoding as well as transcription
raise the question of the most effective approach to semantic speech
classification. Concretely, can (1) end-to-end (E2E) classifiers obtained by
fine-tuning state-of-the-art multilingual speech encoders (MSEs) match or
surpass the performance of (2) cascading (CA), where speech is first
transcribed into text and classification is delegated to a text-based
classifier. To answer this, we first construct SpeechTaxi, an 80-hour
multilingual dataset for semantic speech classification of Bible verses,
covering 28 diverse languages. We then leverage SpeechTaxi to conduct a wide
range of experiments comparing E2E and CA in monolingual semantic speech
classification as well as in cross-lingual transfer. We find that E2E based on
MSEs outperforms CA in monolingual setups, i.e., when trained on in-language
data. However, MSEs seem to have poor cross-lingual transfer abilities, with
E2E substantially lagging CA both in (1) zero-shot transfer to languages unseen
in training and (2) multilingual training, i.e., joint training on multiple
languages. Finally, we devise a novel CA approach based on transcription to
Romanized text as a language-agnostic intermediate representation and show that
it represents a robust solution for languages without native ASR support. Our
SpeechTaxi dataset is publicly available at: https://huggingface.co/
datasets/LennartKeller/SpeechTaxi/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Retrieval Or Holistic Understanding? Dolce: Differentiate Our Long
  Context Evaluation Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06338v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06338v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We argue that there are two major distinct capabilities in long context
understanding: retrieval and holistic understanding. Understanding and further
improving LLMs' long context capabilities would not be possible without knowing
the tasks' focus categories. We aim to automatically identify retrieval focused
and holistic understanding focused problems from suites of benchmarks and
quantitatively measure the difficulty within each focus. In this paper, we
present the Dolce framework, which parameterizes each problem by $\lambda$
(complexity) and $k$ (redundancy) and assigns to one of five predefined focus
categories. We propose to sample short contexts from the full context and
estimate the probability an LLM solves the problem using the sampled spans. To
find the $\lambda$ and $k$ for each problem, we further propose a mixture model
of a non-parametric background noise component and a parametric/non-parametric
hybrid oracle component, where we derive the probability functions
parameterized by $\lambda$ and $k$ for both the correct-or-wrong (COW) scenario
and the partial-point-in-grading (PIG) scenario. Our proposed methods can
identify 0% to 67% of the problems are retrieval focused and 0% to 90% of the
problems are holistic understanding focused across 44 existing long context
evaluation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extracting Paragraphs from LLM Token Activations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06328v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06328v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicholas Pochinkov, Angelo Benoit, Lovkush Agarwal, Zainab Ali Majid, Lucile Ter-Minassian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative large language models (LLMs) excel in natural language processing
tasks, yet their inner workings remain underexplored beyond token-level
predictions. This study investigates the degree to which these models decide
the content of a paragraph at its onset, shedding light on their contextual
understanding. By examining the information encoded in single-token
activations, specifically the "\textbackslash n\textbackslash n" double newline
token, we demonstrate that patching these activations can transfer significant
information about the context of the following paragraph, providing further
insights into the model's capacity to plan ahead.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06263v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06263v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihyun Lee, Solee Im, Wonjun Lee, Gary Geunbae Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dialogue State Tracking (DST) is a key part of task-oriented dialogue
systems, identifying important information in conversations. However, its
accuracy drops significantly in spoken dialogue environments due to named
entity errors from Automatic Speech Recognition (ASR) systems. We introduce a
simple yet effective data augmentation method that targets those entities to
improve the robustness of DST model. Our novel method can control the placement
of errors using keyword-highlighted prompts while introducing phonetically
similar errors. As a result, our method generated sufficient error patterns on
keywords, leading to improved accuracy in noised and low-accuracy ASR
environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Inference is All You Need: Self Example Retriever for Cross-domain
  Dialogue State Tracking with Chat<span class="highlight-title">GPT</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06243v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06243v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihyun Lee, Gary Geunbae Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional dialogue state tracking approaches heavily rely on extensive
training data and handcrafted features, limiting their scalability and
adaptability to new domains. In this paper, we propose a novel method that
leverages inference and in-context learning with ChatGPT for domain transfer in
dialogue state tracking, without any parameter updates. By guiding ChatGPT's
chain of thought, we enable it to retrieve relevant examples and generalize
knowledge to accurately infer dialogue states, solely through inference.
Experimental results on the MultiWOZ dataset demonstrate competitive
performance and promising generalization across domains. Our parameter-free
approach offers a scalable and adaptable solution, opening new research
directions in domain transfer learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NLP-Powered Repository and Search Engine for Academic Papers: A Case
  Study on Cyber Risk Literature with CyLit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06226v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06226v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linfeng Zhang, Changyue Hu, Zhiyu Quan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the body of academic literature continues to grow, researchers face
increasing difficulties in effectively searching for relevant resources.
Existing databases and search engines often fall short of providing a
comprehensive and contextually relevant collection of academic literature. To
address this issue, we propose a novel framework that leverages Natural
Language Processing (NLP) techniques. This framework automates the retrieval,
summarization, and clustering of academic literature within a specific research
domain. To demonstrate the effectiveness of our approach, we introduce CyLit,
an NLP-powered repository specifically designed for the cyber risk literature.
CyLit empowers researchers by providing access to context-specific resources
and enabling the tracking of trends in the dynamic and rapidly evolving field
of cyber risk. Through the automatic processing of large volumes of data, our
NLP-powered solution significantly enhances the efficiency and specificity of
academic literature searches. We compare the literature categorization results
of CyLit to those presented in survey papers or generated by ChatGPT,
highlighting the distinctive insights this tool provides into cyber risk
research literature. Using NLP techniques, we aim to revolutionize the way
researchers discover, analyze, and utilize academic resources, ultimately
fostering advancements in various domains of knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Temporal Understanding in Audio Question Answering for Large
  Audio Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06223v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06223v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arvind Krishna Sridhar, Yinyi Guo, Erik Visser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Audio Question Answering task includes audio event classification, audio
captioning, and open ended reasoning. Recently, Audio Question Answering has
garnered attention due to the advent of Large Audio Language Models. Current
literature focuses on constructing LALMs by integrating audio encoders with
text only Large Language Models through a projection module. While Large Audio
Language Models excel in general audio understanding, they are limited in
temporal reasoning which may hinder their commercial applications and on device
deployment. This paper addresses these challenges and limitations in audio
temporal reasoning. First, we introduce a data augmentation technique for
generating reliable audio temporal questions and answers using an LLM. Second,
we propose a continued finetuning curriculum learning strategy to specialize in
temporal reasoning without compromising performance on finetuned tasks.
Finally, we develop a reliable and transparent automated metric, assisted by an
LLM, to measure the correlation between Large Audio Language Model responses
and ground truth data intelligently. We demonstrate the effectiveness of our
proposed techniques using SOTA LALMs on public audio benchmark datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Topic Segmentation of Broadcasted Speech with Multilingual
  Semantic Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sakshi Deo Shukla, Pavel Denisov, Tugtekin Turan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in speech-based topic segmentation have highlighted the
potential of pretrained speech encoders to capture semantic representations
directly from speech. Traditionally, topic segmentation has relied on a
pipeline approach in which transcripts of the automatic speech recognition
systems are generated, followed by text-based segmentation algorithms. In this
paper, we introduce an end-to-end scheme that bypasses this conventional
two-step process by directly employing semantic speech encoders for
segmentation. Focused on the broadcasted news domain, which poses unique
challenges due to the diversity of speakers and topics within single
recordings, we address the challenge of accessing topic change points
efficiently in an end-to-end manner. Furthermore, we propose a new benchmark
for spoken news topic segmentation by utilizing a dataset featuring
approximately 1000 hours of publicly available recordings across six European
languages and including an evaluation set in Hindi to test the model's
cross-domain performance in a cross-lingual, zero-shot scenario. This setup
reflects real-world diversity and the need for models adapting to various
linguistic settings. Our results demonstrate that while the traditional
pipeline approach achieves a state-of-the-art $P_k$ score of 0.2431 for
English, our end-to-end model delivers a competitive $P_k$ score of 0.2564.
When trained multilingually, these scores further improve to 0.1988 and 0.2370,
respectively. To support further research, we release our model along with data
preparation scripts, facilitating open research on multilingual spoken news
topic segmentation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SubRegWeigh: Effective and Efficient Annotation Weighing with Subword
  Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06216v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06216v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kohei Tsuji, Tatsuya Hiraoka, Yuchang Cheng, Tomoya Iwakura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many datasets of natural language processing (NLP) sometimes include
annotation errors. Researchers have attempted to develop methods to reduce the
adverse effect of errors in datasets automatically. However, an existing method
is time-consuming because it requires many trained models to detect errors. We
propose a novel method to reduce the time of error detection. Specifically, we
use a tokenization technique called subword regularization to create
pseudo-multiple models which are used to detect errors. Our proposed method,
SubRegWeigh, can perform annotation weighting four to five times faster than
the existing method. Additionally, SubRegWeigh improved performance in both
document classification and named entity recognition tasks. In experiments with
pseudo-incorrect labels, pseudo-incorrect labels were adequately detected.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 1 figures, 10 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06211v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06211v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaeseong Lee, seung-won hwang, Aurick Qiao, Daniel F Campos, Zhewei Yao, Yuxiong He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-experts (MoEs) have been adopted for reducing inference costs by
sparsely activating experts in Large language models (LLMs). Despite this
reduction, the massive number of experts in MoEs still makes them expensive to
serve. In this paper, we study how to address this, by pruning MoEs. Among
pruning methodologies, unstructured pruning has been known to achieve the
highest performance for a given pruning ratio, compared to structured pruning,
since the latter imposes constraints on the sparsification structure. This is
intuitive, as the solution space of unstructured pruning subsumes that of
structured pruning. However, our counterintuitive finding reveals that expert
pruning, a form of structured pruning, can actually precede unstructured
pruning to outperform unstructured-only pruning. As existing expert pruning,
requiring $O(\frac{k^n}{\sqrt{n}})$ forward passes for $n$ experts, cannot
scale for recent MoEs, we propose a scalable alternative with $O(1)$
complexity, yet outperforming the more expensive methods. The key idea is
leveraging a latent structure between experts, based on behavior similarity,
such that the greedy decision of whether to prune closely captures the joint
pruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized
MoE with 128 experts, our method needs only one H100 and two hours to achieve
nearly no loss in performance with 40% sparsity, even in generative tasks such
as GSM8K, where state-of-the-art unstructured pruning fails to. The code will
be made publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing
  Behaviors with LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanli Qian, Chenfeng Gao, Anup Sathya, Ryo Suzuki, Ken Nakagaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces text-to-shape-display, a novel approach to generating
dynamic shape changes in pin-based shape displays through natural language
commands. By leveraging large language models (LLMs) and AI-chaining, our
approach allows users to author shape-changing behaviors on demand through text
prompts without programming. We describe the foundational aspects necessary for
such a system, including the identification of key generative elements
(primitive, animation, and interaction) and design requirements to enhance user
interaction, based on formative exploration and iterative design processes.
Based on these insights, we develop SHAPE-IT, an LLM-based authoring tool for a
24 x 24 shape display, which translates the user's textual command into
executable code and allows for quick exploration through a web-based control
interface. We evaluate the effectiveness of SHAPE-IT in two ways: 1)
performance evaluation and 2) user evaluation (N= 10). The study conclusions
highlight the ability to facilitate rapid ideation of a wide range of
shape-changing behaviors with AI. However, the findings also expose
accuracy-related challenges and limitations, prompting further exploration into
refining the framework for leveraging AI to better suit the unique requirements
of shape-changing systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for ACM UIST 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NOVI : Chatbot System for University Novice with <span class="highlight-title">BERT</span> and LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06192v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06192v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yoonji Nam, TaeWoong Seo, Gyeongcheol Shin, Sangji Lee, JaeEun Im
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To mitigate the difficulties of university freshmen in adapting to university
life, we developed NOVI, a chatbot system based on GPT-4o. This system utilizes
post and comment data from SKKU 'Everytime', a university community site.
Developed using LangChain, NOVI's performance has been evaluated with a BLEU
score, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR
score. This approach is not only limited to help university freshmen but is
also expected to help various people adapting to new environments with
different data. This research explores the development and potential
application of new educational technology tools, contributing to easier social
adaptation for beginners and settling a foundation for future advancement in
LLM studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Large Language Models Unlock Novel Scientific Research Ideas? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06185v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06185v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  "An idea is nothing more nor less than a new combination of old elements"
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 12 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SQLucid: Grounding Natural Language Database Queries with Interactive
  Explanations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06178v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06178v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Tian, Jonathan K. Kummerfeld, Toby Jia-Jun Li, Tianyi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Though recent advances in machine learning have led to significant
improvements in natural language interfaces for databases, the accuracy and
reliability of these systems remain limited, especially in high-stakes domains.
This paper introduces SQLucid, a novel user interface that bridges the gap
between non-expert users and complex database querying processes. SQLucid
addresses existing limitations by integrating visual correspondence,
intermediate query results, and editable step-by-step SQL explanations in
natural language to facilitate user understanding and engagement. This unique
blend of features empowers users to understand and refine SQL queries easily
and precisely. Two user studies and one quantitative experiment were conducted
to validate SQLucid's effectiveness, showing significant improvement in task
completion accuracy and user confidence compared to existing interfaces. Our
code is available at https://github.com/magic-YuanTian/SQLucid.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to UIST'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Larger Language Models Don't Care How You Think: Why Chain-of-Thought
  <span class="highlight-title">Prompt</span>ing Fails in Subjective Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06173v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06173v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgios Chochlakis, Niyantha Maruthu Pandiyan, Kristina Lerman, Shrikanth Narayanan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the
dominant technique for performing natural language tasks, as it does not
require updating the model parameters with gradient-based methods. ICL promises
to "adapt" the LLM to perform the present task at a competitive or
state-of-the-art level at a fraction of the computational cost. ICL can be
augmented by incorporating the reasoning process to arrive at the final label
explicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.
However, recent work has found that ICL relies mostly on the retrieval of task
priors and less so on "learning" to perform tasks, especially for complex
subjective domains like emotion and morality, where priors ossify posterior
predictions. In this work, we examine whether "enabling" reasoning also creates
the same behavior in LLMs, wherein the format of CoT retrieves reasoning priors
that remain relatively unchanged despite the evidence in the prompt. We find
that, surprisingly, CoT indeed suffers from the same posterior collapse as ICL
for larger language models. Code is avalaible at
https://github.com/gchochla/cot-priors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning and Large Language Models for Audio and Text Analysis in
  Predicting Suicidal Acts in Chinese Psychological Support Hotlines 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06164v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06164v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yining Chen, Jianqiang Li, Changwei Song, Qing Zhao, Yongsheng Tong, Guanghui Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Suicide is a pressing global issue, demanding urgent and effective preventive
interventions. Among the various strategies in place, psychological support
hotlines had proved as a potent intervention method. Approximately two million
people in China attempt suicide annually, with many individuals making multiple
attempts. Prompt identification and intervention for high-risk individuals are
crucial to preventing tragedies. With the rapid advancement of artificial
intelligence (AI), especially the development of large-scale language models
(LLMs), new technological tools have been introduced to the field of mental
health. This study included 1284 subjects, and was designed to validate whether
deep learning models and LLMs, using audio and transcribed text from support
hotlines, can effectively predict suicide risk. We proposed a simple LLM-based
pipeline that first summarizes transcribed text from approximately one hour of
speech to extract key features, and then predict suicidial bahaviours in the
future. We compared our LLM-based method with the traditional manual scale
approach in a clinical setting and with five advanced deep learning models.
Surprisingly, the proposed simple LLM pipeline achieved strong performance on a
test set of 46 subjects, with an F1 score of 76\% when combined with manual
scale rating. This is 7\% higher than the best speech-based deep learning
models and represents a 27.82\% point improvement in F1 score compared to using
the manual scale apporach alone. Our study explores new applications of LLMs
and demonstrates their potential for future use in suicide prevention efforts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Accelerating Large Language Model <span class="highlight-title">Pretrain</span>ing via LFR Pedagogy: Learn,
  Focus, and <span class="highlight-title">Review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06131v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06131v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neha Prakriya, Jui-Nan Yen, Cho-Jui Hsieh, Jason Cong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM) pretraining traditionally relies on autoregressive
language modeling on randomly sampled data blocks from web-scale datasets. We
take inspiration from human learning techniques like spaced repetition to
hypothesize that random data sampling for LLMs leads to high training cost and
low quality models which tend to forget data. In order to effectively commit
web-scale information to long-term memory, we propose the LFR (Learn, Focus,
and Review) pedagogy, a new dynamic training paradigm which focuses and
repeatedly reviews complex data blocks at systematic intervals based on the
model's learning pace and progress. LFR records the model perplexities for
different data blocks and frequently revisits blocks with higher perplexity
which are more likely to be forgotten. We pretrain the GPT-2 models (124M -
1.5B) from scratch on the OpenWebText dataset using LFR. We test on downstream
tasks from the language modeling, question answering, translation, and problem
solving domains to achieve consistently lower perplexity and higher accuracy
than the baseline OpenAI models, while obtaining a 20x pretraining speed-up.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QueryBuilder: Human-in-the-Loop Query Development for Information
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hemanth Kandula, Damianos Karakos, Haoling Qiu, Benjamin Rozonoyer, Ian Soboroff, Lee Tarlin, Bonan Min
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Frequently, users of an Information Retrieval (IR) system start with an
overarching information need (a.k.a., an analytic task) and proceed to define
finer-grained queries covering various important aspects (i.e., sub-topics) of
that analytic task. We present a novel, interactive system called
$\textit{QueryBuilder}$, which allows a novice, English-speaking user to create
queries with a small amount of effort, through efficient exploration of an
English development corpus in order to rapidly develop cross-lingual
information retrieval queries corresponding to the user's information needs.
QueryBuilder performs near real-time retrieval of documents based on
user-entered search terms; the user looks through the retrieved documents and
marks sentences as relevant to the information needed. The marked sentences are
used by the system as additional information in query formation and refinement:
query terms (and, optionally, event features, which capture event $'triggers'$
(indicator terms) and agent/patient roles) are appropriately weighted, and a
neural-based system, which better captures textual meaning, retrieves other
relevant content. The process of retrieval and marking is repeated as many
times as desired, giving rise to increasingly refined queries in each
iteration. The final product is a fine-grained query used in Cross-Lingual
Information Retrieval (CLIR). Our experiments using analytic tasks and requests
from the IARPA BETTER IR datasets show that with a small amount of effort (at
most 10 minutes per sub-topic), novice users can form $\textit{useful}$
fine-grained queries including in languages they don't understand. QueryBuilder
also provides beneficial capabilities to the traditional corpus exploration and
query formation process. A demonstration video is released at
https://vimeo.com/734795835
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mitigating the Influence of Distractor Tasks in LMs with Prior-Aware
  Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.17692v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.17692v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raymond Douglas, Andis Draguns, Tomáš Gavenčiak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The broad capabilities of Language Models (LMs) can be limited by their
sensitivity to distractor tasks: LMs can infer secondary tasks from the prompt
in addition to the intended one, leading to unwanted outputs. For example,
prompt injection attacks can cause models to deviate from explicit directives.
In some 'inverse scaling' cases, this unwanted behaviour actually worsens as
models scale up to at least 540B parameters. We present a theoretical framework
that interprets LMs as a product of experts that combine multiple data
generation processes. Based on this framework, we demonstrate prior-aware
decoding (PAD) - a simple contrastive inference method to reduce the influence
of distractor tasks. We apply PAD to eleven models, across four datasets, and
find improvements in 41 out of 44 task-model combinations, with a median
increase in task completion proportion of 40%. The results suggest a promising
direction for further development towards more reliable language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SORSA: Singular Values and Orthonormal Regularized Singular Vectors
  Adaptation of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00055v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00055v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement in large language models (LLMs) comes with a
significant increase in their parameter size, presenting challenges for
adaptation and fine-tuning. Parameter-efficient fine-tuning (PEFT) methods are
widely used to adapt LLMs for downstream tasks efficiently. In this paper, we
propose Singular Values and Orthonormal Regularized Singular Vectors
Adaptation, or SORSA, a novel PEFT method. We introduce a method to analyze the
variation of the parameters by performing singular value decomposition (SVD)
and discuss and analyze SORSA's superiority in minimizing the alteration in the
SVD aspect. Each SORSA adapter consists of two main parts: trainable principal
singular weights $W_p = U_p \Sigma_p V^\top_p$, and frozen residual weights
$W_r = U_r \Sigma_r V^\top_r$. These parts are initialized by performing SVD on
pre-trained weights. Moreover, we implement and analyze an orthonormal
regularizer, which could effectively transfer the scaling information into
$\Sigma_p$ and ultimately allows the training process to be more efficient.
SORSA adapters could be merged during inference, thus eliminating any inference
latency. After all, SORSA shows a faster convergence than PiSSA and LoRA in our
experiments. On the MATH benchmark, Llama 2 7B adapted using SORSA achieved
10.36% accuracy, outperforming LoRA (5.50%), Full FT (7.22%), and PiSSA
(7.44%). On the GSM-8K benchmark, SORSA achieved 56.03% accuracy, surpassing
LoRA (42.30%), Full FT (49.05%), and PiSSA (53.07%). We conclude that SORSA
offers a new perspective on parameter-efficient fine-tuning, demonstrating
remarkable performance. The code is available at
https://github.com/Gunale0926/SORSA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Retrieval-Augmented Generation: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08921v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08921v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, Siliang Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable
success in addressing the challenges of Large Language Models (LLMs) without
necessitating retraining. By referencing an external knowledge base, RAG
refines LLM outputs, effectively mitigating issues such as ``hallucination'',
lack of domain-specific knowledge, and outdated information. However, the
complex structure of relationships among different entities in databases
presents challenges for RAG systems. In response, GraphRAG leverages structural
information across entities to enable more precise and comprehensive retrieval,
capturing relational knowledge and facilitating more accurate, context-aware
responses. Given the novelty and potential of GraphRAG, a systematic review of
current technologies is imperative. This paper provides the first comprehensive
overview of GraphRAG methodologies. We formalize the GraphRAG workflow,
encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced
Generation. We then outline the core technologies and training methods at each
stage. Additionally, we examine downstream tasks, application domains,
evaluation methodologies, and industrial use cases of GraphRAG. Finally, we
explore future research directions to inspire further inquiries and advance
progress in the field. In order to track recent progress in this field, we set
up a repository at \url{https://github.com/pengboci/GraphRAG-Survey}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work. Compared to the first version, several references have
  been added and a GitHub repository link has been provided</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LAST: Language Model Aware Speech Tokenization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03701v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03701v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arnon Turetzky, Yossi Adi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech tokenization serves as the foundation of speech language model (LM),
enabling them to perform various tasks such as spoken language modeling,
text-to-speech, speech-to-text, etc. Most speech tokenizers are trained
independently of the LM training process, relying on separate acoustic models
and quantization methods. Following such an approach may create a mismatch
between the tokenization process and its usage afterward. In this study, we
propose a novel approach to training a speech tokenizer by leveraging
objectives from pre-trained textual LMs. We advocate for the integration of
this objective into the process of learning discrete speech representations.
Our aim is to transform features from a pre-trained speech model into a new
feature space that enables better clustering for speech LMs. We empirically
investigate the impact of various model design choices, including speech
vocabulary size and text LM size. Our results demonstrate the proposed
tokenization method outperforms the evaluated baselines considering both spoken
language modeling and speech-to-text. More importantly, unlike prior work, the
proposed method allows the utilization of a single pre-trained LM for
processing both speech and text inputs, setting it apart from conventional
tokenization approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Check-Eval: A Checklist-based Approach for Evaluating Text Quality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14467v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14467v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jayr Pereira, Andre Assumpcao, Roberto Lotufo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating the quality of text generated by large language models (LLMs)
remains a significant challenge. Traditional metrics often fail to align well
with human judgments, particularly in tasks requiring creativity and nuance. In
this paper, we propose \textsc{Check-Eval}, a novel evaluation framework
leveraging LLMs to assess the quality of generated text through a
checklist-based approach. \textsc{Check-Eval} can be employed as both a
reference-free and reference-dependent evaluation method, providing a
structured and interpretable assessment of text quality. The framework consists
of two main stages: checklist generation and checklist evaluation. We validate
\textsc{Check-Eval} on two benchmark datasets: Portuguese Legal Semantic
Textual Similarity and \textsc{SummEval}. Our results demonstrate that
\textsc{Check-Eval} achieves higher correlations with human judgments compared
to existing metrics, such as \textsc{G-Eval} and \textsc{GPTScore},
underscoring its potential as a more reliable and effective evaluation
framework for natural language generation tasks. The code for our experiments
is available at \url{https://anonymous.4open.science/r/check-eval-0DB4}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-shot Audio Topic Reranking using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.07606v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.07606v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengjie Qian, Rao Ma, Adian Liusie, Erfan Loweimi, Kate M. Knill, Mark J. F. Gales
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Video Search by Examples (MVSE) investigates using video clips as
the query term for information retrieval, rather than the more traditional text
query. This enables far richer search modalities such as images, speaker,
content, topic, and emotion. A key element for this process is highly rapid and
flexible search to support large archives, which in MVSE is facilitated by
representing video attributes with embeddings. This work aims to compensate for
any performance loss from this rapid archive search by examining reranking
approaches. In particular, zero-shot reranking methods using large language
models (LLMs) are investigated as these are applicable to any video archive
audio content. Performance is evaluated for topic-based retrieval on a publicly
available video archive, the BBC Rewind corpus. Results demonstrate that
reranking significantly improves retrieval ranking without requiring any
task-specific in-domain training data. Furthermore, three sources of
information (ASR transcriptions, automatic summaries and synopses) as input for
LLM reranking were compared. To gain a deeper understanding and further
insights into the performance differences and limitations of these text
sources, we employ a fact-checking approach to analyse the information
consistency among them.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dialogue You Can Trust: Human and AI Perspectives on Generated
  Conversations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01808v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01808v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ike Ebubechukwu, Johane Takeuchi, Antonello Ceravola, Frank Joublin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As dialogue systems and chatbots increasingly integrate into everyday
interactions, the need for efficient and accurate evaluation methods becomes
paramount. This study explores the comparative performance of human and AI
assessments across a range of dialogue scenarios, focusing on seven key
performance indicators (KPIs): Coherence, Innovation, Concreteness, Goal
Contribution, Commonsense Contradiction, Incorrect Fact, and Redundancy.
Utilizing the GPT-4o API, we generated a diverse dataset of conversations and
conducted a two-part experimental analysis. In Experiment 1, we evaluated
multi-party conversations on Coherence, Innovation, Concreteness, and Goal
Contribution, revealing that GPT models align closely with human judgments.
Notably, both human and AI evaluators exhibited a tendency towards binary
judgment rather than linear scaling, highlighting a shared challenge in these
assessments. Experiment 2 extended the work of Finch et al. (2023) by focusing
on dyadic dialogues and assessing Commonsense Contradiction, Incorrect Fact,
and Redundancy. The results indicate that while GPT-4o demonstrates strong
performance in maintaining factual accuracy and commonsense reasoning, it still
struggles with reducing redundancy and self-contradiction. Our findings
underscore the potential of GPT models to closely replicate human evaluation in
dialogue systems, while also pointing to areas for improvement. This research
offers valuable insights for advancing the development and implementation of
more refined dialogue evaluation methodologies, contributing to the evolution
of more effective and human-like AI communication tools.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Qwen2 Technical Report 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10671v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10671v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang Guo, Zhihao Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This report introduces the Qwen2 series, the latest addition to our large
language models and large multimodal models. We release a comprehensive suite
of foundational and instruction-tuned language models, encompassing a parameter
range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts
model. Qwen2 surpasses most prior open-weight models, including its predecessor
Qwen1.5, and exhibits competitive performance relative to proprietary models
across diverse benchmarks on language understanding, generation, multilingual
proficiency, coding, mathematics, and reasoning.
  The flagship model, Qwen2-72B, showcases remarkable performance: 84.2 on
MMLU, 37.9 on GPQA, 64.6 on HumanEval, 89.5 on GSM8K, and 82.4 on BBH as a base
language model. The instruction-tuned variant, Qwen2-72B-Instruct, attains 9.1
on MT-Bench, 48.1 on Arena-Hard, and 35.7 on LiveCodeBench. Moreover, Qwen2
demonstrates robust multilingual capabilities, proficient in approximately 30
languages, spanning English, Chinese, Spanish, French, German, Arabic, Russian,
Korean, Japanese, Thai, Vietnamese, and more, underscoring its versatility and
global reach.
  To foster community innovation and accessibility, we have made the Qwen2
model weights openly available on Hugging Face and ModelScope, and the
supplementary materials including example code on GitHub. These platforms also
include resources for quantization, fine-tuning, and deployment, facilitating a
wide range of applications and research endeavors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VITA: Towards Open-Source Interactive Omni Multimodal LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Shaoqi Dong, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable multimodal capabilities and interactive experience of GPT-4o
underscore their necessity in practical applications, yet open-source models
rarely excel in both areas. In this paper, we introduce VITA, the first-ever
open-source Multimodal Large Language Model (MLLM) adept at simultaneous
processing and analysis of Video, Image, Text, and Audio modalities, and
meanwhile has an advanced multimodal interactive experience. Starting from
Mixtral 8x7B as a language foundation, we expand its Chinese vocabulary
followed by bilingual instruction tuning. We further endow the language model
with visual and audio capabilities through two-stage multi-task learning of
multimodal alignment and instruction tuning. VITA demonstrates robust
foundational capabilities of multilingual, vision, and audio understanding, as
evidenced by its strong performance across a range of both unimodal and
multimodal benchmarks. Beyond foundational capabilities, we have made
considerable progress in enhancing the natural multimodal human-computer
interaction experience. VITA is the first step for the open-source community to
explore the seamless integration of multimodal understanding and interaction.
While there is still lots of work to be done on VITA to get close to
close-source counterparts, we hope that its role as a pioneer can serve as a
cornerstone for subsequent research. Project Page: https://vita-home.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://vita-home.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Large Language Models Address Open-Target Stance Detection? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00222v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00222v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abu Ubaida Akash, Ahmed Fahmy, Amine Trabelsi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Stance detection (SD) assesses a text's position towards a target, typically
labeled as "favor," "against," or "neutral." We introduce Open-Target Stance
Detection (OTSD), where targets are neither seen during training nor provided
as input. Evaluating Large Language Models (LLMs) like GPT-3.5, GPT-4o, Llama
3, and Mistral, we compare their performance with the Target-Stance Extraction
(TSE) approach, which has the advantage of using predefined targets. LLMs
perform better than TSE in target generation when the real target is explicitly
and not explicitly mentioned in the text. For stance detection, LLMs perform
better in explicit scenarios but fail in non-explicit ones.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages; currently under submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02813v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02813v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces MMMU-Pro, a robust version of the Massive
Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark.
MMMU-Pro rigorously assesses multimodal models' true understanding and
reasoning capabilities through a three-step process based on MMMU: (1)
filtering out questions answerable by text-only models, (2) augmenting
candidate options, and (3) introducing a vision-only input setting where
questions are embedded within images. This setting challenges AI to truly "see"
and "read" simultaneously, testing a fundamental human cognitive skill of
seamlessly integrating visual and textual information. Results show that model
performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8%
to 26.9% across models. We explore the impact of OCR prompts and Chain of
Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT
generally improves performance. MMMU-Pro provides a more rigorous evaluation
tool, closely mimicking real-world scenarios and offering valuable directions
for future research in multimodal AI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shift-Reduce Task-Oriented Semantic Parsing with Stack-<span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.11984v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.11984v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Fernández-González
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intelligent voice assistants, such as Apple Siri and Amazon Alexa, are widely
used nowadays. These task-oriented dialogue systems require a semantic parsing
module in order to process user utterances and understand the action to be
performed. This semantic parsing component was initially implemented by
rule-based or statistical slot-filling approaches for processing simple
queries; however, the appearance of more complex utterances demanded the
application of shift-reduce parsers or sequence-to-sequence models. Although
shift-reduce approaches were initially considered the most promising option,
the emergence of sequence-to-sequence neural systems has propelled them to the
forefront as the highest-performing method for this particular task. In this
article, we advance the research on shift-reduce semantic parsing for
task-oriented dialogue. We implement novel shift-reduce parsers that rely on
Stack-Transformers. This framework allows to adequately model transition
systems on the Transformer neural architecture, notably boosting shift-reduce
parsing performance. Furthermore, our approach goes beyond the conventional
top-down algorithm: we incorporate alternative bottom-up and in-order
transition systems derived from constituency parsing into the realm of
task-oriented parsing. We extensively test our approach on multiple domains
from the Facebook TOP benchmark, improving over existing shift-reduce parsers
and state-of-the-art sequence-to-sequence models in both high-resource and
low-resource settings. We also empirically prove that the in-order algorithm
substantially outperforms the commonly-used top-down strategy. Through the
creation of innovative transition systems and harnessing the capabilities of a
robust neural architecture, our study showcases the superiority of shift-reduce
parsers over leading sequence-to-sequence methods on the main benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Final peer-reviewed manuscript accepted for publication in Cognitive
  Computation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Much Data is Enough Data? Fine-Tuning Large Language Models for
  In-House Translation: Performance Evaluation Across Multiple <span class="highlight-title">Dataset</span> Sizes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03454v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03454v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Inacio Vieira, Will Allred, Séamus Lankford, Sheila Castilho, Andy Way
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decoder-only LLMs have shown impressive performance in MT due to their
ability to learn from extensive datasets and generate high-quality
translations. However, LLMs often struggle with the nuances and style required
for organisation-specific translation. In this study, we explore the
effectiveness of fine-tuning Large Language Models (LLMs), particularly Llama 3
8B Instruct, leveraging translation memories (TMs), as a valuable resource to
enhance accuracy and efficiency. We investigate the impact of fine-tuning the
Llama 3 model using TMs from a specific organisation in the software sector.
Our experiments cover five translation directions across languages of varying
resource levels (English to Brazilian Portuguese, Czech, German, Finnish, and
Korean). We analyse diverse sizes of training datasets (1k to 207k segments) to
evaluate their influence on translation quality. We fine-tune separate models
for each training set and evaluate their performance based on automatic
metrics, BLEU, chrF++, TER, and COMET. Our findings reveal improvement in
translation performance with larger datasets across all metrics. On average,
BLEU and COMET scores increase by 13 and 25 points, respectively, on the
largest training set against the baseline model. Notably, there is a
performance deterioration in comparison with the baseline model when
fine-tuning on only 1k and 2k examples; however, we observe a substantial
improvement as the training dataset size increases. The study highlights the
potential of integrating TMs with LLMs to create bespoke translation models
tailored to the specific needs of businesses, thus enhancing translation
quality and reducing turn-around times. This approach offers a valuable insight
for organisations seeking to leverage TMs and LLMs for optimal translation
outcomes, especially in narrower domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Relational <span class="highlight-title">Prompt</span>-based <span class="highlight-title">Pre-train</span>ed Language Models for Social Event
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08263v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08263v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pu Li, Xiaoyan Yu, Hao Peng, Yantuan Xian, Linqin Wang, Li Sun, Jingyun Zhang, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social Event Detection (SED) aims to identify significant events from social
streams, and has a wide application ranging from public opinion analysis to
risk management. In recent years, Graph Neural Network (GNN) based solutions
have achieved state-of-the-art performance. However, GNN-based methods often
struggle with missing and noisy edges between messages, affecting the quality
of learned message embedding. Moreover, these methods statically initialize
node embedding before training, which, in turn, limits the ability to learn
from message texts and relations simultaneously. In this paper, we approach
social event detection from a new perspective based on Pre-trained Language
Models (PLMs), and present RPLM_SED (Relational prompt-based Pre-trained
Language Models for Social Event Detection). We first propose a new pairwise
message modeling strategy to construct social messages into message pairs with
multi-relational sequences. Secondly, a new multi-relational prompt-based
pairwise message learning mechanism is proposed to learn more comprehensive
message representation from message pairs with multi-relational prompts using
PLMs. Thirdly, we design a new clustering constraint to optimize the encoding
process by enhancing intra-cluster compactness and inter-cluster dispersion,
making the message representation more distinguishable. We evaluate the
RPLM_SED on three real-world datasets, demonstrating that the RPLM_SED model
achieves state-of-the-art performance in offline, online, low-resource, and
long-tail distribution scenarios for social event detection tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM TOIS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Joint Embeddings for Graph Instruction Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20684v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20684v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aaron Haag, Vlad Argatu, Oliver Lohse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have achieved impressive performance in text
understanding and have become an essential tool for building smart assistants.
Originally focusing on text, they have been enhanced with multimodal
capabilities in recent works that successfully built visual instruction
following assistants. As far as the graph modality goes, however, no such
assistants have yet been developed. Graph structures are complex in that they
represent relation between different features and are permutation invariant.
Moreover, representing them in purely textual form does not always lead to good
LLM performance even for finetuned models. As a result, there is a need to
develop a new method to integrate graphs in LLMs for general graph
understanding. This work explores the integration of the graph modality in LLM
for general graph instruction following tasks. It aims at producing a deep
learning model that enhances an underlying LLM with graph embeddings and trains
it to understand them and to produce, given an instruction, an answer grounded
in the graph representation. The approach performs significantly better than a
graph to text approach and remains consistent even for larger graphs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ALiiCE: Evaluating Positional Fine-grained Citation Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13375v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13375v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilong Xu, Jinhua Gao, Xiaoming Yu, Baolong Bi, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) can enhance the credibility and verifiability by
generating text with citations. However, existing tasks and evaluation methods
are predominantly limited to sentence-level statement, neglecting the
significance of positional fine-grained citations that can appear anywhere
within sentences. To facilitate further exploration of the fine-grained
citation generation, we propose ALiiCE, the first automatic evaluation
framework for this task. Our framework first parses the sentence claim into
atomic claims via dependency analysis and then calculates citation quality at
the atomic claim level. ALiiCE introduces three novel metrics for positional
fined-grained citation quality assessment, including positional fine-grained
citation recall and precision, and coefficient of variation of citation
positions. We evaluate the positional fine-grained citation generation
performance of several LLMs on two long-form QA datasets. Our experiments and
analyses demonstrate the effectiveness and reasonableness of ALiiCE. The
results also indicate that existing LLMs still struggle to provide positional
fine-grained citations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LongCite: Enabling LLMs to Generate Fine-grained Citations in
  Long-context QA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02897v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02897v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiajie Zhang, Yushi Bai, Xin Lv, Wanjun Gu, Danqing Liu, Minhao Zou, Shulin Cao, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Though current long-context large language models (LLMs) have demonstrated
impressive capacities in answering user questions based on extensive text, the
lack of citations in their responses makes user verification difficult, leading
to concerns about their trustworthiness due to their potential hallucinations.
In this work, we aim to enable long-context LLMs to generate responses with
fine-grained sentence-level citations, improving their faithfulness and
verifiability. We first introduce LongBench-Cite, an automated benchmark for
assessing current LLMs' performance in Long-Context Question Answering with
Citations (LQAC), revealing considerable room for improvement. To this end, we
propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs
to automatically generate long-context QA instances with precise sentence-level
citations, and leverage this pipeline to construct LongCite-45k, a large-scale
SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the
LongCite-45k dataset, successfully enabling their generation of accurate
responses and fine-grained sentence-level citations in a single output. The
evaluation results on LongBench-Cite show that our trained models achieve
state-of-the-art citation quality, surpassing advanced proprietary models
including GPT-4o.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpikeCLIP: A Contrastive Language-Image <span class="highlight-title">Pretrain</span>ed Spiking Neural
  Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06488v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06488v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianlong Li, Wenhao Liu, Changze Lv, Yufei Gu, Jianhan Xu, Cenyuan Zhang, Muling Wu, Xiaoqing Zheng, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking Neural Networks (SNNs) have emerged as a promising alternative to
conventional Artificial Neural Networks (ANNs), demonstrating comparable
performance in both visual and linguistic tasks while offering the advantage of
improved energy efficiency. Despite these advancements, the integration of
linguistic and visual features into a unified representation through spike
trains poses a significant challenge, and the application of SNNs to multimodal
scenarios remains largely unexplored. This paper presents SpikeCLIP, a novel
framework designed to bridge the modality gap in spike-based computation. Our
approach employs a two-step recipe: an ``alignment pre-training'' to align
features across modalities, followed by a ``dual-loss fine-tuning'' to refine
the model's performance. Extensive experiments reveal that SNNs achieve results
on par with ANNs while substantially reducing energy consumption across various
datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP
maintains robust image classification capabilities, even when dealing with
classes that fall outside predefined categories. This study marks a significant
advancement in the development of energy-efficient and biologically plausible
multimodal learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Building a Robust Knowledge Intensive Question Answering Model
  with Large Language Models <span class="chip">NLPCC-2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Xingyun Hong, Shao Yan Shao, Wang Zhilin Wang, Duan Manni Duan, Jin Xiongnan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of LLMs has greatly enhanced the intelligence and fluency of
question answering, while the emergence of retrieval enhancement has enabled
models to better utilize external information. However, the presence of noise
and errors in retrieved information poses challenges to the robustness of LLMs.
In this work, to evaluate the model's performance under multiple interferences,
we first construct a dataset based on machine reading comprehension datasets
simulating various scenarios, including critical information absence, noise,
and conflicts. To address the issue of model accuracy decline caused by noisy
external information, we propose a data augmentation-based fine-tuning method
to enhance LLM's robustness against noise. Additionally, contrastive learning
approach is utilized to preserve the model's discrimination capability of
external information. We have conducted experiments on both existing LLMs and
our approach, the results are evaluated by GPT-4, which indicates that our
proposed methods improve model robustness while strengthening the model's
discrimination capability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by NLPCC-2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Patronizing and Condescending Language in Chinese Videos: A
  Multimodal <span class="highlight-title">Dataset</span> and Detector <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05005v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05005v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongbo Wang, Junyu Lu, Yan Han, Kai Ma, Liang Yang, Hongfei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Patronizing and Condescending Language (PCL) is a form of discriminatory
toxic speech targeting vulnerable groups, threatening both online and offline
safety. While toxic speech research has mainly focused on overt toxicity, such
as hate speech, microaggressions in the form of PCL remain underexplored.
Additionally, dominant groups' discriminatory facial expressions and attitudes
toward vulnerable communities can be more impactful than verbal cues, yet these
frame features are often overlooked. In this paper, we introduce the PCLMM
dataset, the first Chinese multimodal dataset for PCL, consisting of 715
annotated videos from Bilibili, with high-quality PCL facial frame spans. We
also propose the MultiPCL detector, featuring a facial expression detection
module for PCL recognition, demonstrating the effectiveness of modality
complementarity in this challenging task. Our work makes an important
contribution to advancing microaggression detection within the domain of toxic
speech.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review in ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spinning the Golden Thread: Benchmarking Long-Form Generation in
  long-context LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02076v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02076v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Wu, Ming Shan Hee, Zhiqing Hu, Roy Ka-Wei Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The abilities of long-context language models (LMs) are often evaluated using
the "Needle-in-a-Haystack" (NIAH) test, which comprises tasks designed to
assess a model's ability to identify specific information ("needle") within
large text sequences ("haystack"). While these benchmarks measure how well
models understand long-context input sequences, they do not effectively gauge
the quality of long-form text generation--a critical aspect for applications
such as design proposals and creative writing. To address this gap, we have
introduced a new long-form text evaluation benchmark, Spinning the Golden
Thread (SGT), which tests models' ability to identify specific events within
generated long text sequences. In this benchmark, we prompt long-context LMs to
create long-form text that must include particular events or constraints and
evaluate their ability to incorporate these elements. We evaluated ten
long-context LMs across four distinct scenarios, three types of prompt
instructions, and two different generation-length settings (16K and 32K).
Although these models perform well on NIAH benchmarks, none demonstrated
satisfactory performance on the Spinning the Golden Thread, raising concerns
about their ability to generate coherent long-form text that follows
instructions. Additionally, as the length of the generated text increases, all
models exhibit a significant drop in performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Performance Law of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09895v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09895v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuhan Wu, Ruiming Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Guided by the belief of the scaling law, large language models (LLMs) have
achieved impressive performance in recent years. However, scaling law only
gives a qualitative estimation of loss, which is influenced by various factors
such as model architectures, data distributions, tokenizers, and computation
precision. Thus, estimating the real performance of LLMs with different
training settings rather than loss may be quite useful in practical
development. In this article, we present an empirical equation named
"Performance Law" to directly predict the MMLU score of an LLM, which is a
widely used metric to indicate the general capability of LLMs in real-world
conversations and applications. Based on only a few key hyperparameters of the
LLM architecture and the size of training data, we obtain a quite accurate MMLU
prediction of various LLMs with diverse sizes and architectures developed by
different organizations in different years. Performance law can be used to
guide the choice of LLM architecture and the effective allocation of
computational resources without extensive experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Personal opinions of the authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge
  Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05591v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05591v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) leverages retrieval tools to access
external databases, thereby enhancing the generation quality of large language
models (LLMs) through optimized context. However, the existing retrieval
methods are constrained inherently, as they can only perform relevance matching
between explicitly stated queries and well-formed knowledge, but unable to
handle tasks involving ambiguous information needs or unstructured knowledge.
Consequently, existing RAG systems are primarily effective for straightforward
question-answering tasks. In this work, we propose MemoRAG, a novel
retrieval-augmented generation paradigm empowered by long-term memory. MemoRAG
adopts a dual-system architecture. On the one hand, it employs a light but
long-range LLM to form the global memory of database. Once a task is presented,
it generates draft answers, cluing the retrieval tools to locate useful
information within the database. On the other hand, it leverages an expensive
but expressive LLM, which generates the ultimate answer based on the retrieved
information. Building on this general framework, we further optimize MemoRAG's
performance by enhancing its cluing mechanism and memorization capacity. In our
experiment, MemoRAG achieves superior performance across a variety of
evaluation tasks, including both complex ones where conventional RAG fails and
straightforward ones where RAG is commonly applied.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report. Codes and models are in
  https://github.com/qhjqhj00/MemoRAG</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Large Language Models Learn Independent Causal Mechanisms? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02636v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02636v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaël Gendron, Bao Trung Nguyen, Alex Yuxuan Peng, Michael Witbrock, Gillian Dobbie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite impressive performance on language modelling and complex reasoning
tasks, Large Language Models (LLMs) fall short on the same tasks in uncommon
settings or with distribution shifts, exhibiting a lack of generalisation
ability. By contrast, systems such as causal models, that learn abstract
variables and causal relationships, can demonstrate increased robustness
against changes in the distribution. One reason for this success is the
existence and use of Independent Causal Mechanisms (ICMs) representing
high-level concepts that only sparsely interact. In this work, we apply two
concepts from causality to learn ICMs within LLMs. We develop a new LLM
architecture composed of multiple sparsely interacting language modelling
modules. We show that such causal constraints can improve out-of-distribution
performance on abstract and causal reasoning tasks. We also investigate the
level of independence and domain specialisation and show that LLMs rely on
pre-trained partially domain-invariant mechanisms resilient to fine-tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 7 pages for the main paper and 13 pages for references and
  appendices, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">134</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GeoCalib: Learning Single-image Calibration with Geometric Optimization <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Veicht, Paul-Edouard Sarlin, Philipp Lindenberger, Marc Pollefeys
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  From a single image, visual cues can help deduce intrinsic and extrinsic
camera parameters like the focal length and the gravity direction. This
single-image calibration can benefit various downstream applications like image
editing and 3D mapping. Current approaches to this problem are based on either
classical geometry with lines and vanishing points or on deep neural networks
trained end-to-end. The learned approaches are more robust but struggle to
generalize to new environments and are less accurate than their classical
counterparts. We hypothesize that they lack the constraints that 3D geometry
provides. In this work, we introduce GeoCalib, a deep neural network that
leverages universal rules of 3D geometry through an optimization process.
GeoCalib is trained end-to-end to estimate camera parameters and learns to find
useful visual cues from the data. Experiments on various benchmarks show that
GeoCalib is more robust and more accurate than existing classical and learned
approaches. Its internal optimization estimates uncertainties, which help flag
failure cases and benefit downstream applications like visual localization. The
code and trained models are publicly available at
https://github.com/cvg/GeoCalib.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEIA: Latent View-invariant Embeddings for Implicit 3D Articulation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06703v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06703v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Archana Swaminathan, Anubhav Gupta, Kamal Gupta, Shishira R. Maiya, Vatsal Agarwal, Abhinav Shrivastava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Radiance Fields (NeRFs) have revolutionized the reconstruction of
static scenes and objects in 3D, offering unprecedented quality. However,
extending NeRFs to model dynamic objects or object articulations remains a
challenging problem. Previous works have tackled this issue by focusing on
part-level reconstruction and motion estimation for objects, but they often
rely on heuristics regarding the number of moving parts or object categories,
which can limit their practical use. In this work, we introduce LEIA, a novel
approach for representing dynamic 3D objects. Our method involves observing the
object at distinct time steps or "states" and conditioning a hypernetwork on
the current state, using this to parameterize our NeRF. This approach allows us
to learn a view-invariant latent representation for each state. We further
demonstrate that by interpolating between these states, we can generate novel
articulation configurations in 3D space that were previously unseen. Our
experimental results highlight the effectiveness of our method in articulating
objects in a manner that is independent of the viewing angle and joint
configuration. Notably, our approach outperforms previous methods that rely on
motion information for articulation registration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024. Project Website at
  https://archana1998.github.io/leia/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous
  Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06702v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06702v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kairui Ding, Boyuan Chen, Yuchen Su, Huan-ang Gao, Bu Jin, Chonghao Sima, Wuqiang Zhang, Xiaohui Li, Paul Barsch, Hongyang Li, Hao Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end architectures in autonomous driving (AD) face a significant
challenge in interpretability, impeding human-AI trust. Human-friendly natural
language has been explored for tasks such as driving explanation and 3D
captioning. However, previous works primarily focused on the paradigm of
declarative interpretability, where the natural language interpretations are
not grounded in the intermediate outputs of AD systems, making the
interpretations only declarative. In contrast, aligned interpretability
establishes a connection between language and the intermediate outputs of AD
systems. Here we introduce Hint-AD, an integrated AD-language system that
generates language aligned with the holistic perception-prediction-planning
outputs of the AD model. By incorporating the intermediate outputs and a
holistic token mixer sub-network for effective feature adaptation, Hint-AD
achieves desirable accuracy, achieving state-of-the-art results in driving
language tasks including driving explanation, 3D dense captioning, and command
prediction. To facilitate further study on driving explanation task on
nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and
models will be publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CoRL 2024, Project Page: https://air-discover.github.io/Hint-AD/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A study on Deep Convolutional Neural Networks, Transfer Learning and
  Ensemble Model for Breast Cancer Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06699v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06699v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Taimur Ahad, Sumaya Mustofa, Faruk Ahmed, Yousuf Rayhan Emon, Aunirudra Dey Anu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In deep learning, transfer learning and ensemble models have shown promise in
improving computer-aided disease diagnosis. However, applying the transfer
learning and ensemble model is still relatively limited. Moreover, the ensemble
model's development is ad-hoc, overlooks redundant layers, and suffers from
imbalanced datasets and inadequate augmentation. Lastly, significant Deep
Convolutional Neural Networks (D-CNNs) have been introduced to detect and
classify breast cancer. Still, very few comparative studies were conducted to
investigate the accuracy and efficiency of existing CNN architectures.
Realising the gaps, this study compares the performance of D-CNN, which
includes the original CNN, transfer learning, and an ensemble model, in
detecting breast cancer. The comparison study of this paper consists of
comparison using six CNN-based deep learning architectures (SE-ResNet152,
MobileNetV2, VGG19, ResNet18, InceptionV3, and DenseNet-121), a transfer
learning, and an ensemble model on breast cancer detection. Among the
comparison of these models, the ensemble model provides the highest detection
and classification accuracy of 99.94% for breast cancer detection and
classification. However, this study also provides a negative result in the case
of transfer learning, as the transfer learning did not increase the accuracy of
the original SE-ResNet152, MobileNetV2, VGG19, ResNet18, InceptionV3, and
DenseNet-121 model. The high accuracy in detecting and categorising breast
cancer detection using CNN suggests that the CNN model is promising in breast
cancer disease detection. This research is significant in biomedical
engineering, computer-aided disease diagnosis, and ML-based disease detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A comprehensive study on Blood Cancer detection and classification using
  Convolutional Neural Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06689v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06689v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Taimur Ahad, Sajib Bin Mamun, Sumaya Mustofa, Bo Song, Yan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the years in object detection several efficient Convolutional Neural
Networks (CNN) networks, such as DenseNet201, InceptionV3, ResNet152v2,
SEresNet152, VGG19, Xception gained significant attention due to their
performance. Moreover, CNN paradigms have expanded to transfer learning and
ensemble models from original CNN architectures. Research studies suggest that
transfer learning and ensemble models are capable of increasing the accuracy of
deep learning (DL) models. However, very few studies have conducted
comprehensive experiments utilizing these techniques in detecting and
localizing blood malignancies. Realizing the gap, this study conducted three
experiments; in the first experiment -- six original CNNs were used, in the
second experiment -- transfer learning and, in the third experiment a novel
ensemble model DIX (DenseNet201, InceptionV3, and Xception) was developed to
detect and classify blood cancer. The statistical result suggests that DIX
outperformed the original and transfer learning performance, providing an
accuracy of 99.12%. However, this study also provides a negative result in the
case of transfer learning, as the transfer learning did not increase the
accuracy of the original CNNs. Like many other cancers, blood cancer diseases
require timely identification for effective treatment plans and increased
survival possibilities. The high accuracy in detecting and categorization blood
cancer detection using CNN suggests that the CNN model is promising in blood
cancer disease detection. This research is significant in the fields of
biomedical engineering, computer-aided disease diagnosis, and ML-based disease
detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A study on deep feature extraction to detect and classify Acute
  Lymphoblastic Leukemia (ALL) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabit Ahamed Preanto, Md. Taimur Ahad, Yousuf Rayhan Emon, Sumaya Mustofa, Md Alamin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acute lymphoblastic leukaemia (ALL) is a blood malignancy that mainly affects
adults and children. This study looks into the use of deep learning,
specifically Convolutional Neural Networks (CNNs), for the detection and
classification of ALL. Conventional techniques for ALL diagnosis, such bone
marrow biopsy, are costly and prone to mistakes made by hand. By utilising
automated technologies, the research seeks to improve diagnostic accuracy. The
research uses a variety of pre-trained CNN models, such as InceptionV3,
ResNet101, VGG19, DenseNet121, MobileNetV2, and DenseNet121, to extract
characteristics from pictures of blood smears. ANOVA, Recursive Feature
Elimination (RFE), Random Forest, Lasso, and Principal Component Analysis (PCA)
are a few of the selection approaches used to find the most relevant features
after feature extraction. Following that, machine learning methods like Na\"ive
Bayes, Random Forest, Support Vector Machine (SVM), and K-Nearest Neighbours
(KNN) are used to classify these features. With an 87% accuracy rate, the
ResNet101 model produced the best results, closely followed by DenseNet121 and
VGG19. According to the study, CNN-based models have the potential to decrease
the need for medical specialists by increasing the speed and accuracy of ALL
diagnosis. To improve model performance, the study also recommends expanding
and diversifying datasets and investigating more sophisticated designs such as
transformers. This study highlights how well automated deep learning systems do
medical diagnosis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GigaGS: Scaling up Planar-Based 3D Gaussians for Large Scene Surface
  Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06685v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06685v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyi Chen, Weicai Ye, Yifan Wang, Danpeng Chen, Di Huang, Wanli Ouyang, Guofeng Zhang, Yu Qiao, Tong He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D Gaussian Splatting (3DGS) has shown promising performance in novel view
synthesis. Previous methods adapt it to obtaining surfaces of either individual
3D objects or within limited scenes. In this paper, we make the first attempt
to tackle the challenging task of large-scale scene surface reconstruction.
This task is particularly difficult due to the high GPU memory consumption,
different levels of details for geometric representation, and noticeable
inconsistencies in appearance. To this end, we propose GigaGS, the first work
for high-quality surface reconstruction for large-scale scenes using 3DGS.
GigaGS first applies a partitioning strategy based on the mutual visibility of
spatial regions, which effectively grouping cameras for parallel processing. To
enhance the quality of the surface, we also propose novel multi-view
photometric and geometric consistency constraints based on Level-of-Detail
representation. In doing so, our method can reconstruct detailed surface
structures. Comprehensive experiments are conducted on various datasets. The
consistent improvement demonstrates the superiority of GigaGS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Alignist: CAD-Informed Orientation Distribution Estimation by Fusing
  Shape and Correspondences <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06683v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06683v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shishir Reddy Vutukur, Rasmus Laurvig Haugaard, Junwen Huang, Benjamin Busam, Tolga Birdal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object pose distribution estimation is crucial in robotics for better path
planning and handling of symmetric objects. Recent distribution estimation
approaches employ contrastive learning-based approaches by maximizing the
likelihood of a single pose estimate in the absence of a CAD model. We propose
a pose distribution estimation method leveraging symmetry respecting
correspondence distributions and shape information obtained using a CAD model.
Contrastive learning-based approaches require an exhaustive amount of training
images from different viewpoints to learn the distribution properly, which is
not possible in realistic scenarios. Instead, we propose a pipeline that can
leverage correspondence distributions and shape information from the CAD model,
which are later used to learn pose distributions. Besides, having access to
pose distribution based on correspondences before learning pose distributions
conditioned on images, can help formulate the loss between distributions. The
prior knowledge of distribution also helps the network to focus on getting
sharper modes instead. With the CAD prior, our approach converges much faster
and learns distribution better by focusing on learning sharper distribution
near all the valid modes, unlike contrastive approaches, which focus on a
single mode at a time. We achieve benchmark results on SYMSOL-I and T-Less
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Constructing an Interpretable Deep Denoiser by Unrolling Graph Laplacian
  Regularizer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06676v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06676v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seyed Alireza Hosseini, Tam Thuc Do, Gene Cheung, Yuichi Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An image denoiser can be used for a wide range of restoration problems via
the Plug-and-Play (PnP) architecture. In this paper, we propose a general
framework to build an interpretable graph-based deep denoiser (GDD) by
unrolling a solution to a maximum a posteriori (MAP) problem equipped with a
graph Laplacian regularizer (GLR) as signal prior. Leveraging a recent theorem
showing that any (pseudo-)linear denoiser $\boldsymbol \Psi$, under mild
conditions, can be mapped to a solution of a MAP denoising problem regularized
using GLR, we first initialize a graph Laplacian matrix $\mathbf L$ via
truncated Taylor Series Expansion (TSE) of $\boldsymbol \Psi^{-1}$. Then, we
compute the MAP linear system solution by unrolling iterations of the conjugate
gradient (CG) algorithm into a sequence of neural layers as a feed-forward
network -- one that is amenable to parameter tuning. The resulting GDD network
is "graph-interpretable", low in parameter count, and easy to initialize thanks
to $\mathbf L$ derived from a known well-performing denoiser $\boldsymbol
\Psi$. Experimental results show that GDD achieves competitive image denoising
performance compared to competitors, but employing far fewer parameters, and is
more robust to covariate shift.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Semantic Segmentation Approach on Sweet Orange Leaf Diseases Detection
  Utilizing YOLO 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabit Ahamed Preanto, Md. Taimur Ahad, Yousuf Rayhan Emon, Sumaya Mustofa, Md Alamin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This research introduces an advanced method for diagnosing diseases in sweet
orange leaves by utilising advanced artificial intelligence models like YOLOv8
. Due to their significance as a vital agricultural product, sweet oranges
encounter significant threats from a variety of diseases that harmfully affect
both their yield and quality. Conventional methods for disease detection
primarily depend on manual inspection which is ineffective and frequently leads
to errors, resulting in delayed treatment and increased financial losses. In
response to this challenge, the research utilized YOLOv8 , harnessing their
proficiencies in detecting objects and analyzing images. YOLOv8 is recognized
for its rapid and precise performance, while VIT is acknowledged for its
detailed feature extraction abilities. Impressively, during both the training
and validation stages, YOLOv8 exhibited a perfect accuracy of 80.4%, while VIT
achieved an accuracy of 99.12%, showcasing their potential to transform disease
detection in agriculture. The study comprehensively examined the practical
challenges related to the implementation of AI technologies in agriculture,
encompassing the computational demands and user accessibility, and offering
viable solutions for broader usage. Moreover, it underscores the environmental
considerations, particularly the potential for reduced pesticide usage, thereby
promoting sustainable farming and environmental conservation. These findings
provide encouraging insights into the application of AI in agriculture,
suggesting a transition towards more effective, sustainable, and
technologically advanced farming methods. This research not only highlights the
efficacy of YOLOv8 within a specific agricultural domain but also lays the
foundation for further studies that encompass a broader application in crop
management and sustainable agricultural practices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Collection-free Masked Video Modeling <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchi Ishikawa, Masayoshi Kondo, Yoshimitsu Aoki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-training video transformers generally requires a large amount of data,
presenting significant challenges in terms of data collection costs and
concerns related to privacy, licensing, and inherent biases. Synthesizing data
is one of the promising ways to solve these issues, yet pre-training solely on
synthetic data has its own challenges. In this paper, we introduce an effective
self-supervised learning framework for videos that leverages readily available
and less costly static images. Specifically, we define the Pseudo Motion
Generator (PMG) module that recursively applies image transformations to
generate pseudo-motion videos from images. These pseudo-motion videos are then
leveraged in masked video modeling. Our approach is applicable to synthetic
images as well, thus entirely freeing video pre-training from data collection
costs and other concerns in real data. Through experiments in action
recognition tasks, we demonstrate that this framework allows effective learning
of spatio-temporal features through pseudo-motion videos, significantly
improving over existing methods which also use static images and partially
outperforming those using both real and synthetic videos. These results uncover
fragments of what video transformers learn through masked video modeling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ World-Grounded Human Motion Recovery via Gravity-View Coordinates <span class="chip">SIGGRAPH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06662v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06662v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zehong Shen, Huaijin Pi, Yan Xia, Zhi Cen, Sida Peng, Zechen Hu, Hujun Bao, Ruizhen Hu, Xiaowei Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel method for recovering world-grounded human motion from
monocular video. The main challenge lies in the ambiguity of defining the world
coordinate system, which varies between sequences. Previous approaches attempt
to alleviate this issue by predicting relative motion in an autoregressive
manner, but are prone to accumulating errors. Instead, we propose estimating
human poses in a novel Gravity-View (GV) coordinate system, which is defined by
the world gravity and the camera view direction. The proposed GV system is
naturally gravity-aligned and uniquely defined for each video frame, largely
reducing the ambiguity of learning image-pose mapping. The estimated poses can
be transformed back to the world coordinate system using camera rotations,
forming a global motion sequence. Additionally, the per-frame estimation avoids
error accumulation in the autoregressive methods. Experiments on in-the-wild
benchmarks demonstrate that our method recovers more realistic motion in both
the camera space and world-grounded settings, outperforming state-of-the-art
methods in both accuracy and speed. The code is available at
https://zju3dv.github.io/gvhmr/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SIGGRAPH Asia 2024 (Conference Track). Project page:
  https://zju3dv.github.io/gvhmr/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Image Vectorization with Depth: convexified shape layers with depth
  ordering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06648v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06648v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ho Law, Sung Ha Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image vectorization is a process to convert a raster image into a scalable
vector graphic format. Objective is to effectively remove the pixelization
effect while representing boundaries of image by scaleable parameterized
curves. We propose new image vectorization with depth which considers depth
ordering among shapes and use curvature-based inpainting for convexifying
shapes in vectorization process.From a given color quantized raster image, we
first define each connected component of the same color as a shape layer, and
construct depth ordering among them using a newly proposed depth ordering
energy. Global depth ordering among all shapes is described by a directed
graph, and we propose an energy to remove cycle within the graph. After
constructing depth ordering of shapes, we convexify occluded regions by Euler's
elastica curvature-based variational inpainting, and leverage on the stability
of Modica-Mortola double-well potential energy to inpaint large regions. This
is following human vision perception that boundaries of shapes extend smoothly,
and we assume shapes are likely to be convex. Finally, we fit B\'{e}zier curves
to the boundaries and save vectorization as a SVG file which allows
superposition of curvature-based inpainted shapes following the depth ordering.
This is a new way to vectorize images, by decomposing an image into scalable
shape layers with computed depth ordering. This approach makes editing shapes
and images more natural and intuitive. We also consider grouping shape layers
for semantic vectorization. We present various numerical results and
comparisons against recent layer-based vectorization methods to validate the
proposed model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EyeCLIP: A visual-language foundation model for multi-modal ophthalmic
  image analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06644v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06644v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danli Shi, Weiyi Zhang, Jiancheng Yang, Siyu Huang, Xiaolan Chen, Mayinuer Yusufu, Kai Jin, Shan Lin, Shunming Liu, Qing Zhang, Mingguang He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Early detection of eye diseases like glaucoma, macular degeneration, and
diabetic retinopathy is crucial for preventing vision loss. While artificial
intelligence (AI) foundation models hold significant promise for addressing
these challenges, existing ophthalmic foundation models primarily focus on a
single modality, whereas diagnosing eye diseases requires multiple modalities.
A critical yet often overlooked aspect is harnessing the multi-view information
across various modalities for the same patient. Additionally, due to the
long-tail nature of ophthalmic diseases, standard fully supervised or
unsupervised learning approaches often struggle. Therefore, it is essential to
integrate clinical text to capture a broader spectrum of diseases. We propose
EyeCLIP, a visual-language foundation model developed using over 2.77 million
multi-modal ophthalmology images with partial text data. To fully leverage the
large multi-modal unlabeled and labeled data, we introduced a pretraining
strategy that combines self-supervised reconstructions, multi-modal image
contrastive learning, and image-text contrastive learning to learn a shared
representation of multiple modalities. Through evaluation using 14 benchmark
datasets, EyeCLIP can be transferred to a wide range of downstream tasks
involving ocular and systemic diseases, achieving state-of-the-art performance
in disease classification, visual question answering, and cross-modal
retrieval. EyeCLIP represents a significant advancement over previous methods,
especially showcasing few-shot, even zero-shot capabilities in real-world
long-tail scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse
  Low-Rank Adaptation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teng Hu, Jiangning Zhang, Ran Yi, Hongrui Huang, Yabiao Wang, Lizhuang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the development of diffusion models has led to significant
progress in image and video generation tasks, with pre-trained models like the
Stable Diffusion series playing a crucial role. Inspired by model pruning which
lightens large pre-trained models by removing unimportant parameters, we
propose a novel model fine-tuning method to make full use of these ineffective
parameters and enable the pre-trained model with new task-specified
capabilities. In this work, we first investigate the importance of parameters
in pre-trained diffusion models, and discover that the smallest 10% to 20% of
parameters by absolute values do not contribute to the generation process.
Based on this observation, we propose a method termed SaRA that re-utilizes
these temporarily ineffective parameters, equating to optimizing a sparse
weight matrix to learn the task-specific knowledge. To mitigate overfitting, we
propose a nuclear-norm-based low-rank sparse training scheme for efficient
fine-tuning. Furthermore, we design a new progressive parameter adjustment
strategy to make full use of the re-trained/finetuned parameters. Finally, we
propose a novel unstructural backpropagation strategy, which significantly
reduces memory costs during fine-tuning. Our method enhances the generative
capabilities of pre-trained models in downstream applications and outperforms
traditional fine-tuning methods like LoRA in maintaining model's generalization
ability. We validate our approach through fine-tuning experiments on SD models,
demonstrating significant improvements. SaRA also offers a practical advantage
that requires only a single line of code modification for efficient
implementation and is seamlessly compatible with existing methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Parameter efficient finetuning method</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Localizing Structural Elements: Merging Geometrical Detection
  with Semantic Verification in RGB-D Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Tourani, Saad Ejaz, Hriday Bavle, Jose Luis Sanchez-Lopez, Holger Voos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  RGB-D cameras supply rich and dense visual and spatial information for
various robotics tasks such as scene understanding, map reconstruction, and
localization. Integrating depth and visual information can aid robots in
localization and element mapping, advancing applications like 3D scene graph
generation and Visual Simultaneous Localization and Mapping (VSLAM). While
point cloud data containing such information is primarily used for enhanced
scene understanding, exploiting their potential to capture and represent rich
semantic information has yet to be adequately targeted. This paper presents a
real-time pipeline for localizing building components, including wall and
ground surfaces, by integrating geometric calculations for pure 3D plane
detection followed by validating their semantic category using point cloud data
from RGB-D cameras. It has a parallel multi-thread architecture to precisely
estimate poses and equations of all the planes detected in the environment,
filters the ones forming the map structure using a panoptic segmentation
validation, and keeps only the validated building components. Incorporating the
proposed method into a VSLAM framework confirmed that constraining the map with
the detected environment-driven semantic elements can improve scene
understanding and map reconstruction accuracy. It can also ensure
(re-)association of these detected components into a unified 3D scene graph,
bridging the gap between geometric accuracy and semantic understanding.
Additionally, the pipeline allows for the detection of potential higher-level
structural entities, such as rooms, by identifying the relationships between
building components based on their layout.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 5 figures. 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MVGaussian: High-Fidelity text-to-3D Content Generation with Multi-View
  Guidance and Surface Densification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Phu Pham, Aradhya N. Mathur, Ojaswa Sharma, Aniket Bera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of text-to-3D content generation has made significant progress in
generating realistic 3D objects, with existing methodologies like Score
Distillation Sampling (SDS) offering promising guidance. However, these methods
often encounter the "Janus" problem-multi-face ambiguities due to imprecise
guidance. Additionally, while recent advancements in 3D gaussian splitting have
shown its efficacy in representing 3D volumes, optimization of this
representation remains largely unexplored. This paper introduces a unified
framework for text-to-3D content generation that addresses these critical gaps.
Our approach utilizes multi-view guidance to iteratively form the structure of
the 3D model, progressively enhancing detail and accuracy. We also introduce a
novel densification algorithm that aligns gaussians close to the surface,
optimizing the structural integrity and fidelity of the generated models.
Extensive experiments validate our approach, demonstrating that it produces
high-quality visual outputs with minimal time cost. Notably, our method
achieves high-quality results within half an hour of training, offering a
substantial efficiency gain over most existing methods, which require hours of
training time to achieve comparable results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hierarchical Multi-Label Classification with Missing Information for
  Benthic Habitat Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Isaac Xu, Benjamin Misiuk, Scott C. Lowe, Martin Gillis, Craig J. Brown, Thomas Trappenberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we apply state-of-the-art self-supervised learning techniques
on a large dataset of seafloor imagery, \textit{BenthicNet}, and study their
performance for a complex hierarchical multi-label (HML) classification
downstream task. In particular, we demonstrate the capacity to conduct HML
training in scenarios where there exist multiple levels of missing annotation
information, an important scenario for handling heterogeneous real-world data
collected by multiple research groups with differing data collection protocols.
We find that, when using smaller one-hot image label datasets typical of local
or regional scale benthic science projects, models pre-trained with
self-supervision on a larger collection of in-domain benthic data outperform
models pre-trained on ImageNet. In the HML setting, we find the model can
attain a deeper and more precise classification if it is pre-trained with
self-supervision on in-domain data. We hope this work can establish a benchmark
for future models in the field of automated underwater image annotation tasks
and can guide work in other domains with hierarchical annotations of mixed
resolution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When to Extract ReID Features: A Selective Approach for Improved
  Multiple Object Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06617v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06617v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emirhan Bayar, Cemal Aker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extracting and matching Re-Identification (ReID) features is used by many
state-of-the-art (SOTA) Multiple Object Tracking (MOT) methods, particularly
effective against frequent and long-term occlusions. While end-to-end object
detection and tracking have been the main focus of recent research, they have
yet to outperform traditional methods in benchmarks like MOT17 and MOT20. Thus,
from an application standpoint, methods with separate detection and embedding
remain the best option for accuracy, modularity, and ease of implementation,
though they are impractical for edge devices due to the overhead involved. In
this paper, we investigate a selective approach to minimize the overhead of
feature extraction while preserving accuracy, modularity, and ease of
implementation. This approach can be integrated into various SOTA methods. We
demonstrate its effectiveness by applying it to StrongSORT and Deep OC-SORT.
Experiments on MOT17, MOT20, and DanceTrack datasets show that our mechanism
retains the advantages of feature extraction during occlusions while
significantly reducing runtime. Additionally, it improves accuracy by
preventing confusion in the feature-matching stage, particularly in cases of
deformation and appearance similarity, which are common in DanceTrack.
https://github.com/emirhanbayar/Fast-StrongSORT,
https://github.com/emirhanbayar/Fast-Deep-OC-SORT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 figures. Presents a selective approach for ReID feature
  extraction in Multiple Object Tracking, reducing computational overhead while
  maintaining accuracy. Tested on StrongSORT and Deep OC-SORT using MOT17,
  MOT20, and DanceTrack datasets. Code:
  https://github.com/emirhanbayar/Fast-StrongSORT,
  https://github.com/emirhanbayar/Fast-Deep-OC-SORT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving the Precision of CNNs for Magnetic Resonance Spectral Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John LaMaster, Dhritiman Das, Florian Kofler, Jason Crane, Yan Li, Tobias Lasser, Bjoern H Menze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetic resonance spectroscopic imaging is a widely available imaging
modality that can non-invasively provide a metabolic profile of the tissue of
interest, yet is challenging to integrate clinically. One major reason is the
expensive, expert data processing and analysis that is required. Using machine
learning to predict MRS-related quantities offers avenues around this problem,
but deep learning models bring their own challenges, especially model trust.
Current research trends focus primarily on mean error metrics, but
comprehensive precision metrics are also needed, e.g. standard deviations,
confidence intervals, etc.. This work highlights why more comprehensive error
characterization is important and how to improve the precision of CNNs for
spectral modeling, a quantitative task. The results highlight advantages and
trade-offs of these techniques that should be considered when addressing such
regression tasks with CNNs. Detailed insights into the underlying mechanisms of
each technique, and how they interact with other techniques, are discussed in
depth.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 1 figure, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactive 3D Segmentation for Primary Gross Tumor Volume in
  Oropharyngeal Cancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikko Saukkoriipi, Jaakko Sahlsten, Joel Jaskari, Lotta Orasmaa, Jari Kangas, Nastaran Rasouli, Roope Raisamo, Jussi Hirvonen, Helena Mehtonen, Jorma Järnstedt, Antti Mäkitie, Mohamed Naser, Clifton Fuller, Benjamin Kann, Kimmo Kaski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The main treatment modality for oropharyngeal cancer (OPC) is radiotherapy,
where accurate segmentation of the primary gross tumor volume (GTVp) is
essential. However, accurate GTVp segmentation is challenging due to
significant interobserver variability and the time-consuming nature of manual
annotation, while fully automated methods can occasionally fail. An interactive
deep learning (DL) model offers the advantage of automatic high-performance
segmentation with the flexibility for user correction when necessary. In this
study, we examine interactive DL for GTVp segmentation in OPC. We implement
state-of-the-art algorithms and propose a novel two-stage Interactive Click
Refinement (2S-ICR) framework. Using the 2021 HEad and neCK TumOR (HECKTOR)
dataset for development and an external dataset from The University of Texas MD
Anderson Cancer Center for evaluation, the 2S-ICR framework achieves a Dice
similarity coefficient of 0.713 $\pm$ 0.152 without user interaction and 0.824
$\pm$ 0.099 after five interactions, outperforming existing methods in both
cases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Practical Gated Recurrent <span class="highlight-title">Transformer</span> Network Incorporating Multiple
  Fusions for Video Denoising 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06603v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06603v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Guo, Seungwon Choi, Jongseong Choi, Lae-Hoon Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art (SOTA) video denoising methods employ multi-frame
simultaneous denoising mechanisms, resulting in significant delays (e.g., 16
frames), making them impractical for real-time cameras. To overcome this
limitation, we propose a multi-fusion gated recurrent Transformer network
(GRTN) that achieves SOTA denoising performance with only a single-frame delay.
Specifically, the spatial denoising module extracts features from the current
frame, while the reset gate selects relevant information from the previous
frame and fuses it with current frame features via the temporal denoising
module. The update gate then further blends this result with the previous frame
features, and the reconstruction module integrates it with the current frame.
To robustly compute attention for noisy features, we propose a residual
simplified Swin Transformer with Euclidean distance (RSSTE) in the spatial and
temporal denoising modules. Comparative objective and subjective results show
that our GRTN achieves denoising performance comparable to SOTA multi-frame
delay networks, with only a single-frame delay.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lightweight Multiscale Feature Fusion Super-Resolution Network Based on
  Two-branch Convolution and <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06590v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06590v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Ke, Liu Yukai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The single image super-resolution(SISR) algorithms under deep learning
currently have two main models, one based on convolutional neural networks and
the other based on Transformer. The former uses the stacking of convolutional
layers with different convolutional kernel sizes to design the model, which
enables the model to better extract the local features of the image; the latter
uses the self-attention mechanism to design the model, which allows the model
to establish long-distance dependencies between image pixel points through the
self-attention mechanism and then better extract the global features of the
image. However, both of the above methods face their problems. Based on this,
this paper proposes a new lightweight multi-scale feature fusion network model
based on two-way complementary convolutional and Transformer, which integrates
the respective features of Transformer and convolutional neural networks
through a two-branch network architecture, to realize the mutual fusion of
global and local information. Meanwhile, considering the partial loss of
information caused by the low-pixel images trained by the deep neural network,
this paper designs a modular connection method of multi-stage feature
supplementation to fuse the feature maps extracted from the shallow stage of
the model with those extracted from the deep stage of the model, to minimize
the loss of the information in the feature images that is beneficial to the
image restoration as much as possible, to facilitate the obtaining of a
higher-quality restored image. The practical results finally show that the
model proposed in this paper is optimal in image recovery performance when
compared with other lightweight models with the same amount of parameters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages,12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seg-HGNN: Unsupervised and Light-Weight Image Segmentation with
  Hyperbolic Graph Neural Networks <span class="chip">BMVC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Debjyoti Mondal, Rahul Mishra, Chandan Pandey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image analysis in the euclidean space through linear hyperspaces is well
studied. However, in the quest for more effective image representations, we
turn to hyperbolic manifolds. They provide a compelling alternative to capture
complex hierarchical relationships in images with remarkably small
dimensionality. To demonstrate hyperbolic embeddings' competence, we introduce
a light-weight hyperbolic graph neural network for image segmentation,
encompassing patch-level features in a very small embedding size. Our solution,
Seg-HGNN, surpasses the current best unsupervised method by 2.5\%, 4\% on
VOC-07, VOC-12 for localization, and by 0.8\%, 1.3\% on CUB-200, ECSSD for
segmentation, respectively. With less than 7.5k trainable parameters, Seg-HGNN
delivers effective and fast ($\approx 2$ images/second) results on very
standard GPUs like the GTX1650. This empirical evaluation presents compelling
evidence of the efficacy and potential of hyperbolic representations for vision
tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>BMVC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Transtreaming: Adaptive Delay-aware <span class="highlight-title">Transformer</span> for Real-time Streaming
  Perception <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06584v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06584v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Zhang, Yufei Cui, Chenchen Fu, Weiwei Wu, Zihao Wang, Yuyang Sun, Xue Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-time object detection is critical for the decision-making process for
many real-world applications, such as collision avoidance and path planning in
autonomous driving. This work presents an innovative real-time streaming
perception method, Transtreaming, which addresses the challenge of real-time
object detection with dynamic computational delay. The core innovation of
Transtreaming lies in its adaptive delay-aware transformer, which can
concurrently predict multiple future frames and select the output that best
matches the real-world present time, compensating for any system-induced
computation delays. The proposed model outperforms the existing
state-of-the-art methods, even in single-frame detection scenarios, by
leveraging a transformer-based methodology. It demonstrates robust performance
across a range of devices, from powerful V100 to modest 2080Ti, achieving the
highest level of perceptual accuracy on all platforms. Unlike most
state-of-the-art methods that struggle to complete computation within a single
frame on less powerful devices, Transtreaming meets the stringent real-time
processing requirements on all kinds of devices. The experimental results
emphasize the system's adaptability and its potential to significantly improve
the safety and reliability for many real-world systems, such as autonomous
driving.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semi-Supervised 3D Object Detection with Chanel Augmentation using
  Transformation Equivariance <span class="chip">ICIP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minju Kang, Taehun Kong, Tae-Kyun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate 3D object detection is crucial for autonomous vehicles and robots to
navigate and interact with the environment safely and effectively. Meanwhile,
the performance of 3D detector relies on the data size and annotation which is
expensive. Consequently, the demand of training with limited labeled data is
growing. We explore a novel teacher-student framework employing channel
augmentation for 3D semi-supervised object detection. The teacher-student SSL
typically adopts a weak augmentation and strong augmentation to teacher and
student, respectively. In this work, we apply multiple channel augmentations to
both networks using the transformation equivariance detector (TED). The TED
allows us to explore different combinations of augmentation on point clouds and
efficiently aggregates multi-channel transformation equivariance features. In
principle, by adopting fixed channel augmentations for the teacher network, the
student can train stably on reliable pseudo-labels. Adopting strong channel
augmentations can enrich the diversity of data, fostering robustness to
transformations and enhancing generalization performance of the student
network. We use SOTA hierarchical supervision as a baseline and adapt its
dual-threshold to TED, which is called channel IoU consistency. We evaluate our
method with KITTI dataset, and achieved a significant performance leap,
surpassing SOTA 3D semi-supervised object detection models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to 2024 IEEE International Conference on Image Processing
  (ICIP)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantifying and Enabling the Interpretability of CLIP-like Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Avinash Madasu, Yossi Gandelsman, Vasudev Lal, Phillip Howard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  CLIP is one of the most popular foundational models and is heavily used for
many vision-language tasks. However, little is known about the inner workings
of CLIP. To bridge this gap we propose a study to quantify the interpretability
in CLIP like models. We conduct this study on six different CLIP models from
OpenAI and OpenCLIP which vary by size, type of pre-training data and patch
size. Our approach begins with using the TEXTSPAN algorithm and in-context
learning to break down individual attention heads into specific properties. We
then evaluate how easily these heads can be interpreted using new metrics which
measure property consistency within heads and property disentanglement across
heads. Our findings reveal that larger CLIP models are generally more
interpretable than their smaller counterparts. To further assist users in
understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a
tool designed for interpretability analysis. CLIP-InterpreT offers five types
of analyses: property-based nearest neighbor search, per-head topic
segmentation, contrastive segmentation, per-head nearest neighbors of an image,
and per-head nearest neighbors of text.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PoseEmbroider: Towards a 3D, Visual, Semantic-aware Human Pose
  Representation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06535v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06535v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ginger Delmas, Philippe Weinzaepfel, Francesc Moreno-Noguer, Grégory Rogez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aligning multiple modalities in a latent space, such as images and texts, has
shown to produce powerful semantic visual representations, fueling tasks like
image captioning, text-to-image generation, or image grounding. In the context
of human-centric vision, albeit CLIP-like representations encode most standard
human poses relatively well (such as standing or sitting), they lack sufficient
acuteness to discern detailed or uncommon ones. Actually, while 3D human poses
have been often associated with images (e.g. to perform pose estimation or
pose-conditioned image generation), or more recently with text (e.g. for
text-to-pose generation), they have seldom been paired with both. In this work,
we combine 3D poses, person's pictures and textual pose descriptions to produce
an enhanced 3D-, visual- and semantic-aware human pose representation. We
introduce a new transformer-based model, trained in a retrieval fashion, which
can take as input any combination of the aforementioned modalities. When
composing modalities, it outperforms a standard multi-modal alignment retrieval
model, making it possible to sort out partial information (e.g. image with the
lower body occluded). We showcase the potential of such an embroidered pose
representation for (1) SMPL regression from image with optional text cue; and
(2) on the task of fine-grained instruction generation, which consists in
generating a text that describes how to move from one 3D pose to another (as a
fitness coach). Unlike prior works, our model can take any kind of input (image
and/or pose) without retraining.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In Flight Boresight Rectification for Lightweight Airborne Pushbroom
  Imaging Spectrometry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06520v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06520v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julien Yuuki Burkhard, Jesse Ray Murray Lahaye, Laurent Valentin Jospin, Jan Skaloud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hyperspectral cameras have recently been miniaturized for operation on
lightweight airborne platforms such as UAV or small aircraft. Unlike frame
cameras (RGB or Multispectral), many hyperspectral sensors use a linear array
or 'push-broom' scanning design. This design presents significant challenges
for image rectification and the calibration of the intrinsic and extrinsic
camera parameters. Typically, methods employed to address such tasks rely on a
precise GPS/INS estimate of the airborne platform trajectory and a detailed
terrain model. However, inaccuracies in the trajectory or surface model
information can introduce systematic errors and complicate geometric modeling
which ultimately degrade the quality of the rectification. To overcome these
challenges, we propose a method for tie point extraction and camera calibration
for 'push-broom' hyperspectral sensors using only the raw spectral imagery and
raw, possibly low quality, GPS/INS trajectory. We demonstrate that our approach
allows for the automatic calibration of airborne systems with hyperspectral
cameras, outperforms other state-of-the-art automatic rectification methods and
reaches an accuracy on par with manual calibration methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aligning Machine and Human Visual Representations across Abstraction
  Levels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Muttenthaler, Klaus Greff, Frieda Born, Bernhard Spitzer, Simon Kornblith, Michael C. Mozer, Klaus-Robert Müller, Thomas Unterthiner, Andrew K. Lampinen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks have achieved success across a wide range of
applications, including as models of human behavior in vision tasks. However,
neural network training and human learning differ in fundamental ways, and
neural networks often fail to generalize as robustly as humans do, raising
questions regarding the similarity of their underlying representations. What is
missing for modern learning systems to exhibit more human-like behavior? We
highlight a key misalignment between vision models and humans: whereas human
conceptual knowledge is hierarchically organized from fine- to coarse-scale
distinctions, model representations do not accurately capture all these levels
of abstraction. To address this misalignment, we first train a teacher model to
imitate human judgments, then transfer human-like structure from its
representations into pretrained state-of-the-art vision foundation models.
These human-aligned models more accurately approximate human behavior and
uncertainty across a wide range of similarity tasks, including a new dataset of
human judgments spanning multiple levels of semantic abstractions. They also
perform better on a diverse set of machine learning tasks, increasing
generalization and out-of-distribution robustness. Thus, infusing neural
networks with additional human knowledge yields a best-of-both-worlds
representation that is both more consistent with human cognition and more
practically useful, thus paving the way toward more robust, interpretable, and
human-like artificial intelligence systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>51 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Laplacian Operator for 3D Point Clouds <span class="chip">SIGGRAPH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06506v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06506v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Pang, Zhongtian Zheng, Yilong Li, Guoping Wang, Peng-Shuai Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The discrete Laplacian operator holds a crucial role in 3D geometry
processing, yet it is still challenging to define it on point clouds. Previous
works mainly focused on constructing a local triangulation around each point to
approximate the underlying manifold for defining the Laplacian operator, which
may not be robust or accurate. In contrast, we simply use the K-nearest
neighbors (KNN) graph constructed from the input point cloud and learn the
Laplacian operator on the KNN graph with graph neural networks (GNNs). However,
the ground-truth Laplacian operator is defined on a manifold mesh with a
different connectivity from the KNN graph and thus cannot be directly used for
training. To train the GNN, we propose a novel training scheme by imitating the
behavior of the ground-truth Laplacian operator on a set of probe functions so
that the learned Laplacian operator behaves similarly to the ground-truth
Laplacian operator. We train our network on a subset of ShapeNet and evaluate
it across a variety of point clouds. Compared with previous methods, our method
reduces the error by an order of magnitude and excels in handling sparse point
clouds with thin structures or sharp features. Our method also demonstrates a
strong generalization ability to unseen shapes. With our learned Laplacian
operator, we further apply a series of Laplacian-based geometry processing
algorithms directly to point clouds and achieve accurate results, enabling many
exciting possibilities for geometry processing on point clouds. The code and
trained models are available at https://github.com/IntelligentGeometry/NeLo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SIGGRAPH Asia 2024 (Journal Track)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating Hallucination in Visual-Language Models via Re-Balancing
  Contrastive Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06485v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06485v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Liang, Jiayuan Yu, Lianrui Mu, Jiedong Zhuang, Jiaqi Hu, Yuchen Yang, Jiangnan Ye, Lu Lu, Jian Chen, Haoji Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although Visual-Language Models (VLMs) have shown impressive capabilities in
tasks like visual question answering and image captioning, they still struggle
with hallucinations. Analysis of attention distribution in these models shows
that VLMs tend to processing textual tokens rather than visual tokens. This
imbalance of attention distribution causes VLMs to favor textual knowledge in
the case of multimodal knowledge conflicts, resulting in differences from the
image information. In this paper, we propose Re-Balancing Contrastive Decoding
(RBD) method, which employs textual and visual branches to recalibrate
attention distribution in VLMs. Specifically, the textual branch injects image
noise to stimulate the model's dependency on text, thereby reducing textual
bias. Concurrently, the visual branch focuses on the selection of significant
tokens, refining the attention mechanism to highlight the primary subject. This
dual-branch strategy enables the RBD method to diminish textual bias while
enhancing visual information. Experimental results demonstrate that our method,
RBD, outperforms the existing methods by the CHAIR and POPE metrics, mitigate
hallucinations without reducing the model's general capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PRCV</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-scale Cycle Tracking in Dynamic Planar Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06476v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06476v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Farhan Rasheed, Abrar Naseer, Emma Nilsson, Talha Bin Masood, Ingrid Hotz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a nested tracking framework for analyzing cycles in 2D
force networks within granular materials. These materials are composed of
interacting particles, whose interactions are described by a force network.
Understanding the cycles within these networks at various scales and their
evolution under external loads is crucial, as they significantly contribute to
the mechanical and kinematic properties of the system. Our approach involves
computing a cycle hierarchy by partitioning the 2D domain into segments bounded
by cycles in the force network. We can adapt concepts from nested tracking
graphs originally developed for merge trees by leveraging the duality between
this partitioning and the cycles. We demonstrate the effectiveness of our
method on two force networks derived from experiments with photoelastic disks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>TopoInVis 2024, 11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Weakly-supervised Camera Localization by Ground-to-satellite Image
  Registration <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06471v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06471v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujiao Shi, Hongdong Li, Akhil Perincherry, Ankit Vora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ground-to-satellite image matching/retrieval was initially proposed for
city-scale ground camera localization. This work addresses the problem of
improving camera pose accuracy by ground-to-satellite image matching after a
coarse location and orientation have been obtained, either from the city-scale
retrieval or from consumer-level GPS and compass sensors. Existing
learning-based methods for solving this task require accurate GPS labels of
ground images for network training. However, obtaining such accurate GPS labels
is difficult, often requiring an expensive {\color{black}Real Time Kinematics
(RTK)} setup and suffering from signal occlusion, multi-path signal
disruptions, \etc. To alleviate this issue, this paper proposes a weakly
supervised learning strategy for ground-to-satellite image registration when
only noisy pose labels for ground images are available for network training. It
derives positive and negative satellite images for each ground image and
leverages contrastive learning to learn feature representations for ground and
satellite images useful for translation estimation. We also propose a
self-supervision strategy for cross-view image relative rotation estimation,
which trains the network by creating pseudo query and reference image pairs.
Experimental results show that our weakly supervised learning strategy achieves
the best performance on cross-area evaluation compared to recent
state-of-the-art methods that are reliant on accurate pose labels for
supervision.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Continual Domain Incremental Learning for Privacy-aware Digital
  Pathology <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06455v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06455v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pratibha Kumari, Daniel Reisenbüchler, Lucas Luttner, Nadine S. Schaadt, Friedrich Feuerhake, Dorit Merhof
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, there has been remarkable progress in the field of digital
pathology, driven by the ability to model complex tissue patterns using
advanced deep-learning algorithms. However, the robustness of these models is
often severely compromised in the presence of data shifts (e.g., different
stains, organs, centers, etc.). Alternatively, continual learning (CL)
techniques aim to reduce the forgetting of past data when learning new data
with distributional shift conditions. Specifically, rehearsal-based CL
techniques, which store some past data in a buffer and then replay it with new
data, have proven effective in medical image analysis tasks. However, privacy
concerns arise as these approaches store past data, prompting the development
of our novel Generative Latent Replay-based CL (GLRCL) approach. GLRCL captures
the previous distribution through Gaussian Mixture Models instead of storing
past samples, which are then utilized to generate features and perform latent
replay with new data. We systematically evaluate our proposed framework under
different shift conditions in histopathology data, including stain and organ
shift. Our approach significantly outperforms popular buffer-free CL approaches
and performs similarly to rehearsal-based CL approaches that require large
buffers causing serious privacy violations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in MICCAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Generative Interactive Environments By Trained Agent
  Exploration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06445v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06445v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naser Kazemi, Nedko Savov, Danda Paudel, Luc Van Gool
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Distillation via Query Selection for Detection <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06443v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06443v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Liu, Luting Wang, Zongheng Tang, Yue Liao, Yifan Sun, Lijun Zhang, Si Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers have revolutionized the object detection landscape by
introducing DETRs, acclaimed for their simplicity and efficacy. Despite their
advantages, the substantial size of these models poses significant challenges
for practical deployment, particularly in resource-constrained environments.
This paper addresses the challenge of compressing DETR by leveraging knowledge
distillation, a technique that holds promise for maintaining model performance
while reducing size. A critical aspect of DETRs' performance is their reliance
on queries to interpret object representations accurately. Traditional
distillation methods often focus exclusively on positive queries, identified
through bipartite matching, neglecting the rich information present in
hard-negative queries. Our visual analysis indicates that hard-negative
queries, focusing on foreground elements, are crucial for enhancing
distillation outcomes. To this end, we introduce a novel Group Query Selection
strategy, which diverges from traditional query selection in DETR distillation
by segmenting queries based on their Generalized Intersection over Union (GIoU)
with ground truth objects, thereby uncovering valuable hard-negative queries
for distillation. Furthermore, we present the Knowledge Distillation via Query
Selection for DETR (QSKD) framework, which incorporates Attention-Guided
Feature Distillation (AGFD) and Local Alignment Prediction Distillation (LAPD).
These components optimize the distillation process by focusing on the most
informative aspects of the teacher model's intermediate features and output.
Our comprehensive experimental evaluation of the MS-COCO dataset demonstrates
the effectiveness of our approach, significantly improving average precision
(AP) across various DETR architectures without incurring substantial
computational costs. Specifically, the AP of Conditional DETR ResNet-18
increased from 35.8 to 39.9.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Prompt</span>2Fashion: An automatically generated fashion <span class="highlight-title">dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06442v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06442v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgia Argyro, Angeliki Dimitriou, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the rapid evolution and increasing efficacy of language and vision
generative models, there remains a lack of comprehensive datasets that bridge
the gap between personalized fashion needs and AI-driven design, limiting the
potential for truly inclusive and customized fashion solutions. In this work,
we leverage generative models to automatically construct a fashion image
dataset tailored to various occasions, styles, and body types as instructed by
users. We use different Large Language Models (LLMs) and prompting strategies
to offer personalized outfits of high aesthetic quality, detail, and relevance
to both expert and non-expert users' requirements, as demonstrated by
qualitative analysis. Up until now the evaluation of the generated outfits has
been conducted by non-expert human subjects. Despite the provided fine-grained
insights on the quality and relevance of generation, we extend the discussion
on the importance of expert knowledge for the evaluation of artistic
AI-generated datasets such as this one. Our dataset is publicly available on
GitHub at https://github.com/georgiarg/Prompt2Fashion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Likelihood Ratio-Based Approach to Segmenting Unknown Objects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06424v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06424v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nazir Nayal, Youssef Shoeb, Fatma Güney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Addressing the Out-of-Distribution (OoD) segmentation task is a prerequisite
for perception systems operating in an open-world environment. Large
foundational models are frequently used in downstream tasks, however, their
potential for OoD remains mostly unexplored. We seek to leverage a large
foundational model to achieve robust representation. Outlier supervision is a
widely used strategy for improving OoD detection of the existing segmentation
networks. However, current approaches for outlier supervision involve
retraining parts of the original network, which is typically disruptive to the
model's learned feature representation. Furthermore, retraining becomes
infeasible in the case of large foundational models. Our goal is to retrain for
outlier segmentation without compromising the strong representation space of
the foundational model. To this end, we propose an adaptive, lightweight
unknown estimation module (UEM) for outlier supervision that significantly
enhances the OoD segmentation performance without affecting the learned feature
representation of the original network. UEM learns a distribution for outliers
and a generic distribution for known classes. Using the learned distributions,
we propose a likelihood-ratio-based outlier scoring function that fuses the
confidence of UEM with that of the pixel-wise segmentation inlier network to
detect unknown objects. We also propose an objective to optimize this score
directly. Our approach achieves a new state-of-the-art across multiple
datasets, outperforming the previous best method by 5.74% average precision
points while having a lower false-positive rate. Importantly, strong inlier
performance remains unaffected.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 2 figures, and 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unrevealed Threats: A Comprehensive Study of the Adversarial Robustness
  of Underwater Image Enhancement Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06420v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06420v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyu Zhai, Zhibo He, Xiaofeng Cong, Junming Hou, Jie Gui, Jian Wei You, Xin Gong, James Tin-Yau Kwok, Yuan Yan Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning-based methods for underwater image enhancement (UWIE) have undergone
extensive exploration. However, learning-based models are usually vulnerable to
adversarial examples so as the UWIE models. To the best of our knowledge, there
is no comprehensive study on the adversarial robustness of UWIE models, which
indicates that UWIE models are potentially under the threat of adversarial
attacks. In this paper, we propose a general adversarial attack protocol. We
make a first attempt to conduct adversarial attacks on five well-designed UWIE
models on three common underwater image benchmark datasets. Considering the
scattering and absorption of light in the underwater environment, there exists
a strong correlation between color correction and underwater image enhancement.
On the basis of that, we also design two effective UWIE-oriented adversarial
attack methods Pixel Attack and Color Shift Attack targeting different color
spaces. The results show that five models exhibit varying degrees of
vulnerability to adversarial attacks and well-designed small perturbations on
degraded images are capable of preventing UWIE models from generating enhanced
results. Further, we conduct adversarial training on these models and
successfully mitigated the effectiveness of adversarial attacks. In summary, we
reveal the adversarial vulnerability of UWIE models and propose a new
evaluation dimension of UWIE models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sources of Uncertainty in 3D Scene Reconstruction <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06407v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06407v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcus Klasson, Riccardo Mereu, Juho Kannala, Arno Solin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The process of 3D scene reconstruction can be affected by numerous
uncertainty sources in real-world scenes. While Neural Radiance Fields (NeRFs)
and 3D Gaussian Splatting (GS) achieve high-fidelity rendering, they lack
built-in mechanisms to directly address or quantify uncertainties arising from
the presence of noise, occlusions, confounding outliers, and imprecise camera
pose inputs. In this paper, we introduce a taxonomy that categorizes different
sources of uncertainty inherent in these methods. Moreover, we extend NeRF- and
GS-based methods with uncertainty estimation techniques, including learning
uncertainty outputs and ensembles, and perform an empirical study to assess
their ability to capture the sensitivity of the reconstruction. Our study
highlights the need for addressing various uncertainty aspects when designing
NeRF/GS-based methods for uncertainty-aware 3D reconstruction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in ECCV 2024 Workshop Proceedings. Project page at
  https://aaltoml.github.io/uncertainty-nerf-gs/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AMNS: Attention-Weighted Selective Mask and Noise Label Suppression for
  Text-to-Image Person Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06385v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06385v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Runqing Zhang, Xue Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image person retrieval aims to retrieve images of person given
textual descriptions, and most methods implicitly assume that the training
image-text pairs are correctly aligned, but in practice, under-correlated and
false-correlated problems arise for image-text pairs due to poor image quality
and mislabeling. Meanwhile, the random masking augmentation strategy may
incorrectly discard semantic content resulting in the problem of generating
noisy pairings between image lexical elements and text descriptions. To solve
these two problems, we propose a new noise label suppression method and
alleviate the problem generated by random mask through an attention-weighted
selective mask strategy. In the proposed noise label suppression method, the
effect of noise labels is suppressed by preventing the model from being
overconfident by considering the inverse KL scatter loss, which is combined
with the weight adjustment focus loss to further improve the model's
recognition ability on difficult samples. On the other hand, Attention-Weighted
Selective Mask processes the raw image through the EMA version of the image
encoder, retaining some of the tokens with strong semantic associations with
the corresponding text descriptions in order to extract better features.
Numerous experiments validate the effectiveness of our approach in terms of
dealing with noisy problems. The code will be available soon at
https://github.com/RunQing715/AMNS.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Cross-Font Image Retrieval Network for Recognizing Undeciphered Oracle
  Bone Inscriptions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhicong Wu, Qifeng Su, Ke Gu, Xiaodong Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Oracle Bone Inscription (OBI) is the earliest mature writing system known in
China to date, which represents a crucial stage in the development of
hieroglyphs. Nevertheless, the substantial quantity of undeciphered OBI
characters continues to pose a persistent challenge for scholars, while
conventional methods of ancient script research are both time-consuming and
labor-intensive. In this paper, we propose a cross-font image retrieval network
(CFIRN) to decipher OBI characters by establishing associations between OBI
characters and other script forms, simulating the interpretive behavior of
paleography scholars. Concretely, our network employs a siamese framework to
extract deep features from character images of various fonts, fully exploring
structure clues with different resolution by designed multiscale feature
integration (MFI) module and multiscale refinement classifier (MRC). Extensive
experiments on three challenging cross-font image retrieval datasets
demonstrate that, given undeciphered OBI characters, our CFIRN can effectively
achieve accurate matches with characters from other gallery fonts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distilling Generative-Discriminative Representations for Very
  Low-Resolution Face Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junzheng Zhang, Weijia Guo, Bochao Liu, Ruixin Shi, Yong Li, Shiming Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Very low-resolution face recognition is challenging due to the serious loss
of informative facial details in resolution degradation. In this paper, we
propose a generative-discriminative representation distillation approach that
combines generative representation with cross-resolution aligned knowledge
distillation. This approach facilitates very low-resolution face recognition by
jointly distilling generative and discriminative models via two distillation
modules. Firstly, the generative representation distillation takes the encoder
of a diffusion model pretrained for face super-resolution as the generative
teacher to supervise the learning of the student backbone via feature
regression, and then freezes the student backbone. After that, the
discriminative representation distillation further considers a pretrained face
recognizer as the discriminative teacher to supervise the learning of the
student head via cross-resolution relational contrastive distillation. In this
way, the general backbone representation can be transformed into discriminative
head representation, leading to a robust and discriminative student model for
very low-resolution face recognition. Our approach improves the recovery of the
missing details in very low-resolution faces and achieves better knowledge
transfer. Extensive experiments on face datasets demonstrate that our approach
enhances the recognition accuracy of very low-resolution faces, showcasing its
effectiveness and adaptability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Texture-AD: An Anomaly Detection <span class="highlight-title">Dataset</span> and Benchmark for Real
  Algorithm Development 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianwu Lei, Bohan Wang, Silin Chen, Shurong Cao, Ningmu Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anomaly detection is a crucial process in industrial manufacturing and has
made significant advancements recently. However, there is a large variance
between the data used in the development and the data collected by the
production environment. Therefore, we present the Texture-AD benchmark based on
representative texture-based anomaly detection to evaluate the effectiveness of
unsupervised anomaly detection algorithms in real-world applications. This
dataset includes images of 15 different cloth, 14 semiconductor wafers and 10
metal plates acquired under different optical schemes. In addition, it includes
more than 10 different types of defects produced during real manufacturing
processes, such as scratches, wrinkles, color variations and point defects,
which are often more difficult to detect than existing datasets. All anomalous
areas are provided with pixel-level annotations to facilitate comprehensive
evaluation using anomaly detection models. Specifically, to adapt to diverse
products in automated pipelines, we present a new evaluation method and results
of baseline algorithms. The experimental results show that Texture-AD is a
difficult challenge for state-of-the-art algorithms. To our knowledge,
Texture-AD is the first dataset to be devoted to evaluating industrial defect
detection algorithms in the real world. The dataset is available at
https://XXX.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffQRCoder: Diffusion-based Aesthetic QR Code Generation with Scanning
  Robustness Guided Iterative Refinement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06355v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06355v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia-Wei Liao, Winston Wang, Tzu-Sian Wang, Li-Xuan Peng, Ju-Hsuan Weng, Cheng-Fu Chou, Jun-Cheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the success of Diffusion Models for image generation, the technologies
also have revolutionized the aesthetic Quick Response (QR) code generation.
Despite significant improvements in visual attractiveness for the beautified
codes, their scannabilities are usually sacrificed and thus hinder their
practical uses in real-world scenarios. To address this issue, we propose a
novel Diffusion-based QR Code generator (DiffQRCoder) to effectively craft both
scannable and visually pleasing QR codes. The proposed approach introduces
Scanning-Robust Perceptual Guidance (SRPG), a new diffusion guidance for
Diffusion Models to guarantee the generated aesthetic codes to obey the
ground-truth QR codes while maintaining their attractiveness during the
denoising process. Additionally, we present another post-processing technique,
Scanning Robust Manifold Projected Gradient Descent (SR-MPGD), to further
enhance their scanning robustness through iterative latent space optimization.
With extensive experiments, the results demonstrate that our approach not only
outperforms other compared methods in Scanning Success Rate (SSR) with better
or comparable CLIP aesthetic score (CLIP-aes.) but also significantly improves
the SSR of the ControlNet-only approach from 60% to 99%. The subjective
evaluation indicates that our approach achieves promising visual attractiveness
to users as well. Finally, even with different scanning angles and the most
rigorous error tolerance settings, our approach robustly achieves over 95% SSR,
demonstrating its capability for real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Weather Image Restoration via Histogram-Based <span class="highlight-title">Transformer</span> Feature
  Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Wen, Anyu Lai, Bo Qian, Hao Wang, Wuzhen Shi, Wenming Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Currently, the mainstream restoration tasks under adverse weather conditions
have predominantly focused on single-weather scenarios. However, in reality,
multiple weather conditions always coexist and their degree of mixing is
usually unknown. Under such complex and diverse weather conditions,
single-weather restoration models struggle to meet practical demands. This is
particularly critical in fields such as autonomous driving, where there is an
urgent need for a model capable of effectively handling mixed weather
conditions and enhancing image quality in an automated manner. In this paper,
we propose a Task Sequence Generator module that, in conjunction with the Task
Intra-patch Block, effectively extracts task-specific features embedded in
degraded images. The Task Intra-patch Block introduces an external learnable
sequence that aids the network in capturing task-specific information.
Additionally, we employ a histogram-based transformer module as the backbone of
our network, enabling the capture of both global and local dynamic range
features. Our proposed model achieves state-of-the-art performance on public
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2409.03249</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SDF-Net: A Hybrid Detection Network for Mediastinal Lymph Node Detection
  on Contrast CT Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiuli Xiong, Lanzhuju Mei, Jiameng Liu, Dinggang Shen, Zhong Xue, Xiaohuan Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate lymph node detection and quantification are crucial for cancer
diagnosis and staging on contrast-enhanced CT images, as they impact treatment
planning and prognosis. However, detecting lymph nodes in the mediastinal area
poses challenges due to their low contrast, irregular shapes and dispersed
distribution. In this paper, we propose a Swin-Det Fusion Network (SDF-Net) to
effectively detect lymph nodes. SDF-Net integrates features from both
segmentation and detection to enhance the detection capability of lymph nodes
with various shapes and sizes. Specifically, an auto-fusion module is designed
to merge the feature maps of segmentation and detection networks at different
levels. To facilitate effective learning without mask annotations, we introduce
a shape-adaptive Gaussian kernel to represent lymph node in the training stage
and provide more anatomical information for effective learning. Comparative
results demonstrate promising performance in addressing the complex lymph node
detection problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ G3PT: Unleash the power of Autoregressive Modeling in 3D Generation via
  Cross-scale Querying <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06322v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06322v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinzhi Zhang, Feng Xiong, Mu Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autoregressive transformers have revolutionized generative models in language
processing and shown substantial promise in image and video generation.
However, these models face significant challenges when extended to 3D
generation tasks due to their reliance on next-token prediction to learn token
sequences, which is incompatible with the unordered nature of 3D data. Instead
of imposing an artificial order on 3D data, in this paper, we introduce G3PT, a
scalable coarse-to-fine 3D generative model utilizing a cross-scale querying
transformer. The key is to map point-based 3D data into discrete tokens with
different levels of detail, naturally establishing a sequential relationship
between different levels suitable for autoregressive modeling. Additionally,
the cross-scale querying transformer connects tokens globally across different
levels of detail without requiring an ordered sequence. Benefiting from this
approach, G3PT features a versatile 3D generation pipeline that effortlessly
supports diverse conditional structures, enabling the generation of 3D shapes
from various types of conditions. Extensive experiments demonstrate that G3PT
achieves superior generation quality and generalization ability compared to
previous 3D generation methods. Most importantly, for the first time in 3D
generation, scaling up G3PT reveals distinct power-law scaling behaviors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seam Carving as Feature Pooling in CNN 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06311v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06311v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Imrul Jubair
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work investigates the potential of seam carving as a feature pooling
technique within Convolutional Neural Networks (CNNs) for image classification
tasks. We propose replacing the traditional max pooling layer with a seam
carving operation. Our experiments on the Caltech-UCSD Birds 200-2011 dataset
demonstrate that the seam carving-based CNN achieves better performance
compared to the model utilizing max pooling, based on metrics such as accuracy,
precision, recall, and F1-score. We further analyze the behavior of both
approaches through feature map visualizations, suggesting that seam carving
might preserve more structural information during the pooling process.
Additionally, we discuss the limitations of our approach and propose potential
future directions for research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PPMamba: A Pyramid Pooling Local Auxiliary SSM-Based Model for Remote
  Sensing Image Semantic Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yin Hu, Xianping Ma, Jialu Sui, Man-On Pun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic segmentation is a vital task in the field of remote sensing (RS).
However, conventional convolutional neural network (CNN) and transformer-based
models face limitations in capturing long-range dependencies or are often
computationally intensive. Recently, an advanced state space model (SSM),
namely Mamba, was introduced, offering linear computational complexity while
effectively establishing long-distance dependencies. Despite their advantages,
Mamba-based methods encounter challenges in preserving local semantic
information. To cope with these challenges, this paper proposes a novel network
called Pyramid Pooling Mamba (PPMamba), which integrates CNN and Mamba for RS
semantic segmentation tasks. The core structure of PPMamba, the Pyramid
Pooling-State Space Model (PP-SSM) block, combines a local auxiliary mechanism
with an omnidirectional state space model (OSS) that selectively scans feature
maps from eight directions, capturing comprehensive feature information.
Additionally, the auxiliary mechanism includes pyramid-shaped convolutional
branches designed to extract features at multiple scales. Extensive experiments
on two widely-used datasets, ISPRS Vaihingen and LoveDA Urban, demonstrate that
PPMamba achieves competitive performance compared to state-of-the-art models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ High-Performance Few-Shot Segmentation with Foundation Models: An
  Empirical Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06305v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06305v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijie Chang, Lihe Zhang, Huchuan Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing few-shot segmentation (FSS) methods mainly focus on designing novel
support-query matching and self-matching mechanisms to exploit implicit
knowledge in pre-trained backbones. However, the performance of these methods
is often constrained by models pre-trained on classification tasks. The
exploration of what types of pre-trained models can provide more beneficial
implicit knowledge for FSS remains limited. In this paper, inspired by the
representation consistency of foundational computer vision models, we develop a
FSS framework based on foundation models. To be specific, we propose a simple
approach to extract implicit knowledge from foundation models to construct
coarse correspondence and introduce a lightweight decoder to refine coarse
correspondence for fine-grained segmentation. We systematically summarize the
performance of various foundation models on FSS and discover that the implicit
knowledge within some of these models is more beneficial for FSS than models
pre-trained on classification tasks. Extensive experiments on two widely used
datasets demonstrate the effectiveness of our approach in leveraging the
implicit knowledge of foundation models. Notably, the combination of DINOv2 and
DFN exceeds previous state-of-the-art methods by 17.5% on COCO-20i. Code is
available at https://github.com/DUT-CSJ/FoundationFSS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Attribute-Enriched <span class="highlight-title">Dataset</span> and Auto-Annotated Pipeline for Open
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06300v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06300v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengfei Qi, Yifei Zhang, Wenqiang Li, Youwen Hu, Kunlong Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting objects of interest through language often presents challenges,
particularly with objects that are uncommon or complex to describe, due to
perceptual discrepancies between automated models and human annotators. These
challenges highlight the need for comprehensive datasets that go beyond
standard object labels by incorporating detailed attribute descriptions. To
address this need, we introduce the Objects365-Attr dataset, an extension of
the existing Objects365 dataset, distinguished by its attribute annotations.
This dataset reduces inconsistencies in object detection by integrating a broad
spectrum of attributes, including color, material, state, texture and tone. It
contains an extensive collection of 5.6M object-level attribute descriptions,
meticulously annotated across 1.4M bounding boxes. Additionally, to validate
the dataset's effectiveness, we conduct a rigorous evaluation of YOLO-World at
different scales, measuring their detection performance and demonstrating the
dataset's contribution to advancing object detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Long Video Understanding via Hierarchical Event-Based Memory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06299v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06299v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dingxin Cheng, Mingda Li, Jingyu Liu, Yongxin Guo, Bin Jiang, Qingbin Liu, Xi Chen, Bo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, integrating visual foundation models into large language models
(LLMs) to form video understanding systems has attracted widespread attention.
Most of the existing models compress diverse semantic information within the
whole video and feed it into LLMs for content comprehension. While this method
excels in short video understanding, it may result in a blend of multiple event
information in long videos due to coarse compression, which causes information
redundancy. Consequently, the semantics of key events might be obscured within
the vast information that hinders the model's understanding capabilities. To
address this issue, we propose a Hierarchical Event-based Memory-enhanced LLM
(HEM-LLM) for better understanding of long videos. Firstly, we design a novel
adaptive sequence segmentation scheme to divide multiple events within long
videos. In this way, we can perform individual memory modeling for each event
to establish intra-event contextual connections, thereby reducing information
redundancy. Secondly, while modeling current event, we compress and inject the
information of the previous event to enhance the long-term inter-event
dependencies in videos. Finally, we perform extensive experiments on various
video understanding tasks and the results show that our model achieves
state-of-the-art performances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EntAugment: Entropy-Driven Adaptive Data Augmentation Framework for
  Image Classification <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06290v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06290v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Suorong Yang, Furao Shen, Jian Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data augmentation (DA) has been widely used to improve the generalization of
deep neural networks. While existing DA methods have proven effective, they
often rely on augmentation operations with random magnitudes to each sample.
However, this approach can inadvertently introduce noise, induce distribution
shifts, and increase the risk of overfitting. In this paper, we propose
EntAugment, a tuning-free and adaptive DA framework. Unlike previous work,
EntAugment dynamically assesses and adjusts the augmentation magnitudes for
each sample during training, leveraging insights into both the inherent
complexities of training samples and the evolving status of deep models.
Specifically, in EntAugment, the magnitudes are determined by the information
entropy derived from the probability distribution obtained by applying the
softmax function to the model's output. In addition, to further enhance the
efficacy of EntAugment, we introduce a novel entropy regularization term,
EntLoss, which complements the EntAugment approach. Theoretical analysis
further demonstrates that EntLoss, compared to traditional cross-entropy loss,
achieves closer alignment between the model distributions and underlying
dataset distributions. Moreover, EntAugment and EntLoss can be utilized
separately or jointly. We conduct extensive experiments across multiple image
classification tasks and network architectures with thorough comparisons of
existing DA methods. Importantly, the proposed methods outperform others
without introducing any auxiliary models or noticeable extra computational
costs, highlighting both effectiveness and efficiency. Code is available at
https://github.com/Jackbrocp/EntAugment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context Enhancement with Reconstruction as Sequence for Unified
  Unsupervised Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06285v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06285v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui-Yue Yang, Hui Chen, Lihao Liu, Zijia Lin, Kai Chen, Liejun Wang, Jungong Han, Guiguang Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised anomaly detection (AD) aims to train robust detection models
using only normal samples, while can generalize well to unseen anomalies.
Recent research focuses on a unified unsupervised AD setting in which only one
model is trained for all classes, i.e., n-class-one-model paradigm.
Feature-reconstruction-based methods achieve state-of-the-art performance in
this scenario. However, existing methods often suffer from a lack of sufficient
contextual awareness, thereby compromising the quality of the reconstruction.
To address this issue, we introduce a novel Reconstruction as Sequence (RAS)
method, which enhances the contextual correspondence during feature
reconstruction from a sequence modeling perspective. In particular, based on
the transformer technique, we integrate a specialized RASFormer block into RAS.
This block enables the capture of spatial relationships among different image
regions and enhances sequential dependencies throughout the reconstruction
process. By incorporating the RASFormer block, our RAS method achieves superior
contextual awareness capabilities, leading to remarkable performance.
Experimental results show that our RAS significantly outperforms competing
methods, well demonstrating the effectiveness and superiority of our method.
Our code is available at https://github.com/Nothingtolose9979/RAS.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Robust Uncertainty-Aware Incomplete Multi-View Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mulin Chen, Haojian Huang, Qiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Handling incomplete data in multi-view classification is challenging,
especially when traditional imputation methods introduce biases that compromise
uncertainty estimation. Existing Evidential Deep Learning (EDL) based
approaches attempt to address these issues, but they often struggle with
conflicting evidence due to the limitations of the Dempster-Shafer combination
rule, leading to unreliable decisions. To address these challenges, we propose
the Alternating Progressive Learning Network (APLN), specifically designed to
enhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates
bias from corrupted observed data by first applying coarse imputation, followed
by mapping the data to a latent space. In this latent space, we progressively
learn an evidence distribution aligned with the target domain, incorporating
uncertainty considerations through EDL. Additionally, we introduce a
conflict-aware Dempster-Shafer combination rule (DSCR) to better handle
conflicting evidence. By sampling from the learned distribution, we optimize
the latent representations of missing views, reducing bias and enhancing
decision-making robustness. Extensive experiments demonstrate that APLN,
combined with DSCR, significantly outperforms traditional methods, particularly
in environments characterized by high uncertainty and conflicting evidence,
establishing it as a promising solution for incomplete multi-view
classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work: 9 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mahalanobis k-NN: A Statistical Lens for Robust Point-Cloud
  Registrations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06267v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06267v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejas Anvekar, Shivanand Venkanna Sheshappanavar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we discuss Mahalanobis k-NN: a statistical lens designed to
address the challenges of feature matching in learning-based point cloud
registration when confronted with an arbitrary density of point clouds, either
in the source or target point cloud. We tackle this by adopting Mahalanobis
k-NN's inherent property to capture the distribution of the local neighborhood
and surficial geometry. Our method can be seamlessly integrated into any
local-graph-based point cloud analysis method. In this paper, we focus on two
distinct methodologies: Deep Closest Point (DCP) and Deep Universal Manifold
Embedding (DeepUME). Our extensive benchmarking on the ModelNet40 and Faust
datasets highlights the efficacy of the proposed method in point cloud
registration tasks. Moreover, we establish for the first time that the features
acquired through point cloud registration inherently can possess discriminative
capabilities. This is evident by a substantial improvement of about 20\% in the
average accuracy observed in the point cloud few-shot classification task
benchmarked on ModelNet40 and ScanObjectNN. The code is publicly available at
https://github.com/TejasAnvekar/Mahalanobis-k-NN
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ALSS-YOLO: An Adaptive Lightweight Channel Split and Shuffling Network
  for TIR Wildlife Detection in UAV Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06259v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06259v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ang He, Xiaobo Li, Ximei Wu, Chengyue Su, Jing Chen, Sheng Xu, Xiaobin Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unmanned aerial vehicles (UAVs) equipped with thermal infrared (TIR) cameras
play a crucial role in combating nocturnal wildlife poaching. However, TIR
images often face challenges such as jitter, and wildlife overlap,
necessitating UAVs to possess the capability to identify blurred and
overlapping small targets. Current traditional lightweight networks deployed on
UAVs struggle to extract features from blurry small targets. To address this
issue, we developed ALSS-YOLO, an efficient and lightweight detector optimized
for TIR aerial images. Firstly, we propose a novel Adaptive Lightweight Channel
Split and Shuffling (ALSS) module. This module employs an adaptive channel
split strategy to optimize feature extraction and integrates a channel
shuffling mechanism to enhance information exchange between channels. This
improves the extraction of blurry features, crucial for handling jitter-induced
blur and overlapping targets. Secondly, we developed a Lightweight Coordinate
Attention (LCA) module that employs adaptive pooling and grouped convolution to
integrate feature information across dimensions. This module ensures
lightweight operation while maintaining high detection precision and robustness
against jitter and target overlap. Additionally, we developed a single-channel
focus module to aggregate the width and height information of each channel into
four-dimensional channel fusion, which improves the feature representation
efficiency of infrared images. Finally, we modify the localization loss
function to emphasize the loss value associated with small objects to improve
localization accuracy. Extensive experiments on the BIRDSAI and ISOD TIR UAV
wildlife datasets show that ALSS-YOLO achieves state-of-the-art performance,
Our code is openly available at
https://github.com/helloworlder8/computer_vision.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Test-Time Certifiable Self-Supervision to Bridge the Sim2Real Gap in
  Event-Based Satellite Pose Estimation <span class="chip">IROS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohsi Jawaid, Rajat Talak, Yasir Latif, Luca Carlone, Tat-Jun Chin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning plays a critical role in vision-based satellite pose
estimation. However, the scarcity of real data from the space environment means
that deep models need to be trained using synthetic data, which raises the
Sim2Real domain gap problem. A major cause of the Sim2Real gap are novel
lighting conditions encountered during test time. Event sensors have been shown
to provide some robustness against lighting variations in vision-based pose
estimation. However, challenging lighting conditions due to strong directional
light can still cause undesirable effects in the output of commercial
off-the-shelf event sensors, such as noisy/spurious events and inhomogeneous
event densities on the object. Such effects are non-trivial to simulate in
software, thus leading to Sim2Real gap in the event domain. To close the
Sim2Real gap in event-based satellite pose estimation, the paper proposes a
test-time self-supervision scheme with a certifier module. Self-supervision is
enabled by an optimisation routine that aligns a dense point cloud of the
predicted satellite pose with the event data to attempt to rectify the
inaccurately estimated pose. The certifier attempts to verify the corrected
pose, and only certified test-time inputs are backpropagated via implicit
differentiation to refine the predicted landmarks, thus improving the pose
estimates and closing the Sim2Real gap. Results show that the our method
outperforms established test-time adaptation schemes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted for publication at IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS 2024). Copyright may be
  transferred without notice, after which this version may no longer be
  accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recurrent Neural Networks for Still Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06235v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06235v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Dmitri,  Lvov, Yair Smadar, Ran Bezen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we explore the application of Recurrent Neural Network (RNN)
for still images. Typically, Convolutional Neural Networks (CNNs) are the
prevalent method applied for this type of data, and more recently, transformers
have gained popularity, although they often require large models. Unlike these
methods, RNNs are generally associated with processing sequences over time
rather than single images. We argue that RNNs can effectively handle still
images by interpreting the pixels as a sequence. This approach could be
particularly advantageous for compact models designed for embedded systems,
where resources are limited. Additionally, we introduce a novel RNN design
tailored for two-dimensional inputs, such as images, and a custom version of
BiDirectional RNN (BiRNN) that is more memory-efficient than traditional
implementations. In our research, we have tested these layers in Convolutional
Recurrent Neural Networks (CRNNs), predominantly composed of Conv2D layers,
with RNN layers at or close to the end. Experiments on the COCO and CIFAR100
datasets show better results, particularly for small networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Latent Implicit 3D Shape Model for Multiple Levels of Detail 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06231v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06231v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benoit Guillard, Marc Habermann, Christian Theobalt, Pascal Fua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit neural representations map a shape-specific latent code and a 3D
coordinate to its corresponding signed distance (SDF) value. However, this
approach only offers a single level of detail. Emulating low levels of detail
can be achieved with shallow networks, but the generated shapes are typically
not smooth. Alternatively, some network designs offer multiple levels of
detail, but are limited to overfitting a single object.
  To address this, we propose a new shape modeling approach, which enables
multiple levels of detail and guarantees a smooth surface at each level. At the
core, we introduce a novel latent conditioning for a multiscale and
bandwith-limited neural architecture. This results in a deep parameterization
of multiple shapes, where early layers quickly output approximated SDF values.
This allows to balance speed and accuracy within a single network and enhance
the efficiency of implicit scene rendering. We demonstrate that by limiting the
bandwidth of the network, we can maintain smooth surfaces across all levels of
detail. At finer levels, reconstruction quality is on par with the state of the
art models, which are limited to a single level of detail.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in GCPR 2024 proceedings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIP-GAF: A MLLM-annotated Benchmark for Most Important Person
  Localization and Group Context Understanding <span class="chip">WACV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06224v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06224v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Surbhi Madan, Shreya Ghosh, Lownish Rai Sookha, M. A. Ganaie, Ramanathan Subramanian, Abhinav Dhall, Tom Gedeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the Most Important Person (MIP) in any social event setup is a
challenging problem mainly due to contextual complexity and scarcity of labeled
data. Moreover, the causality aspects of MIP estimation are quite subjective
and diverse. To this end, we aim to address the problem by annotating a
large-scale `in-the-wild' dataset for identifying human perceptions about the
`Most Important Person (MIP)' in an image. The paper provides a thorough
description of our proposed Multimodal Large Language Model (MLLM) based data
annotation strategy, and a thorough data quality analysis. Further, we perform
a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art
MIP localization methods, indicating a significant drop in performance compared
to existing datasets. The performance drop shows that the existing MIP
localization algorithms must be more robust with respect to `in-the-wild'
situations. We believe the proposed dataset will play a vital role in building
the next-generation social situation understanding methods. The code and data
is available at https://github.com/surbhimadan92/MIP-GAF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at WACV 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CerviXpert: A Multi-Structural Convolutional Neural Network for
  Predicting Cervix Type and Cervical Cell Abnormalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rashik Shahriar Akash, Radiful Islam, S. M. Saiful Islam Badhon, K. S. M. Tozammel Hossain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cervical cancer affects millions of women worldwide and has a significantly
higher survival rate when diagnosed early. Pap smears and cervical biopsies are
vital screening tools for detecting such cancer. However, the success of these
screening processes depends on the skills of cytologists. A recent trend in
diagnostic cytology is to apply machine-learning-based models to classify
cancer using cell images. These automated models have been shown to perform
just as well as, or even better than, expert cytologists. Some notable methods
for classifying cervix cancers include ResNet50, VGG16, MobileNetV2, and
InceptionV3, based on deep convolutional neural networks (CNN). However, these
methods are computationally expensive. We present CerviXpert, a
multi-structural Convolutional Neural Network, to identify cervix cancer. We
perform extensive experiments on a publicly available dataset, SiPaKMeD, to
show the efficacy of our method. CerviXpert presents a promising solution for
efficient cervical cancer screening and diagnosis by striking a balance between
accuracy and practical feasibility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Denoising: A Powerful Building-Block for Imaging, Inverse Problems, and
  Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peyman Milanfar, Mauricio Delbracio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Denoising, the process of reducing random fluctuations in a signal to
emphasize essential patterns, has been a fundamental problem of interest since
the dawn of modern scientific inquiry. Recent denoising techniques,
particularly in imaging, have achieved remarkable success, nearing theoretical
limits by some measures. Yet, despite tens of thousands of research papers, the
wide-ranging applications of denoising beyond noise removal have not been fully
recognized. This is partly due to the vast and diverse literature, making a
clear overview challenging.
  This paper aims to address this gap. We present a comprehensive perspective
on denoisers, their structure, and desired properties. We emphasize the
increasing importance of denoising and showcase its evolution into an essential
building block for complex tasks in imaging, inverse problems, and machine
learning. Despite its long history, the community continues to uncover
unexpected and groundbreaking uses for denoising, further solidifying its place
as a cornerstone of scientific and engineering practice.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DACAT: Dual-stream Adaptive Clip-aware Time Modeling for Robust Online
  Surgical Phase Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06217v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06217v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixiang Yang, Qiang Li, Zhiwei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surgical phase recognition has become a crucial requirement in laparoscopic
surgery, enabling various clinical applications like surgical risk forecasting.
Current methods typically identify the surgical phase using individual
frame-wise embeddings as the fundamental unit for time modeling. However, this
approach is overly sensitive to current observations, often resulting in
discontinuous and erroneous predictions within a complete surgical phase. In
this paper, we propose DACAT, a novel dual-stream model that adaptively learns
clip-aware context information to enhance the temporal relationship. In one
stream, DACAT pretrains a frame encoder, caching all historical frame-wise
features. In the other stream, DACAT fine-tunes a new frame encoder to extract
the frame-wise feature at the current moment. Additionally, a max clip-response
read-out (Max-R) module is introduced to bridge the two streams by using the
current frame-wise feature to adaptively fetch the most relevant past clip from
the feature cache. The clip-aware context feature is then encoded via
cross-attention between the current frame and its fetched adaptive clip, and
further utilized to enhance the time modeling for accurate online surgical
phase recognition. The benchmark results on three public datasets, i.e.,
Cholec80, M2CAI16, and AutoLaparo, demonstrate the superiority of our proposed
DACAT over existing state-of-the-art methods, with improvements in Jaccard
scores of at least 4.5%, 4.6%, and 2.7%, respectively. Our code and models have
been released at https://github.com/kk42yy/DACAT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Generalizable Scene Change Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06214v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06214v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaewoo Kim, Uehwan Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene Change Detection (SCD) is vital for applications such as visual
surveillance and mobile robotics. However, current SCD methods exhibit a bias
to the temporal order of training datasets and limited performance on unseen
domains; coventional SCD benchmarks are not able to evaluate generalization or
temporal consistency. To tackle these limitations, we introduce a Generalizable
Scene Change Detection Framework (GeSCF) in this work. The proposed GeSCF
leverages localized semantics of a foundation model without any re-training or
fine-tuning -- for generalization over unseen domains. Specifically, we design
an adaptive thresholding of the similarity distribution derived from facets of
the pre-trained foundation model to generate initial pseudo-change mask. We
further utilize Segment Anything Model's (SAM) class-agnostic masks to refine
pseudo-masks. Moreover, our proposed framework maintains commutative operations
in all settings to ensure complete temporal consistency. Finally, we define new
metrics, evaluation dataset, and evaluation protocol for Generalizable Scene
Change Detection (GeSCD). Extensive experiments demonstrate that GeSCF excels
across diverse and challenging environments -- establishing a new benchmark for
SCD performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ INTRA: Interaction Relationship-aware Weakly Supervised Affordance
  Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06210v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06210v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ji Ha Jang, Hoigi Seo, Se Young Chun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Affordance denotes the potential interactions inherent in objects. The
perception of affordance can enable intelligent agents to navigate and interact
with new environments efficiently. Weakly supervised affordance grounding
teaches agents the concept of affordance without costly pixel-level
annotations, but with exocentric images. Although recent advances in weakly
supervised affordance grounding yielded promising results, there remain
challenges including the requirement for paired exocentric and egocentric image
dataset, and the complexity in grounding diverse affordances for a single
object. To address them, we propose INTeraction Relationship-aware weakly
supervised Affordance grounding (INTRA). Unlike prior arts, INTRA recasts this
problem as representation learning to identify unique features of interactions
through contrastive learning with exocentric images only, eliminating the need
for paired datasets. Moreover, we leverage vision-language model embeddings for
performing affordance grounding flexibly with any text, designing
text-conditioned affordance map generation to reflect interaction relationship
for contrastive learning and enhancing robustness with our text synonym
augmentation. Our method outperformed prior arts on diverse datasets such as
AGD20K, IIT-AFF, CAD and UMD. Additionally, experimental results demonstrate
that our method has remarkable domain scalability for synthesized images /
illustrations and is capable of performing affordance grounding for novel
interactions and objects.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AgileIR: Memory-Efficient Group Shifted Windows Attention for Agile
  Image Restoration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06206v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06206v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongyi Cai, Mohammad Mahdinur Rahman, Mohammad Shahid Akhtar, Jie Li, Jingyu Wu, Zhili Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image Transformers show a magnificent success in Image Restoration tasks.
Nevertheless, most of transformer-based models are strictly bounded by
exorbitant memory occupancy. Our goal is to reduce the memory consumption of
Swin Transformer and at the same time speed up the model during training
process. Thus, we introduce AgileIR, group shifted attention mechanism along
with window attention, which sparsely simplifies the model in architecture. We
propose Group Shifted Window Attention (GSWA) to decompose Shift Window
Multi-head Self Attention (SW-MSA) and Window Multi-head Self Attention (W-MSA)
into groups across their attention heads, contributing to shrinking memory
usage in back propagation. In addition to that, we keep shifted window masking
and its shifted learnable biases during training, in order to induce the model
interacting across windows within the channel. We also re-allocate projection
parameters to accelerate attention matrix calculation, which we found a
negligible decrease in performance. As a result of experiment, compared with
our baseline SwinIR and other efficient quantization models, AgileIR keeps the
performance still at 32.20 dB on Set5 evaluation dataset, exceeding other
methods with tailor-made efficient methods and saves over 50% memory while a
large batch size is employed.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RealisDance: Equip controllable character animation with realistic hands 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06202v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06202v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingkai Zhou, Benzhi Wang, Weihua Chen, Jingqi Bai, Dongyang Li, Aixi Zhang, Hao Xu, Mingyang Yang, Fan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable character animation is an emerging task that generates character
videos controlled by pose sequences from given character images. Although
character consistency has made significant progress via reference UNet, another
crucial factor, pose control, has not been well studied by existing methods
yet, resulting in several issues: 1) The generation may fail when the input
pose sequence is corrupted. 2) The hands generated using the DWPose sequence
are blurry and unrealistic. 3) The generated video will be shaky if the pose
sequence is not smooth enough. In this paper, we present RealisDance to handle
all the above issues. RealisDance adaptively leverages three types of poses,
avoiding failed generation caused by corrupted pose sequences. Among these pose
types, HaMeR provides accurate 3D and depth information of hands, enabling
RealisDance to generate realistic hands even for complex gestures. Besides
using temporal attention in the main UNet, RealisDance also inserts temporal
attention into the pose guidance network, smoothing the video from the pose
condition aspect. Moreover, we introduce pose shuffle augmentation during
training to further improve generation robustness and video smoothness.
Qualitative experiments demonstrate the superiority of RealisDance over other
existing methods, especially in hand quality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep kernel representations of latent space features for low-dose PET-MR
  imaging robust to variable dose reduction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06198v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06198v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cameron Dennis Pain, Yasmeen George, Alex Fornito, Gary Egan, Zhaolin Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-dose positron emission tomography (PET) image reconstruction methods have
potential to significantly improve PET as an imaging modality. Deep learning
provides a promising means of incorporating prior information into the image
reconstruction problem to produce quantitatively accurate images from
compromised signal. Deep learning-based methods for low-dose PET are generally
poorly conditioned and perform unreliably on images with features not present
in the training distribution. We present a method which explicitly models deep
latent space features using a robust kernel representation, providing robust
performance on previously unseen dose reduction factors. Additional constraints
on the information content of deep latent features allow for tuning
in-distribution accuracy and generalisability. Tests with out-of-distribution
dose reduction factors ranging from $\times 10$ to $\times 1000$ and with both
paired and unpaired MR, demonstrate significantly improved performance relative
to conventional deep-learning methods trained using the same data.
Code:https://github.com/cameronPain
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 15 figures, 4 tables, Submitted to IEEE Transactions on
  Medical Imaging</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UdeerLID+: Integrating LiDAR, Image, and Relative Depth with
  Semi-Supervised 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06197v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06197v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Ni, Xin Zhan, Tao Luo, Wenbin Liu, Zhan Shi, JunBo Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Road segmentation is a critical task for autonomous driving systems,
requiring accurate and robust methods to classify road surfaces from various
environmental data. Our work introduces an innovative approach that integrates
LiDAR point cloud data, visual image, and relative depth maps derived from
images. The integration of multiple data sources in road segmentation presents
both opportunities and challenges. One of the primary challenges is the
scarcity of large-scale, accurately labeled datasets that are necessary for
training robust deep learning models. To address this, we have developed the
[UdeerLID+] framework under a semi-supervised learning paradigm. Experiments
results on KITTI datasets validate the superior performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MyGo: Consistent and Controllable Multi-View Driving Video Generation
  with Camera Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06189v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06189v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yining Yao, Xi Guo, Chenjing Ding, Wei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality driving video generation is crucial for providing training data
for autonomous driving models. However, current generative models rarely focus
on enhancing camera motion control under multi-view tasks, which is essential
for driving video generation. Therefore, we propose MyGo, an end-to-end
framework for video generation, introducing motion of onboard cameras as
conditions to make progress in camera controllability and multi-view
consistency. MyGo employs additional plug-in modules to inject camera
parameters into the pre-trained video diffusion model, which retains the
extensive knowledge of the pre-trained model as much as possible. Furthermore,
we use epipolar constraints and neighbor view information during the generation
process of each view to enhance spatial-temporal consistency. Experimental
results show that MyGo has achieved state-of-the-art results in both general
camera-controlled video generation and multi-view driving video generation
tasks, which lays the foundation for more accurate environment simulation in
autonomous driving. Project page:
\href{https://metadrivescape.github.io/papers_project/MyGo/page.html}{metadrivescape.github.io/papers\_project/MyGo/page.html}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bottleneck-based Encoder-decoder ARchitecture (BEAR) for Learning
  Unbiased Consumer-to-Consumer Image Representations <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06187v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06187v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pablo Rivas, Gisela Bichler, Tomas Cerny, Laurie Giddens, Stacie Petter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unbiased representation learning is still an object of study under specific
applications and contexts. Novel architectures are usually crafted to resolve
particular problems using mixtures of fundamental pieces. This paper presents
different image feature extraction mechanisms that work together with residual
connections to encode perceptual image information in an autoencoder
configuration. We use image data that aims to support a larger research agenda
dealing with issues regarding criminal activity in consumer-to-consumer online
platforms. Preliminary results suggest that the proposed architecture can learn
rich spaces using ours and other image datasets resolving important challenges
that are identified.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2022 LXAI Workshop at the 39th International Conference on Machine
  Learning (ICML), Baltimore, Maryland</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EDADepth: Enhanced Data Augmentation for Monocular Depth Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06183v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06183v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nischal Khanal, Shivanand Venkanna Sheshappanavar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to their text-to-image synthesis feature, diffusion models have recently
seen a rise in visual perception tasks, such as depth estimation. The lack of
good-quality datasets makes the extraction of a fine-grain semantic context
challenging for the diffusion models. The semantic context with fewer details
further worsens the process of creating effective text embeddings that will be
used as input for diffusion models. In this paper, we propose a novel EDADepth,
an enhanced data augmentation method to estimate monocular depth without using
additional training data. We use Swin2SR, a super-resolution model, to enhance
the quality of input images. We employ the BEiT pre-trained semantic
segmentation model for better extraction of text embeddings. We introduce
BLIP-2 tokenizer to generate tokens from these text embeddings. The novelty of
our approach is the introduction of Swin2SR, the BEiT model, and the BLIP-2
tokenizer in the diffusion-based pipeline for the monocular depth estimation.
Our model achieves state-of-the-art results (SOTA) on the {\delta}3 metric on
NYUv2 and KITTI datasets. It also achieves results comparable to those of the
SOTA models in the RMSE and REL metrics. Finally, we also show improvements in
the visualization of the estimated depth compared to the SOTA diffusion-based
monocular depth estimation models. Code:
https://github.com/edadepthmde/EDADepth_ICMLA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Loss Distillation via Gradient Matching for Point Cloud Completion with
  Weighted Chamfer Distance <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06171v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06171v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fangzhou Lin, Haotian Liu, Haoying Zhou, Songlin Hou, Kazunori D Yamada, Gregory S. Fischer, Yanhua Li, Haichong K. Zhang, Ziming Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D point clouds enhanced the robot's ability to perceive the geometrical
information of the environments, making it possible for many downstream tasks
such as grasp pose detection and scene understanding. The performance of these
tasks, though, heavily relies on the quality of data input, as incomplete can
lead to poor results and failure cases. Recent training loss functions designed
for deep learning-based point cloud completion, such as Chamfer distance (CD)
and its variants (\eg HyperCD ), imply a good gradient weighting scheme can
significantly boost performance. However, these CD-based loss functions usually
require data-related parameter tuning, which can be time-consuming for
data-extensive tasks. To address this issue, we aim to find a family of
weighted training losses ({\em weighted CD}) that requires no parameter tuning.
To this end, we propose a search scheme, {\em Loss Distillation via Gradient
Matching}, to find good candidate loss functions by mimicking the learning
behavior in backpropagation between HyperCD and weighted CD. Once this is done,
we propose a novel bilevel optimization formula to train the backbone network
based on the weighted CD loss. We observe that: (1) with proper weighted
functions, the weighted CD can always achieve similar performance to HyperCD,
and (2) the Landau weighted CD, namely {\em Landau CD}, can outperform HyperCD
for point cloud completion and lead to new state-of-the-art results on several
benchmark datasets. {\it Our demo code is available at
\url{https://github.com/Zhang-VISLab/IROS2024-LossDistillationWeightedCD}.}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures, 7 tables, this paper was accepted to IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting <span class="highlight-title">Prompt</span> <span class="highlight-title">Pretrain</span>ing of Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06166v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06166v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenyuan Chen, Lingfeng Yang, Shuo Chen, Zhaowei Chen, Jiajun Liang, Xiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt learning is an effective method to customize Vision-Language Models
(VLMs) for various downstream tasks, involving tuning very few parameters of
input prompt tokens. Recently, prompt pretraining in large-scale dataset (e.g.,
ImageNet-21K) has played a crucial role in prompt learning for universal visual
discrimination. However, we revisit and observe that the limited learnable
prompts could face underfitting risks given the extensive images during prompt
pretraining, simultaneously leading to poor generalization. To address the
above issues, in this paper, we propose a general framework termed Revisiting
Prompt Pretraining (RPP), which targets at improving the fitting and
generalization ability from two aspects: prompt structure and prompt
supervision. For prompt structure, we break the restriction in common practice
where query, key, and value vectors are derived from the shared learnable
prompt token. Instead, we introduce unshared individual query, key, and value
learnable prompts, thereby enhancing the model's fitting capacity through
increased parameter diversity. For prompt supervision, we additionally utilize
soft labels derived from zero-shot probability predictions provided by a
pretrained Contrastive Language Image Pretraining (CLIP) teacher model. These
soft labels yield more nuanced and general insights into the inter-class
relationships, thereby endowing the pretraining process with better
generalization ability. RPP produces a more resilient prompt initialization,
enhancing its robust transferability across diverse visual recognition tasks.
Experiments across various benchmarks consistently confirm the state-of-the-art
(SOTA) performance of our pretrained prompts. Codes and models will be made
available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniLearn: Enhancing Dynamic Facial Expression Recognition through
  Unified <span class="highlight-title">Pre-Train</span>ing and Fine-Tuning on Images and Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yin Chen, Jia Li, Yu Zhang, Zhenzhen Hu, Shiguang Shan, Meng Wang, Richang Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamic facial expression recognition (DFER) is essential for understanding
human emotions and behavior. However, conventional DFER methods, which
primarily use dynamic facial data, often underutilize static expression images
and their labels, limiting their performance and robustness. To overcome this,
we introduce UniLearn, a novel unified learning paradigm that integrates static
facial expression recognition (SFER) data to enhance DFER task. UniLearn
employs a dual-modal self-supervised pre-training method, leveraging both
facial expression images and videos to enhance a ViT model's spatiotemporal
representation capability. Then, the pre-trained model is fine-tuned on both
static and dynamic expression datasets using a joint fine-tuning strategy. To
prevent negative transfer during joint fine-tuning, we introduce an innovative
Mixture of Adapter Experts (MoAE) module that enables task-specific knowledge
acquisition and effectively integrates information from both static and dynamic
expression data. Extensive experiments demonstrate UniLearn's effectiveness in
leveraging complementary information from static and dynamic facial data,
leading to more accurate and robust DFER. UniLearn consistently achieves
state-of-the-art performance on FERV39K, MAFW, and DFEW benchmarks, with
weighted average recall (WAR) of 53.65\%, 58.44\%, and 76.68\%, respectively.
The source code and model weights will be publicly available at
\url{https://github.com/MSA-LMC/UniLearn}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Draw an Audio: Leveraging Multi-Instruction for Video-to-Audio Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Yang, Binjie Mao, Zili Wang, Xing Nie, Pengfei Gao, Ying Guo, Cheng Zhen, Pengfei Yan, Shiming Xiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foley is a term commonly used in filmmaking, referring to the addition of
daily sound effects to silent films or videos to enhance the auditory
experience. Video-to-Audio (V2A), as a particular type of automatic foley task,
presents inherent challenges related to audio-visual synchronization. These
challenges encompass maintaining the content consistency between the input
video and the generated audio, as well as the alignment of temporal and
loudness properties within the video. To address these issues, we construct a
controllable video-to-audio synthesis model, termed Draw an Audio, which
supports multiple input instructions through drawn masks and loudness signals.
To ensure content consistency between the synthesized audio and target video,
we introduce the Mask-Attention Module (MAM), which employs masked video
instruction to enable the model to focus on regions of interest. Additionally,
we implement the Time-Loudness Module (TLM), which uses an auxiliary loudness
signal to ensure the synthesis of sound that aligns with the video in both
loudness and temporal dimensions. Furthermore, we have extended a large-scale
V2A dataset, named VGGSound-Caption, by annotating caption prompts. Extensive
experiments on challenging benchmarks across two large-scale V2A datasets
verify Draw an Audio achieves the state-of-the-art. Project page:
https://yannqi.github.io/Draw-an-Audio/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DECOLLAGE: 3D Detailization by Controllable, Localized, and Learned
  Geometry Enhancement <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qimin Chen, Zhiqin Chen, Vladimir G. Kim, Noam Aigerman, Hao Zhang, Siddhartha Chaudhuri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a 3D modeling method which enables end-users to refine or
detailize 3D shapes using machine learning, expanding the capabilities of
AI-assisted 3D content creation. Given a coarse voxel shape (e.g., one produced
with a simple box extrusion tool or via generative modeling), a user can
directly "paint" desired target styles representing compelling geometric
details, from input exemplar shapes, over different regions of the coarse
shape. These regions are then up-sampled into high-resolution geometries which
adhere with the painted styles. To achieve such controllable and localized 3D
detailization, we build on top of a Pyramid GAN by making it masking-aware. We
devise novel structural losses and priors to ensure that our method preserves
both desired coarse structures and fine-grained features even if the painted
styles are borrowed from diverse sources, e.g., different semantic parts and
even different shape categories. Through extensive experiments, we show that
our ability to localize details enables novel interactive creative workflows
and applications. Our experiments further demonstrate that in comparison to
prior techniques built on global detailization, our method generates
structure-preserving, high-resolution stylized geometries with more coherent
shape details and style transitions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024 (poster). Code: https://qiminchen.github.io/decollage/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WonderWorld: Interactive 3D Scene Generation from a Single Image 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09394v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09394v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong-Xing Yu, Haoyi Duan, Charles Herrmann, William T. Freeman, Jiajun Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present WonderWorld, a novel framework for interactive 3D scene generation
that enables users to interactively specify scene contents and layout and see
the created scenes in low latency. The major challenge lies in achieving fast
generation of 3D scenes. Existing scene generation approaches fall short of
speed as they often require (1) progressively generating many views and depth
maps, and (2) time-consuming optimization of the scene geometry
representations. We introduce the Fast Layered Gaussian Surfels (FLAGS) as our
scene representation and an algorithm to generate it from a single view. Our
approach does not need multiple views, and it leverages a geometry-based
initialization that significantly reduces optimization time. Another challenge
is generating coherent geometry that allows all scenes to be connected. We
introduce the guided depth diffusion that allows partial conditioning of depth
estimation. WonderWorld generates connected and diverse 3D scenes in less than
10 seconds on a single A6000 GPU, enabling real-time user interaction and
exploration. We demonstrate the potential of WonderWorld for user-driven
content creation and exploration in virtual environments. We will release full
code and software for reproducibility. Project website:
https://kovenyu.com/WonderWorld/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website: https://kovenyu.com/WonderWorld/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CAMS: Convolution and Attention-Free Mamba-based Cardiac Image
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05786v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05786v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abbas Khan, Muhammad Asad, Martin Benning, Caroline Roney, Gregory Slabaugh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Convolutional Neural Networks (CNNs) and Transformer-based self-attention
models have become the standard for medical image segmentation. This paper
demonstrates that convolution and self-attention, while widely used, are not
the only effective methods for segmentation. Breaking with convention, we
present a Convolution and self-Attention-free Mamba-based semantic Segmentation
Network named CAMS-Net. Specifically, we design Mamba-based Channel Aggregator
and Spatial Aggregator, which are applied independently in each encoder-decoder
stage. The Channel Aggregator extracts information across different channels,
and the Spatial Aggregator learns features across different spatial locations.
We also propose a Linearly Interconnected Factorized Mamba (LIFM) block to
reduce the computational complexity of a Mamba block and to enhance its
decision function by introducing a non-linearity between two factorized Mamba
blocks. Our model outperforms the existing state-of-the-art CNN,
self-attention, and Mamba-based methods on CMR and M&Ms-2 Cardiac segmentation
datasets, showing how this innovative, convolution, and self-attention-free
method can inspire further research beyond CNN and Transformer paradigms,
achieving linear complexity and reducing the number of parameters. Source code
and pre-trained models will be publicly available upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Visual Odometry with Events and Frames <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.09947v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.09947v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roberto Pellerito, Marco Cannici, Daniel Gehrig, Joris Belhadj, Olivier Dubois-Matra, Massimo Casasco, Davide Scaramuzza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual Odometry (VO) is crucial for autonomous robotic navigation, especially
in GPS-denied environments like planetary terrains. To improve robustness,
recent model-based VO systems have begun combining standard and event-based
cameras. While event cameras excel in low-light and high-speed motion, standard
cameras provide dense and easier-to-track features. However, the field of
image- and event-based VO still predominantly relies on model-based methods and
is yet to fully integrate recent image-only advancements leveraging end-to-end
learning-based architectures. Seamlessly integrating the two modalities remains
challenging due to their different nature, one asynchronous, the other not,
limiting the potential for a more effective image- and event-based VO. We
introduce RAMP-VO, the first end-to-end learned image- and event-based VO
system. It leverages novel Recurrent, Asynchronous, and Massively Parallel
(RAMP) encoders capable of fusing asynchronous events with image data,
providing 8x faster inference and 33% more accurate predictions than existing
solutions. Despite being trained only in simulation, RAMP-VO outperforms
previous methods on the newly introduced Apollo and Malapert datasets, and on
existing benchmarks, where it improves image- and event-based methods by 58.8%
and 30.6%, paving the way for robust and asynchronous VO in space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS), 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Robust Single Rotation Averaging Revisited <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.05388v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.05388v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seong Hun Lee, Javier Civera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose a novel method for robust single rotation averaging
that can efficiently handle an extremely large fraction of outliers. Our
approach is to minimize the total truncated least unsquared deviations (TLUD)
cost of geodesic distances. The proposed algorithm consists of three steps:
First, we consider each input rotation as a potential initial solution and
choose the one that yields the least sum of truncated chordal deviations. Next,
we obtain the inlier set using the initial solution and compute its chordal
$L_2$-mean. Finally, starting from this estimate, we iteratively compute the
geodesic $L_1$-mean of the inliers using the Weiszfeld algorithm on $SO(3)$. An
extensive evaluation shows that our method is robust against up to 99% outliers
given a sufficient number of accurate inliers, outperforming the current state
of the art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024 Workshop on Recovering 6D Object Pose (R6D)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Caterpillar: A Pure-MLP Architecture with Shifted-Pillars-Concatenation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.17644v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.17644v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin Sun, Xiaoshuang Shi, Zhiyuan Wang, Kaidi Xu, Heng Tao Shen, Xiaofeng Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling in Computer Vision has evolved to MLPs. Vision MLPs naturally lack
local modeling capability, to which the simplest treatment is combined with
convolutional layers. Convolution, famous for its sliding window scheme, also
suffers from this scheme of redundancy and lower parallel computation. In this
paper, we seek to dispense with the windowing scheme and introduce a more
elaborate and parallelizable method to exploit locality. To this end, we
propose a new MLP module, namely Shifted-Pillars-Concatenation (SPC), that
consists of two steps of processes: (1) Pillars-Shift, which generates four
neighboring maps by shifting the input image along four directions, and (2)
Pillars-Concatenation, which applies linear transformations and concatenation
on the maps to aggregate local features. SPC module offers superior local
modeling power and performance gains, making it a promising alternative to the
convolutional layer. Then, we build a pure-MLP architecture called Caterpillar
by replacing the convolutional layer with the SPC module in a hybrid model of
sMLPNet. Extensive experiments show Caterpillar's excellent performance on both
small-scale and ImageNet-1k classification benchmarks, with remarkable
scalability and transfer capability possessed as well. The code is available at
https://github.com/sunjin19126/Caterpillar.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlocking the Use of Raw Multispectral Earth Observation Imagery for
  Onboard Artificial Intelligence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.11891v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.11891v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriele Meoni, Roberto Del Prete, Federico Serva, Alix De Beussche, Olivier Colin, Nicolas Longépé
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nowadays, there is growing interest in applying Artificial Intelligence (AI)
on board Earth Observation (EO) satellites for time-critical applications, such
as natural disaster response. However, the unavailability of raw satellite data
currently hinders research on lightweight pre-processing techniques and limits
the exploration of end-to-end pipelines, which could offer more efficient and
accurate extraction of insights directly from the source data. To fill this
gap, this work presents a novel methodology to automate the creation of
datasets for the detection of target events (e.g., warm thermal hotspots) or
objects (e.g., vessels) from Sentinel-2 raw data and other multispectral EO
pushbroom raw imagery. The presented approach first processes the raw data by
applying a pipeline consisting of spatial band registration and georeferencing
of the raw data pixels. Then, it detects the target events by leveraging
event-specific state-of-the-art algorithms on the Level-1C products, which are
mosaicked and cropped on the georeferenced correspondent raw granule area. The
detected events are finally re-projected back onto the corresponding raw
images. We apply the proposed methodology to realize THRawS (Thermal Hotspots
in Raw Sentinel-2 data), the first dataset of Sentinel-2 raw data containing
warm thermal hotspots. THRawS includes 1090 samples containing wildfires,
volcanic eruptions, and 33,335 event-free acquisitions to enable thermal
hotspot detection and general classification applications. This dataset and
associated toolkits provide the community with both an immediately useful
resource as well as a framework and methodology acting as a template for future
additions. With this work, we hope to pave the way for research on
energy-efficient pre-processing algorithms and AI-based end-to-end processing
systems on board EO satellites.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 Pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Analysis of Unstructured High-Density Crowded Scenes for Crowd
  Monitoring 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11836v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11836v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Matov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We are interested in developing an automated system for detection of
organized movements in human crowds. Computer vision algorithms can extract
information from videos of crowded scenes and automatically detect and track
groups of individuals undergoing organized motion that represents an anomalous
behavior in the context of conflict aversion. Our system can detect organized
cohorts against the background of randomly moving objects and we can estimate
the number of participants in an organized cohort, the speed and direction of
motion in real time, within three to four video frames, which is less than one
second from the onset of motion captured on a CCTV. We have performed
preliminary analysis in this context in biological cell data containing up to
four thousand objects per frame and will extend this numerically to a
hundred-fold for public safety applications.
  We envisage using the existing infrastructure of video cameras for acquiring
image datasets on-the-fly and deploying an easy-to-use data-driven software
system for parsing of significant events by analyzing image sequences taken
inside and outside of sports stadiums or other public venues. Other prospective
users are organizers of political rallies, civic and wildlife organizations,
security firms, and the military. We will optimize the performance of the
software by implementing a classification method able to distinguish between
activities posing a threat and those not posing a threat.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Implicit Filtering for Learning Neural Signed Distance Functions from 3D
  Point Clouds <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13342v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13342v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengtao Li, Ge Gao, Yudong Liu, Ming Gu, Yu-Shen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural signed distance functions (SDFs) have shown powerful ability in
fitting the shape geometry. However, inferring continuous signed distance
fields from discrete unoriented point clouds still remains a challenge. The
neural network typically fits the shape with a rough surface and omits
fine-grained geometric details such as shape edges and corners. In this paper,
we propose a novel non-linear implicit filter to smooth the implicit field
while preserving high-frequency geometry details. Our novelty lies in that we
can filter the surface (zero level set) by the neighbor input points with
gradients of the signed distance field. By moving the input raw point clouds
along the gradient, our proposed implicit filtering can be extended to non-zero
level sets to keep the promise consistency between different level sets, which
consequently results in a better regularization of the zero level set. We
conduct comprehensive experiments in surface reconstruction from objects and
complex scene point clouds, the numerical and visual comparisons demonstrate
our improvements over the state-of-the-art methods under the widely used
benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024. Project page:
  https://list17.github.io/ImplicitFilter</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SUMix: Mixup with Semantic and Uncertain Information <span class="chip">ECCV2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07805v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07805v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huafeng Qin, Xin Jin, Hongyu Zhu, Hongchao Liao, Mounîm A. El-Yacoubi, Xinbo Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixup data augmentation approaches have been applied for various tasks of
deep learning to improve the generalization ability of deep neural networks.
Some existing approaches CutMix, SaliencyMix, etc. randomly replace a patch in
one image with patches from another to generate the mixed image. Similarly, the
corresponding labels are linearly combined by a fixed ratio $\lambda$ by l. The
objects in two images may be overlapped during the mixing process, so some
semantic information is corrupted in the mixed samples. In this case, the mixed
image does not match the mixed label information. Besides, such a label may
mislead the deep learning model training, which results in poor performance. To
solve this problem, we proposed a novel approach named SUMix to learn the
mixing ratio as well as the uncertainty for the mixed samples during the
training process. First, we design a learnable similarity function to compute
an accurate mix ratio. Second, an approach is investigated as a regularized
term to model the uncertainty of the mixed samples. We conduct experiments on
five image benchmarks, and extensive experimental results imply that our method
is capable of improving the performance of classifiers with different
cutting-based mixup approaches. The source code is available at
https://github.com/JinXins/SUMix.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV2024 [Camera Ready] (19 pages, 7 figures) with the
  source code at https://github.com/JinXins/SUMix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Textured-GS: Gaussian Splatting with Spatially Defined Color and Opacity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09733v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09733v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhentao Huang, Minglun Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce Textured-GS, an innovative method for rendering
Gaussian splatting that incorporates spatially defined color and opacity
variations using Spherical Harmonics (SH). This approach enables each Gaussian
to exhibit a richer representation by accommodating varying colors and
opacities across its surface, significantly enhancing rendering quality
compared to traditional methods. To demonstrate the merits of our approach, we
have adapted the Mini-Splatting architecture to integrate textured Gaussians
without increasing the number of Gaussians. Our experiments across multiple
real-world datasets show that Textured-GS consistently outperforms both the
baseline Mini-Splatting and standard 3DGS in terms of visual fidelity. The
results highlight the potential of Textured-GS to advance Gaussian-based
rendering technologies, promising more efficient and high-quality scene
reconstructions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CathFlow: <span class="highlight-title">Self-Supervised</span> Segmentation of Catheters in Interventional
  Ultrasound Using Optical Flow and <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.14465v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.14465v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Ranne, Liming Kuang, Yordanka Velikova, Nassir Navab, Ferdinando Rodriguez y Baena
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In minimally invasive endovascular procedures, contrast-enhanced angiography
remains the most robust imaging technique. However, it is at the expense of the
patient and clinician's health due to prolonged radiation exposure. As an
alternative, interventional ultrasound has notable benefits such as being
radiation-free, fast to deploy, and having a small footprint in the operating
room. Yet, ultrasound is hard to interpret, and highly prone to artifacts and
noise. Additionally, interventional radiologists must undergo extensive
training before they become qualified to diagnose and treat patients
effectively, leading to a shortage of staff, and a lack of open-source
datasets. In this work, we seek to address both problems by introducing a
self-supervised deep learning architecture to segment catheters in longitudinal
ultrasound images, without demanding any labeled data. The network architecture
builds upon AiAReSeg, a segmentation transformer built with the Attention in
Attention mechanism, and is capable of learning feature changes across time and
space. To facilitate training, we used synthetic ultrasound data based on
physics-driven catheter insertion simulations, and translated the data into a
unique CT-Ultrasound common domain, CACTUSS, to improve the segmentation
performance. We generated ground truth segmentation masks by computing the
optical flow between adjacent frames using FlowNet2, and performed thresholding
to obtain a binary map estimate. Finally, we validated our model on a test
dataset, consisting of unseen synthetic data and images collected from silicon
aorta phantoms, thus demonstrating its potential for applications to clinical
data in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Extending 6D Object Pose Estimators for Stereo Vision <span class="chip">ICPR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05610v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05610v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Pöllabauer, Jan Emrich, Volker Knauthe, Arjan Kuijper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the 6D pose of objects accurately, quickly, and robustly remains a
difficult task. However, recent methods for directly regressing poses from RGB
images using dense features have achieved state-of-the-art results. Stereo
vision, which provides an additional perspective on the object, can help reduce
pose ambiguity and occlusion. Moreover, stereo can directly infer the distance
of an object, while mono-vision requires internalized knowledge of the object's
size. To extend the state-of-the-art in 6D object pose estimation to stereo, we
created a BOP compatible stereo version of the YCB-V dataset. Our method
outperforms state-of-the-art 6D pose estimation algorithms by utilizing stereo
vision and can easily be adopted for other dense feature-based algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4th International Conference on Pattern Recognition and Artificial
  Intelligence (ICPRAI)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TiCoSS: Tightening the Coupling between Semantic Segmentation and Stereo
  Matching within A Joint Learning Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.18038v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.18038v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guanfeng Tang, Zhiyuan Wu, Jiahang Li, Ping Zhong, Xieyuanli Chen, Huiming Lu, Rui Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic segmentation and stereo matching, respectively analogous to the
ventral and dorsal streams in our human brain, are two key components of
autonomous driving perception systems. Addressing these two tasks with separate
networks is no longer the mainstream direction in developing computer vision
algorithms, particularly with the recent advances in large vision models and
embodied artificial intelligence. The trend is shifting towards combining them
within a joint learning framework, especially emphasizing feature sharing
between the two tasks. The major contributions of this study lie in
comprehensively tightening the coupling between semantic segmentation and
stereo matching. Specifically, this study introduces three novelties: (1) a
tightly coupled, gated feature fusion strategy, (2) a hierarchical deep
supervision strategy, and (3) a coupling tightening loss function. The combined
use of these technical contributions results in TiCoSS, a state-of-the-art
joint learning framework that simultaneously tackles semantic segmentation and
stereo matching. Through extensive experiments on the KITTI and vKITTI2
datasets, along with qualitative and quantitative analyses, we validate the
effectiveness of our developed strategies and loss function, and demonstrate
its superior performance compared to prior arts, with a notable increase in
mIoU by over 9%. Our source code will be publicly available at
mias.group/TiCoSS upon publication.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Valeo4Cast: A Modular Approach to End-to-End Forecasting <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.08113v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.08113v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihong Xu, Éloi Zablocki, Alexandre Boulch, Gilles Puy, Mickael Chen, Florent Bartoccioni, Nermin Samet, Oriane Siméoni, Spyros Gidaris, Tuan-Hung Vu, Andrei Bursuc, Eduardo Valle, Renaud Marlet, Matthieu Cord
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motion forecasting is crucial in autonomous driving systems to anticipate the
future trajectories of surrounding agents such as pedestrians, vehicles, and
traffic signals. In end-to-end forecasting, the model must jointly detect and
track from sensor data (cameras or LiDARs) the past trajectories of the
different elements of the scene and predict their future locations. We depart
from the current trend of tackling this task via end-to-end training from
perception to forecasting, and instead use a modular approach. We individually
build and train detection, tracking and forecasting modules. We then only use
consecutive finetuning steps to integrate the modules better and alleviate
compounding errors. We conduct an in-depth study on the finetuning strategies
and it reveals that our simple yet effective approach significantly improves
performance on the end-to-end forecasting benchmark. Consequently, our solution
ranks first in the Argoverse 2 End-to-end Forecasting Challenge, with 63.82
mAPf. We surpass forecasting results by +17.1 points over last year's winner
and by +13.3 points over this year's runner-up. This remarkable performance in
forecasting can be explained by our modular paradigm, which integrates
finetuning strategies and significantly outperforms the end-to-end-trained
counterparts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Winning solution of the Argoverse 2 "Unified Detection, Tracking, and
  Forecasting" challenge; work accepted at Road++ ECCVW 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Image Similarity using An Ensemble of Context-Sensitive Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07951v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07951v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zukang Liao, Min Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image similarity has been extensively studied in computer vision. In recent
years, machine-learned models have shown their ability to encode more semantics
than traditional multivariate metrics. However, in labelling semantic
similarity, assigning a numerical score to a pair of images is impractical,
making the improvement and comparisons on the task difficult. In this work, we
present a more intuitive approach to build and compare image similarity models
based on labelled data in the form of A:R vs B:R, i.e., determining if an image
A is closer to a reference image R than another image B. We address the
challenges of sparse sampling in the image space (R, A, B) and biases in the
models trained with context-based data by using an ensemble model. Our testing
results show that the ensemble model constructed performs ~5% better than the
best individual context-sensitive models. They also performed better than the
models that were directly fine-tuned using mixed imagery data as well as
existing deep embeddings, e.g., CLIP and DINO. This work demonstrates that
context-based labelling and model training can be effective when an appropriate
ensemble approach is used to alleviate the limitation due to sparse sampling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LiDAR-based 4D Occupancy Completion and Forecasting <span class="chip">IROS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11239v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11239v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinhao Liu, Moonjun Gong, Qi Fang, Haoyu Xie, Yiming Li, Hang Zhao, Chen Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scene completion and forecasting are two popular perception problems in
research for mobile agents like autonomous vehicles. Existing approaches treat
the two problems in isolation, resulting in a separate perception of the two
aspects. In this paper, we introduce a novel LiDAR perception task of Occupancy
Completion and Forecasting (OCF) in the context of autonomous driving to unify
these aspects into a cohesive framework. This task requires new algorithms to
address three challenges altogether: (1) sparse-to-dense reconstruction, (2)
partial-to-complete hallucination, and (3) 3D-to-4D prediction. To enable
supervision and evaluation, we curate a large-scale dataset termed OCFBench
from public autonomous driving datasets. We analyze the performance of closely
related existing baseline models and our own ones on our dataset. We envision
that this research will inspire and call for further investigation in this
evolving and crucial area of 4D perception. Our code for data curation and
baseline implementation is available at https://github.com/ai4ce/Occ4cast.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IROS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EMCNet : Graph-Nets for Electron Micrographs Classification <span class="chip">KDD 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03767v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03767v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Characterization of materials via electron micrographs is an important and
challenging task in several materials processing industries. Classification of
electron micrographs is complex due to the high intra-class dissimilarity, high
inter-class similarity, and multi-spatial scales of patterns. However, existing
methods are ineffective in learning complex image patterns. We propose an
effective end-to-end electron micrograph representation learning-based
framework for nanomaterial identification to overcome the challenges. We
demonstrate that our framework outperforms the popular baselines on the
open-source datasets in nanomaterials-based identification tasks. The ablation
studies are reported in great detail to support the efficacy of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 10 figures, Accepted in a ACM SIGKDD 2022 Workshop on
  Machine Learning for Materials</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VITA: Towards Open-Source Interactive Omni Multimodal LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05211v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05211v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Shaoqi Dong, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable multimodal capabilities and interactive experience of GPT-4o
underscore their necessity in practical applications, yet open-source models
rarely excel in both areas. In this paper, we introduce VITA, the first-ever
open-source Multimodal Large Language Model (MLLM) adept at simultaneous
processing and analysis of Video, Image, Text, and Audio modalities, and
meanwhile has an advanced multimodal interactive experience. Starting from
Mixtral 8x7B as a language foundation, we expand its Chinese vocabulary
followed by bilingual instruction tuning. We further endow the language model
with visual and audio capabilities through two-stage multi-task learning of
multimodal alignment and instruction tuning. VITA demonstrates robust
foundational capabilities of multilingual, vision, and audio understanding, as
evidenced by its strong performance across a range of both unimodal and
multimodal benchmarks. Beyond foundational capabilities, we have made
considerable progress in enhancing the natural multimodal human-computer
interaction experience. VITA is the first step for the open-source community to
explore the seamless integration of multimodal understanding and interaction.
While there is still lots of work to be done on VITA to get close to
close-source counterparts, we hope that its role as a pioneer can serve as a
cornerstone for subsequent research. Project Page: https://vita-home.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://vita-home.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PoseScript: Linking 3D Human Poses and Natural Language <span class="chip">ECCV 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.11795v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.11795v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ginger Delmas, Philippe Weinzaepfel, Thomas Lucas, Francesc Moreno-Noguer, Grégory Rogez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural language plays a critical role in many computer vision applications,
such as image captioning, visual question answering, and cross-modal retrieval,
to provide fine-grained semantic information. Unfortunately, while human pose
is key to human understanding, current 3D human pose datasets lack detailed
language descriptions. To address this issue, we have introduced the PoseScript
dataset. This dataset pairs more than six thousand 3D human poses from AMASS
with rich human-annotated descriptions of the body parts and their spatial
relationships. Additionally, to increase the size of the dataset to a scale
that is compatible with data-hungry learning algorithms, we have proposed an
elaborate captioning process that generates automatic synthetic descriptions in
natural language from given 3D keypoints. This process extracts low-level pose
information, known as "posecodes", using a set of simple but generic rules on
the 3D keypoints. These posecodes are then combined into higher level textual
descriptions using syntactic rules. With automatic annotations, the amount of
available data significantly scales up (100k), making it possible to
effectively pretrain deep models for finetuning on human captions. To showcase
the potential of annotated poses, we present three multi-modal learning tasks
that utilize the PoseScript dataset. Firstly, we develop a pipeline that maps
3D poses and textual descriptions into a joint embedding space, allowing for
cross-modal retrieval of relevant poses from large-scale datasets. Secondly, we
establish a baseline for a text-conditioned model generating 3D poses. Thirdly,
we present a learned process for generating pose descriptions. These
applications demonstrate the versatility and usefulness of annotated poses in
various tasks and pave the way for future research in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>TPAMI 2024, extended version of the ECCV 2022 paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shedding More Light on Robust Classifiers under the lens of Energy-based
  Models <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06315v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06315v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mujtaba Hussain Mirza, Maria Rosaria Briglia, Senad Beadini, Iacopo Masi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  By reinterpreting a robust discriminative classifier as Energy-based Model
(EBM), we offer a new take on the dynamics of adversarial training (AT). Our
analysis of the energy landscape during AT reveals that untargeted attacks
generate adversarial images much more in-distribution (lower energy) than the
original data from the point of view of the model. Conversely, we observe the
opposite for targeted attacks. On the ground of our thorough analysis, we
present new theoretical and practical results that show how interpreting AT
energy dynamics unlocks a better understanding: (1) AT dynamic is governed by
three phases and robust overfitting occurs in the third phase with a drastic
divergence between natural and adversarial energies (2) by rewriting the loss
of TRadeoff-inspired Adversarial DEfense via Surrogate-loss minimization
(TRADES) in terms of energies, we show that TRADES implicitly alleviates
overfitting by means of aligning the natural energy with the adversarial one
(3) we empirically show that all recent state-of-the-art robust classifiers are
smoothing the energy landscape and we reconcile a variety of studies about
understanding AT and weighting the loss function under the umbrella of EBMs.
Motivated by rigorous evidence, we propose Weighted Energy Adversarial Training
(WEAT), a novel sample weighting scheme that yields robust accuracy matching
the state-of-the-art on multiple benchmarks such as CIFAR-10 and SVHN and going
beyond in CIFAR-100 and Tiny-ImageNet. We further show that robust classifiers
vary in the intensity and quality of their generative capabilities, and offer a
simple method to push this capability, reaching a remarkable Inception Score
(IS) and FID using a robust classifier without training for generative
modeling. The code to reproduce our results is available at
http://github.com/OmnAI-Lab/Robust-Classifiers-under-the-lens-of-EBM/ .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at European Conference on Computer Vision (ECCV) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02813v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02813v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces MMMU-Pro, a robust version of the Massive
Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark.
MMMU-Pro rigorously assesses multimodal models' true understanding and
reasoning capabilities through a three-step process based on MMMU: (1)
filtering out questions answerable by text-only models, (2) augmenting
candidate options, and (3) introducing a vision-only input setting where
questions are embedded within images. This setting challenges AI to truly "see"
and "read" simultaneously, testing a fundamental human cognitive skill of
seamlessly integrating visual and textual information. Results show that model
performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8%
to 26.9% across models. We explore the impact of OCR prompts and Chain of
Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT
generally improves performance. MMMU-Pro provides a more rigorous evaluation
tool, closely mimicking real-world scenarios and offering valuable directions
for future research in multimodal AI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do LLMs Understand Visual Anomalies? Uncovering LLM's Capabilities in
  Zero-shot Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.09654v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.09654v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Zhu, Shaofeng Cai, Fang Deng, Beng Chin Ooi, Junran Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision-language models (LVLMs) are markedly proficient in deriving
visual representations guided by natural language. Recent explorations have
utilized LVLMs to tackle zero-shot visual anomaly detection (VAD) challenges by
pairing images with textual descriptions indicative of normal and abnormal
conditions, referred to as anomaly prompts. However, existing approaches depend
on static anomaly prompts that are prone to cross-semantic ambiguity, and
prioritize global image-level representations over crucial local pixel-level
image-to-text alignment that is necessary for accurate anomaly localization. In
this paper, we present ALFA, a training-free approach designed to address these
challenges via a unified model. We propose a run-time prompt adaptation
strategy, which first generates informative anomaly prompts to leverage the
capabilities of a large language model (LLM). This strategy is enhanced by a
contextual scoring mechanism for per-image anomaly prompt adaptation and
cross-semantic ambiguity mitigation. We further introduce a novel fine-grained
aligner to fuse local pixel-level semantics for precise anomaly localization,
by projecting the image-text alignment from global to local semantic spaces.
Extensive evaluations on MVTec and VisA datasets confirm ALFA's effectiveness
in harnessing the language potential for zero-shot VAD, achieving significant
PRO improvements of 12.1% on MVTec and 8.9% on VisA compared to
state-of-the-art approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MM'24 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TempSAL -- Uncovering Temporal Information for Deep Saliency Prediction <span class="chip">CVPR 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.02315v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.02315v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bahar Aydemir, Ludo Hoffstetter, Tong Zhang, Mathieu Salzmann, Sabine Süsstrunk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep saliency prediction algorithms complement the object recognition
features, they typically rely on additional information, such as scene context,
semantic relationships, gaze direction, and object dissimilarity. However, none
of these models consider the temporal nature of gaze shifts during image
observation. We introduce a novel saliency prediction model that learns to
output saliency maps in sequential time intervals by exploiting human temporal
attention patterns. Our approach locally modulates the saliency predictions by
combining the learned temporal maps. Our experiments show that our method
outperforms the state-of-the-art models, including a multi-duration saliency
model, on the SALICON benchmark. Our code will be publicly available on GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures, published in CVPR 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Space3D-Bench: Spatial 3D Question Answering Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16662v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16662v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emilia Szymanska, Mihai Dusmanu, Jan-Willem Buurlage, Mahdi Rad, Marc Pollefeys
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Answering questions about the spatial properties of the environment poses
challenges for existing language and vision foundation models due to a lack of
understanding of the 3D world notably in terms of relationships between
objects. To push the field forward, multiple 3D Q&A datasets were proposed
which, overall, provide a variety of questions, but they individually focus on
particular aspects of 3D reasoning or are limited in terms of data modalities.
To address this, we present Space3D-Bench - a collection of 1000 general
spatial questions and answers related to scenes of the Replica dataset which
offers a variety of data modalities: point clouds, posed RGB-D images,
navigation meshes and 3D object detections. To ensure that the questions cover
a wide range of 3D objectives, we propose an indoor spatial questions taxonomy
inspired by geographic information systems and use it to balance the dataset
accordingly. Moreover, we provide an assessment system that grades natural
language responses based on predefined ground-truth answers by leveraging a
Vision Language Model's comprehension of both text and images to compare the
responses with ground-truth textual information or relevant visual data.
Finally, we introduce a baseline called RAG3D-Chat integrating the world
understanding of foundation models with rich context retrieval, achieving an
accuracy of 67% on the proposed dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Question-Answering Dense Video Events 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04388v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04388v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hangyu Qin, Junbin Xiao, Angela Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have shown excellent performance in
question-answering of single-event videos. In this paper, we present
question-answering dense video events, a novel task that requires answering and
grounding the dense-event questions in long videos, thus challenging MLLMs to
faithfully comprehend and reason about multiple events occurring over extended
time periods. To facilitate the study, we construct DeVE-QA - a dataset
featuring 78K questions about 26K events on 10.6K long videos. We then
benchmark and show that existing MLLMs excelling at single-event QA struggle to
perform well in DeVE-QA. For improvement, we propose DeVi, a novel
training-free MLLM approach that highlights a hierarchical captioning module, a
temporal event memory module, and a self-consistency checking module to
respectively detect, contextualize and memorize, and ground dense-events in
long videos for question answering. Extensive experiments show that DeVi is
superior at answering dense-event questions and grounding relevant video
moments. Compared with existing MLLMs, it achieves a remarkable increase of 4.1
percent and 3.7 percent for G(round)QA accuracy on DeVE-QA and NExT-GQA
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Human-Free Automated <span class="highlight-title">Prompt</span>ing for Vision-Language Anomaly Detection:
  <span class="highlight-title">Prompt</span> Optimization with Meta-guiding <span class="highlight-title">Prompt</span> Scheme 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18197v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18197v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pi-Wei Chen, Jerry Chun-Wei Lin, Jia Ji, Feng-Hao Yeh, Zih-Ching Chen, Chao-Chun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained vision-language models (VLMs) are highly adaptable to various
downstream tasks through few-shot learning, making prompt-based anomaly
detection a promising approach. Traditional methods depend on human-crafted
prompts that require prior knowledge of specific anomaly types. Our goal is to
develop a human-free prompt-based anomaly detection framework that optimally
learns prompts through data-driven methods, eliminating the need for human
intervention. The primary challenge in this approach is the lack of anomalous
samples during the training phase. Additionally, the Vision Transformer
(ViT)-based image encoder in VLMs is not ideal for pixel-wise anomaly
segmentation due to a locality feature mismatch between the original image and
the output feature map. To tackle the first challenge, we have developed the
Object-Attention Anomaly Generation Module (OAGM) to synthesize anomaly samples
for training. Furthermore, our Meta-Guiding Prompt-Tuning Scheme (MPTS)
iteratively adjusts the gradient-based optimization direction of learnable
prompts to avoid overfitting to the synthesized anomalies. For the second
challenge, we propose Locality-Aware Attention, which ensures that each local
patch feature attends only to nearby patch features, preserving the locality
features corresponding to their original locations. This framework allows for
the optimal prompt embeddings by searching in the continuous latent space via
backpropagation, free from human semantic constraints. Additionally, the
modified locality-aware attention improves the precision of pixel-wise anomaly
segmentation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nonlinear Unknown Input Observability and Unknown Input Reconstruction:
  The General Analytical Solution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2201.07610v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2201.07610v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Agostino Martinelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Observability is a fundamental structural property of any dynamic system and
describes the possibility of reconstructing the state that characterizes the
system from observing its inputs and outputs. Despite the huge effort made to
study this property and to introduce analytical criteria able to check whether
a dynamic system satisfies this property or not, there is no general analytical
criterion to automatically check the state observability when the dynamics are
also driven by unknown inputs. Here, we introduce the general analytical
solution of this fundamental problem, often called the unknown input
observability problem. This paper provides the general analytical solution of
this problem, namely, it provides the systematic procedure, based on automatic
computation (differentiation and matrix rank determination), that allows us to
automatically check the state observability even in the presence of unknown
inputs (Algorithm 6.1). A first solution of this problem was presented in the
second part of the book: "Observability: A New Theory Based on the Group of
Invariance" [45]. The solution presented by this paper completes the previous
solution in [45]. In particular, the new solution exhaustively accounts for the
systems that do not belong to the category of the systems that are "canonic
with respect to their unknown inputs". The analytical derivations largely
exploit several new concepts and analytical results introduced in [45].
Finally, as a simple consequence of the results here obtained, we also provide
the answer to the problem of unknown input reconstruction which is intimately
related to the problem of state observability. We illustrate the implementation
of the new algorithm by studying the observability properties of a nonlinear
system in the framework of visual-inertial sensor fusion, whose dynamics are
driven by two unknown inputs and one known input.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper was published by the journal of Information Fusion</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Neural Architecture Search based Global-local Vision Mamba for Palm-Vein
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05743v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05743v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huafeng Qin, Yuming Fu, Jing Chen, Mounim A. El-Yacoubi, Xinbo Gao, Feng Xi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the advantages such as high security, high privacy, and liveness
recognition, vein recognition has been received more and more attention in past
years. Recently, deep learning models, e.g., Mamba has shown robust feature
representation with linear computational complexity and successfully applied
for visual tasks. However, vision Manba can capture long-distance feature
dependencies but unfortunately deteriorate local feature details. Besides,
manually designing a Mamba architecture based on human priori knowledge is very
time-consuming and error-prone. In this paper, first, we propose a hybrid
network structure named Global-local Vision Mamba (GLVM), to learn the local
correlations in images explicitly and global dependencies among tokens for vein
feature representation. Secondly, we design a Multi-head Mamba to learn the
dependencies along different directions, so as to improve the feature
representation ability of vision Mamba. Thirdly, to learn the complementary
features, we propose a ConvMamba block consisting of three branches, named
Multi-head Mamba branch (MHMamba), Feature Iteration Unit branch (FIU), and
Convolutional Neural Network (CNN) branch, where the Feature Iteration Unit
branch aims to fuse convolutional local features with Mamba-based global
representations. Finally, a Globallocal Alternate Neural Architecture Search
(GLNAS) method is proposed to search the optimal architecture of GLVM
alternately with the evolutionary algorithm, thereby improving the recognition
performance for vein recognition tasks. We conduct rigorous experiments on
three public palm-vein databases to estimate the performance. The experimental
results demonstrate that the proposed method outperforms the representative
approaches and achieves state-of-the-art recognition accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Active Measurement for Human Mesh Recovery in Close Proximity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.08116v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.08116v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takahiro Maeda, Keisuke Takeshita, Norimichi Ukita, Kazuhito Tanaka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For physical human-robot interactions (pHRI), a robot needs to estimate the
accurate body pose of a target person. However, in these pHRI scenarios, the
robot cannot fully observe the target person's body with equipped cameras
because the target person must be close to the robot for physical interaction.
This close distance leads to severe truncation and occlusions and thus results
in poor accuracy of human pose estimation. For better accuracy in this
challenging environment, we propose an active measurement and sensor fusion
framework of the equipped cameras with touch and ranging sensors such as 2D
LiDAR. Touch and ranging sensor measurements are sparse but reliable and
informative cues for localizing human body parts. In our active measurement
process, camera viewpoints and sensor placements are dynamically optimized to
measure body parts with higher estimation uncertainty, which is closely related
to truncation or occlusion. In our sensor fusion process, assuming that the
measurements of touch and ranging sensors are more reliable than the
camera-based estimations, we fuse the sensor measurements to the camera-based
estimated pose by aligning the estimated pose towards the measured points. Our
proposed method outperformed previous methods on the standard occlusion
benchmark with simulated active measurement. Furthermore, our method reliably
estimated human poses using a real robot, even with practical constraints such
as occlusion by blankets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Robotics and Automation Letters (RA-L)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Scale Denoising in the Feature Space for Low-Light Instance
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18307v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18307v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joanne Lin, Nantheera Anantrasirichai, David Bull
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instance segmentation for low-light imagery remains largely unexplored due to
the challenges imposed by such conditions, for example shot noise due to low
photon count, color distortions and reduced contrast. In this paper, we propose
an end-to-end solution to address this challenging task. Our proposed method
implements weighted non-local blocks (wNLB) in the feature extractor. This
integration enables an inherent denoising process at the feature level. As a
result, our method eliminates the need for aligned ground truth images during
training, thus supporting training on real-world low-light datasets. We
introduce additional learnable weights at each layer in order to enhance the
network's adaptability to real-world noise characteristics, which affect
different feature scales in different ways. Experimental results on several
object detectors show that the proposed method outperforms the pretrained
networks with an Average Precision (AP) improvement of at least +7.6, with the
introduction of wNLB further enhancing AP by upto +1.3.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FrameCorr: Adaptive, Autoencoder-based Neural Compression for Video
  Reconstruction in Resource and Timing Constrained Network Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02453v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02453v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Li, Shehab Sarar Ahmed, Deepak Nair
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing adoption of video processing via Internet of Things (IoT)
devices due to their cost-effectiveness, transmitting captured data to nearby
servers poses challenges due to varying timing constraints and scarcity of
network bandwidth. Existing video compression methods face difficulties in
recovering compressed data when incomplete data is provided. Here, we introduce
FrameCorr, a deep-learning based solution that utilizes previously received
data to predict the missing segments of a frame, enabling the reconstruction of
a frame from partially received data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TrackSSM: A General Motion Predictor by State-Space Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00487v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00487v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Hu, Run Luo, Zelin Liu, Cheng Wang, Wenyu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal motion modeling has always been a key component in multiple object
tracking (MOT) which can ensure smooth trajectory movement and provide accurate
positional information to enhance association precision. However, current
motion models struggle to be both efficient and effective across different
application scenarios. To this end, we propose TrackSSM inspired by the
recently popular state space models (SSM), a unified encoder-decoder motion
framework that uses data-dependent state space model to perform temporal motion
of trajectories. Specifically, we propose Flow-SSM, a module that utilizes the
position and motion information from historical trajectories to guide the
temporal state transition of object bounding boxes. Based on Flow-SSM, we
design a flow decoder. It is composed of a cascaded motion decoding module
employing Flow-SSM, which can use the encoded flow information to complete the
temporal position prediction of trajectories. Additionally, we propose a
Step-by-Step Linear (S$^2$L) training strategy. By performing linear
interpolation between the positions of the object in the previous frame and the
current frame, we construct the pseudo labels of step-by-step linear training,
ensuring that the trajectory flow information can better guide the object
bounding box in completing temporal transitions. TrackSSM utilizes a simple
Mamba-Block to build a motion encoder for historical trajectories, forming a
temporal motion model with an encoder-decoder structure in conjunction with the
flow decoder. TrackSSM is applicable to various tracking scenarios and achieves
excellent tracking performance across multiple benchmarks, further extending
the potential of SSM-like temporal motion models in multi-object tracking
tasks. Code and models are publicly available at
\url{https://github.com/Xavier-Lin/TrackSSM}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diff-INR: Generative Regularization for Electrical Impedance Tomography 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Tong, Junwu Wang, Dong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electrical Impedance Tomography (EIT) is a non-invasive imaging technique
that reconstructs conductivity distributions within a body from boundary
measurements. However, EIT reconstruction is hindered by its ill-posed
nonlinear inverse problem, which complicates accurate results. To tackle this,
we propose Diff-INR, a novel method that combines generative regularization
with Implicit Neural Representations (INR) through a diffusion model. Diff-INR
introduces geometric priors to guide the reconstruction, effectively addressing
the shortcomings of traditional regularization methods. By integrating a
pre-trained diffusion regularizer with INR, our approach achieves
state-of-the-art reconstruction accuracy in both simulation and experimental
data. The method demonstrates robust performance across various mesh densities
and hyperparameter settings, highlighting its flexibility and efficiency. This
advancement represents a significant improvement in managing the ill-posed
nature of EIT. Furthermore, the method's principles are applicable to other
imaging modalities facing similar challenges with ill-posed inverse problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OT-VP: Optimal Transport-guided Visual <span class="highlight-title">Prompt</span>ing for Test-Time
  Adaptation <span class="chip">WACV2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09498v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09498v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunbei Zhang, Akshay Mehra, Jihun Hamm
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Transformers (ViTs) have demonstrated remarkable capabilities in
learning representations, but their performance is compromised when applied to
unseen domains. Previous methods either engage in prompt learning during the
training phase or modify model parameters at test time through entropy
minimization. The former often overlooks unlabeled target data, while the
latter doesn't fully address domain shifts. In this work, our approach, Optimal
Transport-guided Test-Time Visual Prompting (OT-VP), handles these problems by
leveraging prompt learning at test time to align the target and source domains
without accessing the training process or altering pre-trained model
parameters. This method involves learning a universal visual prompt for the
target domain by optimizing the Optimal Transport distance.OT-VP, with only
four learned prompt tokens, exceeds state-of-the-art performance across three
stylistic datasets-PACS, VLCS, OfficeHome, and one corrupted dataset
ImageNet-C. Additionally, OT-VP operates efficiently, both in terms of memory
and computation, and is adaptable for extension to online settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WACV2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Perceptual Assessment and Optimization of HDR Image Rendering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.12877v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.12877v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peibei Cao, Rafal K. Mantiuk, Kede Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High dynamic range (HDR) rendering has the ability to faithfully reproduce
the wide luminance ranges in natural scenes, but how to accurately assess the
rendering quality is relatively underexplored. Existing quality models are
mostly designed for low dynamic range (LDR) images, and do not align well with
human perception of HDR image quality. To fill this gap, we propose a family of
HDR quality metrics, in which the key step is employing a simple inverse
display model to decompose an HDR image into a stack of LDR images with varying
exposures. Subsequently, these decomposed images are assessed through
well-established LDR quality metrics. Our HDR quality models present three
distinct benefits. First, they directly inherit the recent advancements of LDR
quality metrics. Second, they do not rely on human perceptual data of HDR image
quality for re-calibration. Third, they facilitate the alignment and
prioritization of specific luminance ranges for more accurate and detailed
quality assessment. Experimental results show that our HDR quality metrics
consistently outperform existing models in terms of quality assessment on four
HDR image quality datasets and perceptual optimization of HDR novel view
synthesis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training-Free Point Cloud Recognition Based on Geometric and Semantic
  Information Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04760v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04760v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Chen, Di Huang, Zhichao Liao, Xi Cheng, Xinghui Li, Lone Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The trend of employing training-free methods for point cloud recognition is
becoming increasingly popular due to its significant reduction in computational
resources and time costs. However, existing approaches are limited as they
typically extract either geometric or semantic features. To address this
limitation, we are the first to propose a novel training-free method that
integrates both geometric and semantic features. For the geometric branch, we
adopt a non-parametric strategy to extract geometric features. In the semantic
branch, we leverage a model aligned with text features to obtain semantic
features. Additionally, we introduce the GFE module to complement the geometric
information of point clouds and the MFF module to improve performance in
few-shot settings. Experimental results demonstrate that our method outperforms
existing state-of-the-art training-free approaches on mainstream benchmark
datasets, including ModelNet and ScanObiectNN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpikeCLIP: A Contrastive Language-Image <span class="highlight-title">Pretrain</span>ed Spiking Neural
  Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06488v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06488v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianlong Li, Wenhao Liu, Changze Lv, Yufei Gu, Jianhan Xu, Cenyuan Zhang, Muling Wu, Xiaoqing Zheng, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking Neural Networks (SNNs) have emerged as a promising alternative to
conventional Artificial Neural Networks (ANNs), demonstrating comparable
performance in both visual and linguistic tasks while offering the advantage of
improved energy efficiency. Despite these advancements, the integration of
linguistic and visual features into a unified representation through spike
trains poses a significant challenge, and the application of SNNs to multimodal
scenarios remains largely unexplored. This paper presents SpikeCLIP, a novel
framework designed to bridge the modality gap in spike-based computation. Our
approach employs a two-step recipe: an ``alignment pre-training'' to align
features across modalities, followed by a ``dual-loss fine-tuning'' to refine
the model's performance. Extensive experiments reveal that SNNs achieve results
on par with ANNs while substantially reducing energy consumption across various
datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP
maintains robust image classification capabilities, even when dealing with
classes that fall outside predefined categories. This study marks a significant
advancement in the development of energy-efficient and biologically plausible
multimodal learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learned Image Transmission with Hierarchical Variational Autoencoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16340v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16340v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guangyi Zhang, Hanlei Li, Yunlong Cai, Qiyu Hu, Guanding Yu, Runmin Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce an innovative hierarchical joint source-channel
coding (HJSCC) framework for image transmission, utilizing a hierarchical
variational autoencoder (VAE). Our approach leverages a combination of
bottom-up and top-down paths at the transmitter to autoregressively generate
multiple hierarchical representations of the original image. These
representations are then directly mapped to channel symbols for transmission by
the JSCC encoder. We extend this framework to scenarios with a feedback link,
modeling transmission over a noisy channel as a probabilistic sampling process
and deriving a novel generative formulation for JSCC with feedback. Compared
with existing approaches, our proposed HJSCC provides enhanced adaptability by
dynamically adjusting transmission bandwidth, encoding these representations
into varying amounts of channel symbols. Extensive experiments on images of
varying resolutions demonstrate that our proposed model outperforms existing
baselines in rate-distortion performance and maintains robustness against
channel noise. The source code will be made available upon acceptance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Atmospheric Correction Integrated LULC Segmentation Model for
  High-Resolution Satellite Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soham Mukherjee, Yash Dixit, Naman Srivastava, Joel D Joy, Rohan Olikara, Koesha Sinha, Swarup E, Rakshit Ramesh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of fine-scale multispectral imagery with deep learning models
has revolutionized land use and land cover (LULC) classification. However, the
atmospheric effects present in Top-of-Atmosphere sensor measured Digital Number
values must be corrected to retrieve accurate Bottom-of-Atmosphere surface
reflectance for reliable analysis. This study employs look-up-table-based
radiative transfer simulations to estimate the atmospheric path reflectance and
transmittance for atmospherically correcting high-resolution CARTOSAT-3
Multispectral (MX) imagery for several Indian cities. The corrected surface
reflectance data were subsequently used in supervised and semi-supervised
segmentation models, demonstrating stability in multi-class (buildings, roads,
trees and water bodies) LULC segmentation accuracy, particularly in scenarios
with sparsely labelled data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Disentangling Hippocampal Shape Variations: A Study of Neurological
  Disorders Using Mesh Variational Autoencoder with Contrastive Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00785v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00785v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakaria Rabbi, Johannes Kiechle, Christian Beaulieu, Nilanjan Ray, Dana Cobzas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a comprehensive study focused on disentangling
hippocampal shape variations from diffusion tensor imaging (DTI) datasets
within the context of neurological disorders. Leveraging a Graph Variational
Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach
aims to improve interpretability by disentangling two distinct latent variables
corresponding to age and the presence of diseases. In our ablation study, we
investigate a range of VAE architectures and contrastive loss functions,
showcasing the enhanced disentanglement capabilities of our approach. This
evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh
datasets derived from the DTI hippocampal dataset. Our supervised
disentanglement model outperforms several state-of-the-art (SOTA) methods like
attribute and guided VAEs in terms of disentanglement scores. Our model
distinguishes between age groups and disease status in patients with Multiple
Sclerosis (MS) using the hippocampus data. Our Graph VAE with Supervised
Contrastive Learning shows the volume changes of the hippocampus of MS
populations at different ages, and the result is consistent with the current
neuroimaging literature. This research provides valuable insights into the
relationship between neurological disorder and hippocampal shape changes in
different age groups of MS populations using a Graph VAE with Supervised
Contrastive loss.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Length: 25 pages and submitted to the journal: MELBA (Machine
  Learning for Biomedical Imaging)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning a Cross-modality Anomaly Detector for Remote Sensing Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingtao Li, Xinyu Wang, Hengwei Zhao, Liangpei Zhang, Yanfei Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote sensing anomaly detector can find the objects deviating from the
background as potential targets for Earth monitoring. Given the diversity in
earth anomaly types, designing a transferring model with cross-modality
detection ability should be cost-effective and flexible to new earth
observation sources and anomaly types. However, the current anomaly detectors
aim to learn the certain background distribution, the trained model cannot be
transferred to unseen images. Inspired by the fact that the deviation metric
for score ranking is consistent and independent from the image distribution,
this study exploits the learning target conversion from the varying background
distribution to the consistent deviation metric. We theoretically prove that
the large-margin condition in labeled samples ensures the transferring ability
of learned deviation metric. To satisfy this condition, two large margin losses
for pixel-level and feature-level deviation ranking are proposed respectively.
Since the real anomalies are difficult to acquire, anomaly simulation
strategies are designed to compute the model loss. With the large-margin
learning for deviation metric, the trained model achieves cross-modality
detection ability in five modalities including hyperspectral, visible light,
synthetic aperture radar (SAR), infrared and low-light in zero-shot manner.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Journal paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational
  Score Distillation <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.05239v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.05239v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thuan Hoang Nguyen, Anh Tran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their ability to generate high-resolution and diverse images from
text prompts, text-to-image diffusion models often suffer from slow iterative
sampling processes. Model distillation is one of the most effective directions
to accelerate these models. However, previous distillation methods fail to
retain the generation quality while requiring a significant amount of images
for training, either from real data or synthetically generated by the teacher
model. In response to this limitation, we present a novel image-free
distillation scheme named $\textbf{SwiftBrush}$. Drawing inspiration from
text-to-3D synthesis, in which a 3D neural radiance field that aligns with the
input prompt can be obtained from a 2D text-to-image diffusion prior via a
specialized loss without the use of any 3D data ground-truth, our approach
re-purposes that same loss for distilling a pretrained multi-step text-to-image
model to a student network that can generate high-fidelity images with just a
single inference step. In spite of its simplicity, our model stands as one of
the first one-step text-to-image generators that can produce images of
comparable quality to Stable Diffusion without reliance on any training image
data. Remarkably, SwiftBrush achieves an FID score of $\textbf{16.67}$ and a
CLIP score of $\textbf{0.29}$ on the COCO-30K benchmark, achieving competitive
results or even substantially surpassing existing state-of-the-art distillation
techniques.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CVPR 2024; Github:
  https://github.com/VinAIResearch/SwiftBrush</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RangeLDM: Fast Realistic LiDAR Point Cloud Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10094v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10094v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianjiang Hu, Zhimin Zhang, Wei Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autonomous driving demands high-quality LiDAR data, yet the cost of physical
LiDAR sensors presents a significant scaling-up challenge. While recent efforts
have explored deep generative models to address this issue, they often consume
substantial computational resources with slow generation speeds while suffering
from a lack of realism. To address these limitations, we introduce RangeLDM, a
novel approach for rapidly generating high-quality range-view LiDAR point
clouds via latent diffusion models. We achieve this by correcting range-view
data distribution for accurate projection from point clouds to range images via
Hough voting, which has a critical impact on generative learning. We then
compress the range images into a latent space with a variational autoencoder,
and leverage a diffusion model to enhance expressivity. Additionally, we
instruct the model to preserve 3D structural fidelity by devising a
range-guided discriminator. Experimental results on KITTI-360 and nuScenes
datasets demonstrate both the robust expressiveness and fast speed of our LiDAR
point cloud generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DriveScape: Towards High-Resolution Controllable Multi-View Driving
  Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05463v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05463v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Wu, Xi Guo, Weixuan Tang, Tingxuan Huang, Chiyu Wang, Dongyue Chen, Chenjing Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in generative models have provided promising solutions
for synthesizing realistic driving videos, which are crucial for training
autonomous driving perception models. However, existing approaches often
struggle with multi-view video generation due to the challenges of integrating
3D information while maintaining spatial-temporal consistency and effectively
learning from a unified model. In this paper, we propose an end-to-end
framework named DriveScape for multi-view, 3D condition-guided video
generation. DriveScape not only streamlines the process by integrating camera
data to ensure comprehensive spatial-temporal coverage, but also introduces a
Bi-Directional Modulated Transformer module to effectively align 3D road
structural information. As a result, our approach enables precise control over
video generation, significantly enhancing realism and providing a robust
solution for generating multi-view driving videos. Our framework achieves
state-of-the-art results on the nuScenes dataset, demonstrating impressive
generative quality metrics with an FID score of 8.34 and an FVD score of 76.39,
as well as superior performance across various perception tasks. This paves the
way for more accurate environmental simulations in autonomous driving. Code
will be available at
\href{https://metadrivescape.github.io/papers_project/drivescapev1/index.html}{our
project homepage}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Make-A-Shape: a Ten-Million-scale 3D Shape Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.11067v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.11067v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ka-Hei Hui, Aditya Sanghi, Arianna Rampini, Kamal Rahimi Malekshan, Zhengzhe Liu, Hooman Shayani, Chi-Wing Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Significant progress has been made in training large generative models for
natural language and images. Yet, the advancement of 3D generative models is
hindered by their substantial resource demands for training, along with
inefficient, non-compact, and less expressive representations. This paper
introduces Make-A-Shape, a new 3D generative model designed for efficient
training on a vast scale, capable of utilizing 10 millions publicly-available
shapes. Technical-wise, we first innovate a wavelet-tree representation to
compactly encode shapes by formulating the subband coefficient filtering scheme
to efficiently exploit coefficient relations. We then make the representation
generatable by a diffusion model by devising the subband coefficients packing
scheme to layout the representation in a low-resolution grid. Further, we
derive the subband adaptive training strategy to train our model to effectively
learn to generate coarse and detail wavelet coefficients. Last, we extend our
framework to be controlled by additional input conditions to enable it to
generate shapes from assorted modalities, e.g., single/multi-view images, point
clouds, and low-resolution voxels. In our extensive set of experiments, we
demonstrate various applications, such as unconditional generation, shape
completion, and conditional generation on a wide range of modalities. Our
approach not only surpasses the state of the art in delivering high-quality
results but also efficiently generates shapes within a few seconds, often
achieving this in just 2 seconds for most conditions. Our source code is
available at https://github.com/AutodeskAILab/Make-a-Shape.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth
  Smooth Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06241v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06241v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengcheng Zhu, Yaoming Zhuang, Baoquan Chen, Li Li, Chengdong Wu, Zhanlin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This letter introduces a novel framework for dense Visual Simultaneous
Localization and Mapping (VSLAM) based on Gaussian Splatting. Recently, SLAM
based on Gaussian Splatting has shown promising results. However, in monocular
scenarios, the Gaussian maps reconstructed lack geometric accuracy and exhibit
weaker tracking capability. To address these limitations, we jointly optimize
sparse visual odometry tracking and 3D Gaussian Splatting scene representation
for the first time. We obtain depth maps on visual odometry keyframe windows
using a fast Multi-View Stereo (MVS) network for the geometric supervision of
Gaussian maps. Furthermore, we propose a depth smooth loss and Sparse-Dense
Adjustment Ring (SDAR) to reduce the negative effect of estimated depth maps
and preserve the consistency in scale between the visual odometry and Gaussian
maps. We have evaluated our system across various synthetic and real-world
datasets. The accuracy of our pose estimation surpasses existing methods and
achieves state-of-the-art. Additionally, it outperforms previous monocular
methods in terms of novel view synthesis and geometric reconstruction
fidelities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Robotics and Automation Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Bayesian Active Learning-to-Rank with Relative Annotation for
  Estimation of Ulcerative Colitis Severity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04952v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04952v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takeaki Kadota, Hideaki Hayashi, Ryoma Bise, Kiyohito Tanaka, Seiichi Uchida
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic image-based severity estimation is an important task in
computer-aided diagnosis. Severity estimation by deep learning requires a large
amount of training data to achieve a high performance. In general, severity
estimation uses training data annotated with discrete (i.e., quantized)
severity labels. Annotating discrete labels is often difficult in images with
ambiguous severity, and the annotation cost is high. In contrast, relative
annotation, in which the severity between a pair of images is compared, can
avoid quantizing severity and thus makes it easier. We can estimate relative
disease severity using a learning-to-rank framework with relative annotations,
but relative annotation has the problem of the enormous number of pairs that
can be annotated. Therefore, the selection of appropriate pairs is essential
for relative annotation. In this paper, we propose a deep Bayesian active
learning-to-rank that automatically selects appropriate pairs for relative
annotation. Our method preferentially annotates unlabeled pairs with high
learning efficiency from the model uncertainty of the samples. We prove the
theoretical basis for adapting Bayesian neural networks to pairwise
learning-to-rank and demonstrate the efficiency of our method through
experiments on endoscopic images of ulcerative colitis on both private and
public datasets. We also show that our method achieves a high performance under
conditions of significant class imbalance because it automatically selects
samples from the minority classes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 8 figures, accepted in Medical Image Analysis 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Patronizing and Condescending Language in Chinese Videos: A
  Multimodal <span class="highlight-title">Dataset</span> and Detector <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05005v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05005v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongbo Wang, Junyu Lu, Yan Han, Kai Ma, Liang Yang, Hongfei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Patronizing and Condescending Language (PCL) is a form of discriminatory
toxic speech targeting vulnerable groups, threatening both online and offline
safety. While toxic speech research has mainly focused on overt toxicity, such
as hate speech, microaggressions in the form of PCL remain underexplored.
Additionally, dominant groups' discriminatory facial expressions and attitudes
toward vulnerable communities can be more impactful than verbal cues, yet these
frame features are often overlooked. In this paper, we introduce the PCLMM
dataset, the first Chinese multimodal dataset for PCL, consisting of 715
annotated videos from Bilibili, with high-quality PCL facial frame spans. We
also propose the MultiPCL detector, featuring a facial expression detection
module for PCL recognition, demonstrating the effectiveness of modality
complementarity in this challenging task. Our work makes an important
contribution to advancing microaggression detection within the domain of toxic
speech.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review in ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dreaming is All You Need 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01633v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01633v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingze Ni, Wei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In classification tasks, achieving a harmonious balance between exploration
and precision is of paramount importance. To this end, this research introduces
two novel deep learning models, SleepNet and DreamNet, to strike this balance.
SleepNet seamlessly integrates supervised learning with unsupervised ``sleep"
stages using pre-trained encoder models. Dedicated neurons within SleepNet are
embedded in these unsupervised features, forming intermittent ``sleep" blocks
that facilitate exploratory learning. Building upon the foundation of SleepNet,
DreamNet employs full encoder-decoder frameworks to reconstruct the hidden
states, mimicking the human "dreaming" process. This reconstruction process
enables further exploration and refinement of the learned representations.
Moreover, the principle ideas of our SleepNet and DreamNet are generic and can
be applied to both computer vision and natural language processing downstream
tasks. Through extensive empirical evaluations on diverse image and text
datasets, SleepNet and DreanNet have demonstrated superior performance compared
to state-of-the-art models, showcasing the strengths of unsupervised
exploration and supervised precision afforded by our innovative approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adversarial Score Distillation: When score distillation meets GAN <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00739v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00739v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Min Wei, Jingkai Zhou, Junyao Sun, Xuesong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing score distillation methods are sensitive to classifier-free guidance
(CFG) scale: manifested as over-smoothness or instability at small CFG scales,
while over-saturation at large ones. To explain and analyze these issues, we
revisit the derivation of Score Distillation Sampling (SDS) and decipher
existing score distillation with the Wasserstein Generative Adversarial Network
(WGAN) paradigm. With the WGAN paradigm, we find that existing score
distillation either employs a fixed sub-optimal discriminator or conducts
incomplete discriminator optimization, resulting in the scale-sensitive issue.
We propose the Adversarial Score Distillation (ASD), which maintains an
optimizable discriminator and updates it using the complete optimization
objective. Experiments show that the proposed ASD performs favorably in 2D
distillation and text-to-3D tasks against existing methods. Furthermore, to
explore the generalization ability of our WGAN paradigm, we extend ASD to the
image editing task, which achieves competitive results. The project page and
code are at https://github.com/2y7c3/ASD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CVPR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inhomogeneous illumination image enhancement under ex-tremely low
  visibility condition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17503v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17503v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Libang Chen, Jinyan Lin, Qihang Bian, Yikun Liu, Jianying Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Imaging through dense fog presents unique challenges, with essential visual
information crucial for applications like object detection and recognition
obscured, thereby hindering conventional image processing methods. Despite
improvements through neural network-based approaches, these techniques falter
under extremely low visibility conditions exacerbated by inhomogeneous
illumination, which degrades deep learning performance due to inconsistent
signal intensities. We introduce in this paper a novel method that adaptively
filters background illumination based on Structural Differential and Integral
Filtering (SDIF) to enhance only vital signal information. The grayscale
banding is eliminated by incorporating a visual optimization strategy based on
image gradients. Maximum Histogram Equalization (MHE) is used to achieve high
contrast while maintaining fidelity to the original content. We evaluated our
algorithm using data collected from both a fog chamber and outdoor
environments, and performed comparative analyses with existing methods. Our
findings demonstrate that our proposed method significantly enhances signal
clarity under extremely low visibility conditions and out-performs existing
techniques, offering substantial improvements for deep fog imaging
applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Multiview Object Consistency in Humans and Image Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05862v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05862v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tyler Bonnen, Stephanie Fu, Yutong Bai, Thomas O'Connell, Yoni Friedman, Nancy Kanwisher, Joshua B. Tenenbaum, Alexei A. Efros
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a benchmark to directly evaluate the alignment between human
observers and vision models on a 3D shape inference task. We leverage an
experimental design from the cognitive sciences which requires zero-shot visual
inferences about object shape: given a set of images, participants identify
which contain the same/different objects, despite considerable viewpoint
variation. We draw from a diverse range of images that include common objects
(e.g., chairs) as well as abstract shapes (i.e., procedurally generated
`nonsense' objects). After constructing over 2000 unique image sets, we
administer these tasks to human participants, collecting 35K trials of
behavioral data from over 500 participants. This includes explicit choice
behaviors as well as intermediate measures, such as reaction time and gaze
data. We then evaluate the performance of common vision models (e.g., DINOv2,
MAE, CLIP). We find that humans outperform all models by a wide margin. Using a
multi-scale evaluation approach, we identify underlying similarities and
differences between models and humans: while human-model performance is
correlated, humans allocate more time/processing on challenging trials. All
images, data, and code can be accessed via our project page.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://tzler.github.io/MOCHI/ Code:
  https://github.com/tzler/mochi_code Huggingface dataset:
  https://huggingface.co/datasets/tzler/MOCHI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Look Hear: Gaze Prediction for Speech-directed Human Attention <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.19605v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.19605v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sounak Mondal, Seoyoung Ahn, Zhibo Yang, Niranjan Balasubramanian, Dimitris Samaras, Gregory Zelinsky, Minh Hoai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For computer systems to effectively interact with humans using spoken
language, they need to understand how the words being generated affect the
users' moment-by-moment attention. Our study focuses on the incremental
prediction of attention as a person is seeing an image and hearing a referring
expression defining the object in the scene that should be fixated by gaze. To
predict the gaze scanpaths in this incremental object referral task, we
developed the Attention in Referral Transformer model or ART, which predicts
the human fixations spurred by each word in a referring expression. ART uses a
multimodal transformer encoder to jointly learn gaze behavior and its
underlying grounding tasks, and an autoregressive transformer decoder to
predict, for each word, a variable number of fixations based on fixation
history. To train ART, we created RefCOCO-Gaze, a large-scale dataset of 19,738
human gaze scanpaths, corresponding to 2,094 unique image-expression pairs,
from 220 participants performing our referral task. In our quantitative and
qualitative analyses, ART not only outperforms existing methods in scanpath
prediction, but also appears to capture several human attention patterns, such
as waiting, scanning, and verification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal
  High-Frequency Components for Endoscopic Scene Reconstruction <span class="chip">BMVC2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17872v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17872v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoyu Zhao, Xingyue Zhao, Lingting Zhu, Weixi Zheng, Yongchao Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Robot-assisted minimally invasive surgery benefits from enhancing dynamic
scene reconstruction, as it improves surgical outcomes. While Neural Radiance
Fields (NeRF) have been effective in scene reconstruction, their slow inference
speeds and lengthy training durations limit their applicability. To overcome
these limitations, 3D Gaussian Splatting (3D-GS) based methods have emerged as
a recent trend, offering rapid inference capabilities and superior 3D quality.
However, these methods still struggle with under-reconstruction in both static
and dynamic scenes. In this paper, we propose HFGS, a novel approach for
deformable endoscopic reconstruction that addresses these challenges from
spatial and temporal frequency perspectives. Our approach incorporates
deformation fields to better handle dynamic scenes and introduces Spatial
High-Frequency Emphasis Reconstruction (SHF) to minimize discrepancies in
spatial frequency spectra between the rendered image and its ground truth.
Additionally, we introduce Temporal High-Frequency Emphasis Reconstruction
(THF) to enhance dynamic awareness in neural rendering by leveraging flow
priors, focusing optimization on motion-intensive parts. Extensive experiments
on two widely used benchmarks demonstrate that HFGS achieves superior rendering
quality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>BMVC2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">11</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Critical Features Tracking on Triangulated Irregular Networks by a
  Scale-Space Method <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoan Feng, Yunting Song, Leila De Floriani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The scale-space method is a well-established framework that constructs a
hierarchical representation of an input signal and facilitates coarse-to-fine
visual reasoning. Considering the terrain elevation function as the input
signal, the scale-space method can identify and track significant topographic
features across different scales. The number of scales a feature persists,
called its life span, indicates the importance of that feature. In this way,
important topographic features of a landscape can be selected, which are useful
for many applications, including cartography, nautical charting, and land-use
planning. The scale-space methods developed for terrain data use gridded
Digital Elevation Models (DEMs) to represent the terrain. However, gridded DEMs
lack the flexibility to adapt to the irregular distribution of input data and
the varied topological complexity of different regions. Instead, Triangulated
Irregular Networks (TINs) can be directly generated from irregularly
distributed point clouds and accurately preserve important features. In this
work, we introduce a novel scale-space analysis pipeline for TINs, addressing
the multiple challenges in extending grid-based scale-space methods to TINs.
Our pipeline can efficiently identify and track topologically important
features on TINs. Moreover, it is capable of analyzing terrains with irregular
boundaries, which poses challenges for grid-based methods. Comprehensive
experiments show that, compared to grid-based methods, our TIN-based pipeline
is more efficient, accurate, and has better resolution robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13pages, ACM SIGSPATIAL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Operational Advice for Dense and Sparse Retrievers: HNSW, Flat, or
  Inverted Indexes? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jimmy Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Practitioners working on dense retrieval today face a bewildering number of
choices. Beyond selecting the embedding model, another consequential choice is
the actual implementation of nearest-neighbor vector search. While best
practices recommend HNSW indexes, flat vector indexes with brute-force search
represent another viable option, particularly for smaller corpora and for rapid
prototyping. In this paper, we provide experimental results on the BEIR dataset
using the open-source Lucene search library that explicate the tradeoffs
between HNSW and flat indexes (including quantized variants) from the
perspectives of indexing time, query evaluation performance, and retrieval
quality. With additional comparisons between dense and sparse retrievers, our
results provide guidance for today's search practitioner in understanding the
design space of dense and sparse retrievers. To our knowledge, we are the first
to provide operational advice supported by empirical experiments in this
regard.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Sequential Recommendations through Multi-Perspective
  Reflections and Iteration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06377v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06377v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Xiao Zhang, Ming He, Jianping Fan, Jun Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequence recommendation (SeqRec) aims to predict the next item a user will
interact with by understanding user intentions and leveraging collaborative
filtering information. Large language models (LLMs) have shown great promise in
recommendation tasks through prompt-based, fixed reflection libraries, and
fine-tuning techniques. However, these methods face challenges, including lack
of supervision, inability to optimize reflection sources, inflexibility to
diverse user needs, and high computational costs. Despite promising results,
current studies primarily focus on reflections of users' explicit preferences
(e.g., item titles) while neglecting implicit preferences (e.g., brands) and
collaborative filtering information. This oversight hinders the capture of
preference shifts and dynamic user behaviors. Additionally, existing approaches
lack mechanisms for reflection evaluation and iteration, often leading to
suboptimal recommendations. To address these issues, we propose the Mixture of
REflectors (MoRE) framework, designed to model and learn dynamic user
preferences in SeqRec. Specifically, MoRE introduces three reflectors for
generating LLM-based reflections on explicit preferences, implicit preferences,
and collaborative signals. Each reflector incorporates a self-improving
strategy, termed refining-and-iteration, to evaluate and iteratively update
reflections. Furthermore, a meta-reflector employs a contextual bandit
algorithm to select the most suitable expert and corresponding reflections for
each user's recommendation, effectively capturing dynamic preferences.
Extensive experiments on three real-world datasets demonstrate that MoRE
consistently outperforms state-of-the-art methods, requiring less training time
and GPU memory compared to other LLM-based approaches in SeqRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First 3 authors contributes equally to this work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HierLLM: Hierarchical Large Language Model for Question Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06177v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06177v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Liu, Haipeng Liu, Ting Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Question recommendation is a task that sequentially recommends questions for
students to enhance their learning efficiency. That is, given the learning
history and learning target of a student, a question recommender is supposed to
select the question that will bring the most improvement for students. Previous
methods typically model the question recommendation as a sequential
decision-making problem, estimating students' learning state with the learning
history, and feeding the learning state with the learning target to a neural
network to select the recommended question from a question set. However,
previous methods are faced with two challenges: (1) learning history is
unavailable in the cold start scenario, which makes the recommender generate
inappropriate recommendations; (2) the size of the question set is much large,
which makes it difficult for the recommender to select the best question
precisely. To address the challenges, we propose a method called hierarchical
large language model for question recommendation (HierLLM), which is a
LLM-based hierarchical structure. The LLM-based structure enables HierLLM to
tackle the cold start issue with the strong reasoning abilities of LLM. The
hierarchical structure takes advantage of the fact that the number of concepts
is significantly smaller than the number of questions, narrowing the range of
selectable questions by first identifying the relevant concept for the
to-recommend question, and then selecting the recommended question based on
that concept. This hierarchical structure reduces the difficulty of the
recommendation.To investigate the performance of HierLLM, we conduct extensive
experiments, and the results demonstrate the outstanding performance of
HierLLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What makes a good concept anyway ? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naren Khatwani, James Geller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A good medical ontology is expected to cover its domain completely and
correctly. On the other hand, large ontologies are hard to build, hard to
understand, and hard to maintain. Thus, adding new concepts (often multi-word
concepts) to an existing ontology must be done judiciously. Only "good"
concepts should be added; however, it is difficult to define what makes a
concept good. In this research, we propose a metric to measure the goodness of
a concept. We identified factors that appear to influence goodness judgments of
medical experts and combined them into a single metric. These factors include
concept name length (in words), concept occurrence frequency in the medical
literature, and syntactic categories of component words. As an added factor, we
used the simplicity of a term after mapping it into a specific foreign
language. We performed Bayesian optimization of factor weights to achieve
maximum agreement between the metric and three medical experts. The results
showed that our metric had a 50.67% overall agreement with the experts, as
measured by Krippendorff's alpha.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QueryBuilder: Human-in-the-Loop Query Development for Information
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hemanth Kandula, Damianos Karakos, Haoling Qiu, Benjamin Rozonoyer, Ian Soboroff, Lee Tarlin, Bonan Min
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Frequently, users of an Information Retrieval (IR) system start with an
overarching information need (a.k.a., an analytic task) and proceed to define
finer-grained queries covering various important aspects (i.e., sub-topics) of
that analytic task. We present a novel, interactive system called
$\textit{QueryBuilder}$, which allows a novice, English-speaking user to create
queries with a small amount of effort, through efficient exploration of an
English development corpus in order to rapidly develop cross-lingual
information retrieval queries corresponding to the user's information needs.
QueryBuilder performs near real-time retrieval of documents based on
user-entered search terms; the user looks through the retrieved documents and
marks sentences as relevant to the information needed. The marked sentences are
used by the system as additional information in query formation and refinement:
query terms (and, optionally, event features, which capture event $'triggers'$
(indicator terms) and agent/patient roles) are appropriately weighted, and a
neural-based system, which better captures textual meaning, retrieves other
relevant content. The process of retrieval and marking is repeated as many
times as desired, giving rise to increasingly refined queries in each
iteration. The final product is a fine-grained query used in Cross-Lingual
Information Retrieval (CLIR). Our experiments using analytic tasks and requests
from the IARPA BETTER IR datasets show that with a small amount of effort (at
most 10 minutes per sub-topic), novice users can form $\textit{useful}$
fine-grained queries including in languages they don't understand. QueryBuilder
also provides beneficial capabilities to the traditional corpus exploration and
query formation process. A demonstration video is released at
https://vimeo.com/734795835
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RBoard: A Unified Platform for Reproducible and Reusable Recommender
  System Benchmarks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05526v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05526v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyang Shao, Edoardo D'Amico, Gabor Fodor, Tri Kurniawan Wijaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems research lacks standardized benchmarks for
reproducibility and algorithm comparisons. We introduce RBoard, a novel
framework addressing these challenges by providing a comprehensive platform for
benchmarking diverse recommendation tasks, including CTR prediction, Top-N
recommendation, and others. RBoard's primary objective is to enable fully
reproducible and reusable experiments across these scenarios. The framework
evaluates algorithms across multiple datasets within each task, aggregating
results for a holistic performance assessment. It implements standardized
evaluation protocols, ensuring consistency and comparability. To facilitate
reproducibility, all user-provided code can be easily downloaded and executed,
allowing researchers to reliably replicate studies and build upon previous
work. By offering a unified platform for rigorous, reproducible evaluation
across various recommendation scenarios, RBoard aims to accelerate progress in
the field and establish a new standard for recommender systems benchmarking in
both academia and industry. The platform is available at https://rboard.org and
the demo video can be found at https://bit.ly/rboard-demo.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Retrieval-Augmented Generation: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08921v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08921v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, Siliang Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Retrieval-Augmented Generation (RAG) has achieved remarkable
success in addressing the challenges of Large Language Models (LLMs) without
necessitating retraining. By referencing an external knowledge base, RAG
refines LLM outputs, effectively mitigating issues such as ``hallucination'',
lack of domain-specific knowledge, and outdated information. However, the
complex structure of relationships among different entities in databases
presents challenges for RAG systems. In response, GraphRAG leverages structural
information across entities to enable more precise and comprehensive retrieval,
capturing relational knowledge and facilitating more accurate, context-aware
responses. Given the novelty and potential of GraphRAG, a systematic review of
current technologies is imperative. This paper provides the first comprehensive
overview of GraphRAG methodologies. We formalize the GraphRAG workflow,
encompassing Graph-Based Indexing, Graph-Guided Retrieval, and Graph-Enhanced
Generation. We then outline the core technologies and training methods at each
stage. Additionally, we examine downstream tasks, application domains,
evaluation methodologies, and industrial use cases of GraphRAG. Finally, we
explore future research directions to inspire further inquiries and advance
progress in the field. In order to track recent progress in this field, we set
up a repository at \url{https://github.com/pengboci/GraphRAG-Survey}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work. Compared to the first version, several references have
  been added and a GitHub repository link has been provided</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Margin Cosine Loss: Proposal and Application in Recommender
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04614v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04614v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Makbule Gulcin Ozsoy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems guide users through vast amounts of information by
suggesting items based on their predicted preferences. Collaborative
filtering-based deep learning techniques have regained popularity due to their
straightforward nature, relying only on user-item interactions. Typically,
these systems consist of three main components: an interaction module, a loss
function, and a negative sampling strategy. Initially, researchers focused on
enhancing performance by developing complex interaction modules. However, there
has been a recent shift toward refining loss functions and negative sampling
strategies. This shift has led to an increased interest in contrastive
learning, which pulls similar pairs closer while pushing dissimilar ones apart.
Contrastive learning may bring challenges like high memory demands and
under-utilization of some negative samples. The proposed Multi-Margin Cosine
Loss (MMCL) addresses these challenges by introducing multiple margins and
varying weights for negative samples. It efficiently utilizes not only the
hardest negatives but also other non-trivial negatives, offers a simpler yet
effective loss function that outperforms more complex methods, especially when
resources are limited. Experiments on two well-known datasets demonstrated that
MMCL achieved up to a 20\% performance improvement compared to a baseline loss
function when fewer number of negative samples are used.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-shot Audio Topic Reranking using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.07606v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.07606v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengjie Qian, Rao Ma, Adian Liusie, Erfan Loweimi, Kate M. Knill, Mark J. F. Gales
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Video Search by Examples (MVSE) investigates using video clips as
the query term for information retrieval, rather than the more traditional text
query. This enables far richer search modalities such as images, speaker,
content, topic, and emotion. A key element for this process is highly rapid and
flexible search to support large archives, which in MVSE is facilitated by
representing video attributes with embeddings. This work aims to compensate for
any performance loss from this rapid archive search by examining reranking
approaches. In particular, zero-shot reranking methods using large language
models (LLMs) are investigated as these are applicable to any video archive
audio content. Performance is evaluated for topic-based retrieval on a publicly
available video archive, the BBC Rewind corpus. Results demonstrate that
reranking significantly improves retrieval ranking without requiring any
task-specific in-domain training data. Furthermore, three sources of
information (ASR transcriptions, automatic summaries and synopses) as input for
LLM reranking were compared. To gain a deeper understanding and further
insights into the performance differences and limitations of these text
sources, we employ a fact-checking approach to analyse the information
consistency among them.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Counterfactual Explanation Framework for Retrieval Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00860v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00860v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhavik Chandna, Procheta Sen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explainability has become a crucial concern in today's world, aiming to
enhance transparency in machine learning and deep learning models. Information
retrieval is no exception to this trend. In existing literature on
explainability of information retrieval, the emphasis has predominantly been on
illustrating the concept of relevance concerning a retrieval model. The
questions addressed include why a document is relevant to a query, why one
document exhibits higher relevance than another, or why a specific set of
documents is deemed relevant for a query.
  However, limited attention has been given to understanding why a particular
document is considered non-relevant to a query with respect to a retrieval
model. In an effort to address this gap, our work focus on the question of what
terms need to be added within a document to improve its ranking. This in turn
answers the question of which words played a role in not being favored by a
retrieval model for a particular query. We use an optimization framework to
solve the above-mentioned research problem. % To the best of our knowledge, we
mark the first attempt to tackle this specific counterfactual problem. Our
experiments show the effectiveness of our proposed approach in predicting
counterfactuals for both statistical (e.g. BM25) and deep-learning-based models
(e.g. DRMM, DSSM, ColBERT).
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">134</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DANCE: Deep Learning-Assisted Analysis of Protein Sequences Using Chaos
  Enhanced Kaleidoscopic Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06694v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06694v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taslim Murad, Prakash Chourasia, Sarwan Ali, Murray Patterson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cancer is a complex disease characterized by uncontrolled cell growth. T cell
receptors (TCRs), crucial proteins in the immune system, play a key role in
recognizing antigens, including those associated with cancer. Recent
advancements in sequencing technologies have facilitated comprehensive
profiling of TCR repertoires, uncovering TCRs with potent anti-cancer activity
and enabling TCR-based immunotherapies. However, analyzing these intricate
biomolecules necessitates efficient representations that capture their
structural and functional information. T-cell protein sequences pose unique
challenges due to their relatively smaller lengths compared to other
biomolecules. An image-based representation approach becomes a preferred choice
for efficient embeddings, allowing for the preservation of essential details
and enabling comprehensive analysis of T-cell protein sequences. In this paper,
we propose to generate images from the protein sequences using the idea of
Chaos Game Representation (CGR) using the Kaleidoscopic images approach. This
Deep Learning Assisted Analysis of Protein Sequences Using Chaos Enhanced
Kaleidoscopic Images (called DANCE) provides a unique way to visualize protein
sequences by recursively applying chaos game rules around a central seed point.
we perform the classification of the T cell receptors (TCRs) protein sequences
in terms of their respective target cancer cells, as TCRs are known for their
immune response against cancer disease. The TCR sequences are converted into
images using the DANCE method. We employ deep-learning vision models to perform
the classification to obtain insights into the relationship between the visual
patterns observed in the generated kaleidoscopic images and the underlying
protein properties. By combining CGR-based image generation with deep learning
classification, this study opens novel possibilities in the protein analysis
domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HybridFC: A Hybrid Fact-Checking Approach for Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Umair Qudus, Michael Roeder, Muhammad Saleem, Axel-Cyrille Ngonga Ngomo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider fact-checking approaches that aim to predict the veracity of
assertions in knowledge graphs. Five main categories of fact-checking
approaches for knowledge graphs have been proposed in the recent literature, of
which each is subject to partially overlapping limitations. In particular,
current text-based approaches are limited by manual feature engineering.
Path-based and rule-based approaches are limited by their exclusive use of
knowledge graphs as background knowledge, and embedding-based approaches suffer
from low accuracy scores on current fact-checking tasks. We propose a hybrid
approach -- dubbed HybridFC -- that exploits the diversity of existing
categories of fact-checking approaches within an ensemble learning setting to
achieve a significantly better prediction performance. In particular, our
approach outperforms the state of the art by 0.14 to 0.27 in terms of Area
Under the Receiver Operating Characteristic curve on the FactBench dataset. Our
code is open-source and can be found at https://github.com/dice-group/HybridFC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Geometric-Averaged Preference Optimization for Soft Preference Labels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hiroki Furuta, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many algorithms for aligning LLMs with human preferences assume that human
preferences are binary and deterministic. However, it is reasonable to think
that they can vary with different individuals, and thus should be
distributional to reflect the fine-grained relationship between the responses.
In this work, we introduce the distributional soft preference labels and
improve Direct Preference Optimization (DPO) with a weighted geometric average
of the LLM output likelihood in the loss function. In doing so, the scale of
learning loss is adjusted based on the soft labels, and the loss with equally
preferred responses would be close to zero. This simple modification can be
easily applied to any DPO family and helps the models escape from the
over-optimization and objective mismatch prior works suffer from. In our
experiments, we simulate the soft preference labels with AI feedback from LLMs
and demonstrate that geometric averaging consistently improves performance on
standard benchmarks for alignment research. In particular, we observe more
preferable responses than binary labels and significant improvements with data
where modestly-confident labels are in the majority.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Liability and Insurance for Catastrophic Losses: the Nuclear Power
  Precedent and Lessons for AI <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06673v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06673v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cristian Trout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As AI systems become more autonomous and capable, experts warn of them
potentially causing catastrophic losses. Drawing on the successful precedent
set by the nuclear power industry, this paper argues that developers of
frontier AI models should be assigned limited, strict, and exclusive third
party liability for harms resulting from Critical AI Occurrences (CAIOs) -
events that cause or easily could have caused catastrophic losses. Mandatory
insurance for CAIO liability is recommended to overcome developers'
judgment-proofness, mitigate winner's curse dynamics, and leverage insurers'
quasi-regulatory abilities. Based on theoretical arguments and observations
from the analogous nuclear power context, insurers are expected to engage in a
mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and
providing loss prevention guidance in the context of insuring against
heavy-tail risks from AI. While not a substitute for regulation, clear
liability assignment and mandatory insurance can help efficiently allocate
resources to risk-modeling and safe design, facilitating future regulatory
efforts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Generative AI and Law Workshop at the International
  Conference on Machine Learning (ICML 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06672v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06672v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cristian Trout
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many experts believe that AI systems will sooner or later pose uninsurable
risks, including existential risks. This creates an extreme judgment-proof
problem: few if any parties can be held accountable ex post in the event of
such a catastrophe. This paper proposes a novel solution: a
government-provided, mandatory indemnification program for AI developers. The
program uses risk-priced indemnity fees to induce socially optimal levels of
care. Risk-estimates are determined by surveying experts, including indemnified
developers. The Bayesian Truth Serum mechanism is employed to incent honest and
effortful responses. Compared to alternatives, this approach arguably better
leverages all private information, and provides a clearer signal to indemnified
developers regarding what risks they must mitigate to lower their fees. It's
recommended that collected fees be used to help fund the safety research
developers need, employing a fund matching mechanism (Quadratic Financing) to
induce an optimal supply of this public good. Under Quadratic Financing, safety
research projects would compete for private contributions from developers,
signaling how much each is to be supplemented with public funds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Generative AI and Law Workshop at the International
  Conference on Machine Learning (ICML 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DA-MoE: Towards Dynamic Expert Allocation for Mixture-of-Experts Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maryam Akhavan Aghdam, Hongpeng Jin, Yanzhao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based Mixture-of-Experts (MoE) models have been driving several
recent technological advancements in Natural Language Processing (NLP). These
MoE models adopt a router mechanism to determine which experts to activate for
routing input tokens. However, existing router mechanisms allocate a fixed
number of experts to each token, which neglects the varying importance of
different input tokens. In this study, we propose a novel dynamic router
mechanism that Dynamically Allocates a variable number of experts for
Mixture-of-Experts (DA-MoE) models based on an effective token importance
measure. First, we show that the Transformer attention mechanism provides a
natural and effective way of calculating token importance. Second, we propose a
dynamic router mechanism that effectively decides the optimal number of experts
(K) and allocates the top-K experts for each input token. Third, comprehensive
experiments on several benchmark datasets demonstrate that our DA-MoE approach
consistently outperforms the state-of-the-art Transformer based MoE model on
the popular GLUE benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sortformer: Seamless Integration of Speaker Diarization and ASR by
  Bridging Timestamps and Tokens 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06656v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06656v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taejin Park, Ivan Medennikov, Kunal Dhawan, Weiqing Wang, He Huang, Nithin Rao Koluguri, Krishna C. Puvvada, Jagadeesh Balam, Boris Ginsburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose Sortformer, a novel neural model for speaker diarization, trained
with unconventional objectives compared to existing end-to-end diarization
models. The permutation problem in speaker diarization has long been regarded
as a critical challenge. Most prior end-to-end diarization systems employ
permutation invariant loss (PIL), which optimizes for the permutation that
yields the lowest error. In contrast, we introduce Sort Loss, which enables a
diarization model to autonomously resolve permutation, with or without PIL. We
demonstrate that combining Sort Loss and PIL achieves performance competitive
with state-of-the-art end-to-end diarization models trained exclusively with
PIL. Crucially, we present a streamlined multispeaker ASR architecture that
leverages Sortformer as a speaker supervision model, embedding speaker label
estimation within the ASR encoder state using a sinusoidal kernel function.
This approach resolves the speaker permutation problem through sorted
objectives, effectively bridging speaker-label timestamps and speaker tokens.
In our experiments, we show that the proposed multispeaker ASR architecture,
enhanced with speaker supervision, improves performance via adapter techniques.
Code and trained models will be made publicly available via the NVIDIA NeMo
framework
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KANtrol: A Physics-Informed Kolmogorov-Arnold Network Framework for
  Solving Multi-Dimensional and Fractional Optimal Control Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Afzal Aghaei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce the KANtrol framework, which utilizes
Kolmogorov-Arnold Networks (KANs) to solve optimal control problems involving
continuous time variables. We explain how Gaussian quadrature can be employed
to approximate the integral parts within the problem, particularly for
integro-differential state equations. We also demonstrate how automatic
differentiation is utilized to compute exact derivatives for integer-order
dynamics, while for fractional derivatives of non-integer order, we employ
matrix-vector product discretization within the KAN framework. We tackle
multi-dimensional problems, including the optimal control of a 2D heat partial
differential equation. The results of our simulations, which cover both forward
and parameter identification problems, show that the KANtrol framework
outperforms classical MLPs in terms of accuracy and efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Practice of Post-Training on Llama-3 70B with Optimal Selection of
  Additional Language Mixture Ratio 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06624v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06624v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ningyuan Xi, Yetao Wu, Kun Fan, Teng Chen, Qingqing Gu, Peng Yu, Jinxian Qu, Chenxi Liu, Zhonglin Jiang, Yong Chen, Luo Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to
obtain the unfamiliar language skill or adapt into new domains. The huge
training cost of CPT often asks for cautious choice of key hyper-parameters
such as the mixture ratio of extra language or domain corpus. However, there is
no systematic study which bridge the gap between the optimal mixture ratio and
the actual model performance, and the gap between experimental scaling law and
the actual deployment in the full model size. In this paper, we perform CPT on
Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal
correlation between the Additional Language Mixture Ratio (ALMR) and the
Learning Rate (LR) on the 8B size which directly indicate the optimal
experimental set up. By thorough choice of hyper-parameter, and subsequent
fine-tuning, the model capability is improved not only on the Chinese-related
benchmark, but also some specific domains including math, coding and emotional
intelligence. We deploy the final 70B version of LLM on an real-life chat
system which obtain satisfying performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hierarchical Multi-Label Classification with Missing Information for
  Benthic Habitat Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06618v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06618v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Isaac Xu, Benjamin Misiuk, Scott C. Lowe, Martin Gillis, Craig J. Brown, Thomas Trappenberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we apply state-of-the-art self-supervised learning techniques
on a large dataset of seafloor imagery, \textit{BenthicNet}, and study their
performance for a complex hierarchical multi-label (HML) classification
downstream task. In particular, we demonstrate the capacity to conduct HML
training in scenarios where there exist multiple levels of missing annotation
information, an important scenario for handling heterogeneous real-world data
collected by multiple research groups with differing data collection protocols.
We find that, when using smaller one-hot image label datasets typical of local
or regional scale benthic science projects, models pre-trained with
self-supervision on a larger collection of in-domain benthic data outperform
models pre-trained on ImageNet. In the HML setting, we find the model can
attain a deeper and more precise classification if it is pre-trained with
self-supervision on in-domain data. We hope this work can establish a benchmark
for future models in the field of automated underwater image annotation tasks
and can guide work in other domains with hierarchical annotations of mixed
resolution.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One-Shot Imitation under Mismatched Execution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06615v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06615v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kushal Kedia, Prithwish Dan, Sanjiban Choudhury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human demonstrations as prompts are a powerful way to program robots to do
long-horizon manipulation tasks. However, directly translating such
demonstrations into robot-executable actions poses significant challenges due
to execution mismatches, such as different movement styles and physical
capabilities. Existing methods either rely on robot-demonstrator paired data,
which is infeasible to scale, or overly rely on frame-level visual
similarities, which fail to hold. To address these challenges, we propose
RHyME, a novel framework that automatically establishes task execution
correspondences between the robot and the demonstrator by using optimal
transport costs. Given long-horizon robot demonstrations, RHyME synthesizes
semantically equivalent human demonstrations by retrieving and composing
similar short-horizon human clips, facilitating effective policy training
without the need for paired data. We show that RHyME outperforms a range of
baselines across various cross-embodiment datasets on all degrees of
mismatches. Through detailed analysis, we uncover insights for learning and
leveraging cross-embodiment visual representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DemoStart: Demonstration-led auto-curriculum applied to sim-to-real with
  multi-fingered robots 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maria Bauza, Jose Enrique Chen, Valentin Dalibard, Nimrod Gileadi, Roland Hafner, Murilo F. Martins, Joss Moore, Rugile Pevceviciute, Antoine Laurens, Dushyant Rao, Martina Zambelli, Martin Riedmiller, Jon Scholz, Konstantinos Bousmalis, Francesco Nori, Nicolas Heess
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present DemoStart, a novel auto-curriculum reinforcement learning method
capable of learning complex manipulation behaviors on an arm equipped with a
three-fingered robotic hand, from only a sparse reward and a handful of
demonstrations in simulation. Learning from simulation drastically reduces the
development cycle of behavior generation, and domain randomization techniques
are leveraged to achieve successful zero-shot sim-to-real transfer. Transferred
policies are learned directly from raw pixels from multiple cameras and robot
proprioception. Our approach outperforms policies learned from demonstrations
on the real robot and requires 100 times fewer demonstrations, collected in
simulation. More details and videos in https://sites.google.com/view/demostart.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages total with 7 pages of appendix. 9 Figures, 4 in the main
  text and 5 in the appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Label-free Monitoring of <span class="highlight-title">Self-Supervised</span> Learning Progress 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06612v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06612v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Isaac Xu, Scott Lowe, Thomas Trappenberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning (SSL) is an effective method for exploiting
unlabelled data to learn a high-level embedding space that can be used for
various downstream tasks. However, existing methods to monitor the quality of
the encoder -- either during training for one model or to compare several
trained models -- still rely on access to annotated data. When SSL
methodologies are applied to new data domains, a sufficiently large labelled
dataset may not always be available. In this study, we propose several
evaluation metrics which can be applied on the embeddings of unlabelled data
and investigate their viability by comparing them to linear probe accuracy (a
common metric which utilizes an annotated dataset). In particular, we apply
$k$-means clustering and measure the clustering quality with the silhouette
score and clustering agreement. We also measure the entropy of the embedding
distribution. We find that while the clusters did correspond better to the
ground truth annotations as training of the network progressed, label-free
clustering metrics correlated with the linear probe accuracy only when training
with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally,
although entropy did not always have strong correlations with LP accuracy, this
appears to be due to instability arising from early training, with the metric
stabilizing and becoming more reliable at later stages of learning.
Furthermore, while entropy generally decreases as learning progresses, this
trend reverses for SimSiam. More research is required to establish the cause
for this unexpected behaviour. Lastly, we find that while clustering based
approaches are likely only viable for same-architecture comparisons, entropy
may be architecture-independent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving the Precision of CNNs for Magnetic Resonance Spectral Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John LaMaster, Dhritiman Das, Florian Kofler, Jason Crane, Yan Li, Tobias Lasser, Bjoern H Menze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Magnetic resonance spectroscopic imaging is a widely available imaging
modality that can non-invasively provide a metabolic profile of the tissue of
interest, yet is challenging to integrate clinically. One major reason is the
expensive, expert data processing and analysis that is required. Using machine
learning to predict MRS-related quantities offers avenues around this problem,
but deep learning models bring their own challenges, especially model trust.
Current research trends focus primarily on mean error metrics, but
comprehensive precision metrics are also needed, e.g. standard deviations,
confidence intervals, etc.. This work highlights why more comprehensive error
characterization is important and how to improve the precision of CNNs for
spectral modeling, a quantitative task. The results highlight advantages and
trade-offs of these techniques that should be considered when addressing such
regression tasks with CNNs. Detailed insights into the underlying mechanisms of
each technique, and how they interact with other techniques, are discussed in
depth.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 1 figure, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactive 3D Segmentation for Primary Gross Tumor Volume in
  Oropharyngeal Cancer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikko Saukkoriipi, Jaakko Sahlsten, Joel Jaskari, Lotta Orasmaa, Jari Kangas, Nastaran Rasouli, Roope Raisamo, Jussi Hirvonen, Helena Mehtonen, Jorma Järnstedt, Antti Mäkitie, Mohamed Naser, Clifton Fuller, Benjamin Kann, Kimmo Kaski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The main treatment modality for oropharyngeal cancer (OPC) is radiotherapy,
where accurate segmentation of the primary gross tumor volume (GTVp) is
essential. However, accurate GTVp segmentation is challenging due to
significant interobserver variability and the time-consuming nature of manual
annotation, while fully automated methods can occasionally fail. An interactive
deep learning (DL) model offers the advantage of automatic high-performance
segmentation with the flexibility for user correction when necessary. In this
study, we examine interactive DL for GTVp segmentation in OPC. We implement
state-of-the-art algorithms and propose a novel two-stage Interactive Click
Refinement (2S-ICR) framework. Using the 2021 HEad and neCK TumOR (HECKTOR)
dataset for development and an external dataset from The University of Texas MD
Anderson Cancer Center for evaluation, the 2S-ICR framework achieves a Dice
similarity coefficient of 0.713 $\pm$ 0.152 without user interaction and 0.824
$\pm$ 0.099 after five interactions, outperforming existing methods in both
cases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Alleviating Hallucinations in Large Language Models with Scepticism
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yetao Wu, Yihong Wang, Teng Chen, Chenxi Liu, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Zhonglin Jiang, Yong Chen, Luo Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucinations is a major challenge for large language models (LLMs),
prevents adoption in diverse fields. Uncertainty estimation could be used for
alleviating the damages of hallucinations. The skeptical emotion of human could
be useful for enhancing the ability of self estimation. Inspirited by this
observation, we proposed a new approach called Skepticism Modeling (SM). This
approach is formalized by combining the information of token and logits for
self estimation. We construct the doubt emotion aware data, perform continual
pre-training, and then fine-tune the LLMs, improve their ability of self
estimation. Experimental results demonstrate this new approach effectively
enhances a model's ability to estimate their uncertainty, and validate its
generalization ability of other tasks by out-of-domain experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Advancing Causal Inference: A Nonparametric Approach to ATE and CATE
  Estimation with Continuous Treatments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06593v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06593v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hugo Gobato Souto, Francisco Louzada Neto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a generalized ps-BART model for the estimation of
Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE)
in continuous treatments, addressing limitations of the Bayesian Causal Forest
(BCF) model. The ps-BART model's nonparametric nature allows for flexibility in
capturing nonlinear relationships between treatment and outcome variables.
Across three distinct sets of Data Generating Processes (DGPs), the ps-BART
model consistently outperforms the BCF model, particularly in highly nonlinear
settings. The ps-BART model's robustness in uncertainty estimation and accuracy
in both point-wise and probabilistic estimation demonstrate its utility for
real-world applications. This research fills a crucial gap in causal inference
literature, providing a tool better suited for nonlinear treatment-outcome
relationships and opening avenues for further exploration in the domain of
continuous treatment effect estimation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Developing the Temporal Graph Convolutional Neural Network Model to
  Predict Hip Replacement using Electronic Health Records <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06585v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06585v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zoe Hancox, Sarah R. Kingsbury, Andrew Clegg, Philip G. Conaghan, Samuel D. Relton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background: Hip replacement procedures improve patient lives by relieving
pain and restoring mobility. Predicting hip replacement in advance could reduce
pain by enabling timely interventions, prioritising individuals for surgery or
rehabilitation, and utilising physiotherapy to potentially delay the need for
joint replacement. This study predicts hip replacement a year in advance to
enhance quality of life and health service efficiency. Methods: Adapting
previous work using Temporal Graph Convolutional Neural Network (TG-CNN)
models, we construct temporal graphs from primary care medical event codes,
sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip
replacement risk. We match hip replacement cases to controls by age, sex, and
Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187
controls, predicts hip replacement one year in advance. We validate the model
on two unseen datasets, recalibrating for class imbalance. Additionally, we
conduct an ablation study and compare against four baseline models. Results:
Our best model predicts hip replacement risk one year in advance with an AUROC
of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),
achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after
recalibration. Conclusions: The TG-CNN model effectively predicts hip
replacement risk by identifying patterns in patient trajectories, potentially
improving understanding and management of hip-related conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 2024 International Conference on Machine Learning and
  Applications (ICMLA). 8 pages, 3 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Primer on Variational Inference for Physics-Informed Deep Generative
  Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Glyn-Davies, Arnaud Vadeboncoeur, O. Deniz Akyildiz, Ieva Kazlauskaite, Mark Girolami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Variational inference (VI) is a computationally efficient and scalable
methodology for approximate Bayesian inference. It strikes a balance between
accuracy of uncertainty quantification and practical tractability. It excels at
generative modelling and inversion tasks due to its built-in Bayesian
regularisation and flexibility, essential qualities for physics related
problems. Deriving the central learning objective for VI must often be tailored
to new learning tasks where the nature of the problems dictates the conditional
dependence between variables of interest, such as arising in physics problems.
In this paper, we provide an accessible and thorough technical introduction to
VI for forward and inverse problems, guiding the reader through standard
derivations of the VI framework and how it can best be realized through deep
learning. We then review and unify recent literature exemplifying the creative
flexibility allowed by VI. This paper is designed for a general scientific
audience looking to solve physics-based problems with an emphasis on
uncertainty quantification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learn2Aggregate: Supervised Generation of Chvátal-Gomory Cuts Using
  Graph Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06559v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06559v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arnaud Deza, Elias B. Khalil, Zhenan Fan, Zirui Zhou, Yong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present $\textit{Learn2Aggregate}$, a machine learning (ML) framework for
optimizing the generation of Chv\'atal-Gomory (CG) cuts in mixed integer linear
programming (MILP). The framework trains a graph neural network to classify
useful constraints for aggregation in CG cut generation. The ML-driven CG
separator selectively focuses on a small set of impactful constraints,
improving runtimes without compromising the strength of the generated cuts. Key
to our approach is the formulation of a constraint classification task which
favours sparse aggregation of constraints, consistent with empirical findings.
This, in conjunction with a careful constraint labeling scheme and a hybrid of
deep learning and feature engineering, results in enhanced CG cut generation
across five diverse MILP benchmarks. On the largest test sets, our method
closes roughly $\textit{twice}$ as much of the integrality gap as the standard
CG method while running 40$% faster. This performance improvement is due to our
method eliminating 75% of the constraints prior to aggregation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Neural Networks: Multi-Classification and Universal Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Martín Hernández, Enrique Zuazua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We demonstrate that a ReLU deep neural network with a width of $2$ and a
depth of $2N+4M-1$ layers can achieve finite sample memorization for any
dataset comprising $N$ elements in $\mathbb{R}^d$, where $d\ge1,$ and $M$
classes, thereby ensuring accurate classification.
  By modeling the neural network as a time-discrete nonlinear dynamical system,
we interpret the memorization property as a problem of simultaneous or ensemble
controllability. This problem is addressed by constructing the network
parameters inductively and explicitly, bypassing the need for training or
solving any optimization problem.
  Additionally, we establish that such a network can achieve universal
approximation in $L^p(\Omega;\mathbb{R}_+)$, where $\Omega$ is a bounded subset
of $\mathbb{R}^d$ and $p\in[1,\infty)$, using a ReLU deep neural network with a
width of $d+1$. We also provide depth estimates for approximating $W^{1,p}$
functions and width estimates for approximating $L^p(\Omega;\mathbb{R}^m)$ for
$m\geq1$. Our proofs are constructive, offering explicit values for the biases
and weights involved.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modelling Global Trade with Optimal Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06554v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06554v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Gaskin, Marie-Therese Wolfram, Andrew Duncan, Guven Demirel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Global trade is shaped by a complex mix of factors beyond supply and demand,
including tangible variables like transport costs and tariffs, as well as less
quantifiable influences such as political and economic relations.
Traditionally, economists model trade using gravity models, which rely on
explicit covariates but often struggle to capture these subtler drivers of
trade. In this work, we employ optimal transport and a deep neural network to
learn a time-dependent cost function from data, without imposing a specific
functional form. This approach consistently outperforms traditional gravity
models in accuracy while providing natural uncertainty quantification. Applying
our framework to global food and agricultural trade, we show that the global
South suffered disproportionately from the war in Ukraine's impact on wheat
markets. We also analyze the effects of free-trade agreements and trade
disputes with China, as well as Brexit's impact on British trade with Europe,
uncovering hidden patterns that trade volumes alone cannot reveal.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Decoupling of Placid Terminal Attractor-based Gradient Descent
  Algorithm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06542v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06542v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinwei Zhao, Marco Gori, Alessandro Betti, Stefano Melacci, Hongtao Zhang, Jiedong Liu, Xinhong Hei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gradient descent (GD) and stochastic gradient descent (SGD) have been widely
used in a large number of application domains. Therefore, understanding the
dynamics of GD and improving its convergence speed is still of great
importance. This paper carefully analyzes the dynamics of GD based on the
terminal attractor at different stages of its gradient flow. On the basis of
the terminal sliding mode theory and the terminal attractor theory, four
adaptive learning rates are designed. Their performances are investigated in
light of a detailed theoretical investigation, and the running times of the
learning procedures are evaluated and compared. The total times of their
learning processes are also studied in detail. To evaluate their effectiveness,
various simulation results are investigated on a function approximation problem
and an image classification problem.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Functionally Constrained Algorithm Solves Convex Simple Bilevel Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06530v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06530v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huaqing Zhang, Lesi Chen, Jing Xu, Jingzhao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper studies simple bilevel problems, where a convex upper-level
function is minimized over the optimal solutions of a convex lower-level
problem. We first show the fundamental difficulty of simple bilevel problems,
that the approximate optimal value of such problems is not obtainable by
first-order zero-respecting algorithms. Then we follow recent works to pursue
the weak approximate solutions. For this goal, we propose novel near-optimal
methods for smooth and nonsmooth problems by reformulating them into
functionally constrained problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MENSA: A Multi-Event Network for Survival Analysis under Informative
  Censoring <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06525v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06525v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christian Marius Lillelund, Ali Hossein Gharari Foomani, Weijie Sun, Shi-ang Qi, Russell Greiner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given an instance, a multi-event survival model predicts the time until that
instance experiences each of several different events. These events are not
mutually exclusive and there are often statistical dependencies between them.
There are relatively few multi-event survival results, most focusing on
producing a simple risk score, rather than the time-to-event itself. To
overcome these issues, we introduce MENSA, a novel, deep learning approach for
multi-event survival analysis that can jointly learn representations of the
input covariates and the dependence structure between events. As a practical
motivation for multi-event survival analysis, we consider the problem of
predicting the time until a patient with amyotrophic lateral sclerosis (ALS)
loses various physical functions, i.e., the ability to speak, swallow, write,
or walk. When estimating when a patient is no longer able to swallow, our
approach achieves an L1-Margin loss of 278.8 days, compared to 355.2 days when
modeling each event separately. In addition, we also evaluate our approach in
single-event and competing risk scenarios by modeling the censoring and event
distributions as equal contributing factors in the optimization process, and
show that our approach performs well across multiple benchmark datasets. The
source code is available at: https://github.com/thecml/mensa
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning for Koopman Operator Estimation in Idealized Atmospheric
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06522v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06522v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Millard, Arielle Carr, Stéphane Gaudreault
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning is revolutionizing weather forecasting, with new data-driven
models achieving accuracy on par with operational physical models for
medium-term predictions. However, these models often lack interpretability,
making their underlying dynamics difficult to understand and explain. This
paper proposes methodologies to estimate the Koopman operator, providing a
linear representation of complex nonlinear dynamics to enhance the transparency
of data-driven models. Despite its potential, applying the Koopman operator to
large-scale problems, such as atmospheric modeling, remains challenging. This
study aims to identify the limitations of existing methods, refine these models
to overcome various bottlenecks, and introduce novel convolutional neural
network architectures that capture simplified dynamics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Limit Order Book Simulation and Trade Evaluation with
  $K$-Nearest-Neighbor Resampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06514v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06514v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Giegrich, Roel Oomen, Christoph Reisinger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we show how $K$-nearest neighbor ($K$-NN) resampling, an
off-policy evaluation method proposed in \cite{giegrich2023k}, can be applied
to simulate limit order book (LOB) markets and how it can be used to evaluate
and calibrate trading strategies. Using historical LOB data, we demonstrate
that our simulation method is capable of recreating realistic LOB dynamics and
that synthetic trading within the simulation leads to a market impact in line
with the corresponding literature. Compared to other statistical LOB simulation
methods, our algorithm has theoretical convergence guarantees under general
conditions, does not require optimization, is easy to implement and
computationally efficient. Furthermore, we show that in a benchmark comparison
our method outperforms a deep learning-based algorithm for several key
statistics. In the context of a LOB with pro-rata type matching, we demonstrate
how our algorithm can calibrate the size of limit orders for a liquidation
strategy. Finally, we describe how $K$-NN resampling can be modified for
choices of higher dimensional state spaces.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aligning Machine and Human Visual Representations across Abstraction
  Levels 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Muttenthaler, Klaus Greff, Frieda Born, Bernhard Spitzer, Simon Kornblith, Michael C. Mozer, Klaus-Robert Müller, Thomas Unterthiner, Andrew K. Lampinen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks have achieved success across a wide range of
applications, including as models of human behavior in vision tasks. However,
neural network training and human learning differ in fundamental ways, and
neural networks often fail to generalize as robustly as humans do, raising
questions regarding the similarity of their underlying representations. What is
missing for modern learning systems to exhibit more human-like behavior? We
highlight a key misalignment between vision models and humans: whereas human
conceptual knowledge is hierarchically organized from fine- to coarse-scale
distinctions, model representations do not accurately capture all these levels
of abstraction. To address this misalignment, we first train a teacher model to
imitate human judgments, then transfer human-like structure from its
representations into pretrained state-of-the-art vision foundation models.
These human-aligned models more accurately approximate human behavior and
uncertainty across a wide range of similarity tasks, including a new dataset of
human judgments spanning multiple levels of semantic abstractions. They also
perform better on a diverse set of machine learning tasks, increasing
generalization and out-of-distribution robustness. Thus, infusing neural
networks with additional human knowledge yields a best-of-both-worlds
representation that is both more consistent with human cognition and more
practically useful, thus paving the way toward more robust, interpretable, and
human-like artificial intelligence systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>51 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning local and semi-local density functionals from exact
  exchange-correlation potentials and energies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06498v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06498v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bikash Kanungo, Jeffrey Hatch, Paul M. Zimmerman, Vikram Gavini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Finding accurate exchange-correlation (XC) functionals remains the defining
challenge in density functional theory (DFT). Despite 40 years of active
development, the desired chemical accuracy is still elusive with existing
functionals. We present a data-driven pathway to learn the XC functionals by
utilizing the exact density, XC energy, and XC potential. While the exact
densities are obtained from accurate configuration interaction (CI), the exact
XC energies and XC potentials are obtained via inverse DFT calculations on the
CI densities. We demonstrate how simple neural network (NN) based local density
approximation (LDA) and generalized gradient approximation (GGA), trained on
just five atoms and two molecules, provide remarkable improvement in total
energies, densities, atomization energies, and barrier heights for hundreds of
molecules outside the training set. Particularly, the NN-based GGA functional
attains similar accuracy as the higher rung SCAN meta-GGA, highlighting the
promise of using the XC potential in modeling XC functionals. We expect this
approach to pave the way for systematic learning of increasingly accurate and
sophisticated XC functionals.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Superior Computer Chess with Model Predictive Control, Reinforcement
  Learning, and Rollout 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06477v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06477v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atharva Gundawar, Yuchao Li, Dimitri Bertsekas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we apply model predictive control (MPC), rollout, and
reinforcement learning (RL) methodologies to computer chess. We introduce a new
architecture for move selection, within which available chess engines are used
as components. One engine is used to provide position evaluations in an
approximation in value space MPC/RL scheme, while a second engine is used as
nominal opponent, to emulate or approximate the moves of the true opponent
player.
  We show that our architecture improves substantially the performance of the
position evaluation engine. In other words our architecture provides an
additional layer of intelligence, on top of the intelligence of the engines on
which it is based. This is true for any engine, regardless of its strength: top
engines such as Stockfish and Komodo Dragon (of varying strengths), as well as
weaker engines.
  Structurally, our basic architecture selects moves by a one-move lookahead
search, with an intermediate move generated by a nominal opponent engine, and
followed by a position evaluation by another chess engine. Simpler schemes that
forego the use of the nominal opponent, also perform better than the position
evaluator, but not quite by as much. More complex schemes, involving multistep
lookahead, may also be used and generally tend to perform better as the length
of the lookahead increases.
  Theoretically, our methodology relies on generic cost improvement properties
and the superlinear convergence framework of Newton's method, which
fundamentally underlies approximation in value space, and related MPC/RL and
rollout/policy iteration schemes. A critical requirement of this framework is
that the first lookahead step should be executed exactly. This fact has guided
our architectural choices, and is apparently an important factor in improving
the performance of even the best available chess engines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Machine Learning Based Approach for Statistical Analysis of Detonation
  Cells from Soot Foils 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vansh Sharma, Michael Ullman, Venkat Raman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a novel algorithm based on machine learning (ML) for the
precise segmentation and measurement of detonation cells from soot foil images,
addressing the limitations of manual and primitive edge detection methods
prevalent in the field. Using advances in cellular biology segmentation models,
the proposed algorithm is designed to accurately extract cellular patterns
without a training procedure or dataset, which is a significant challenge in
detonation research. The algorithm's performance was validated using a series
of test cases that mimic experimental and numerical detonation studies. The
results demonstrated consistent accuracy, with errors remaining within 10%,
even in complex cases. The algorithm effectively captured key cell metrics such
as cell area and span, revealing trends across different soot foil samples with
uniform to highly irregular cellular structures. Although the model proved
robust, challenges remain in segmenting and analyzing highly complex or
irregular cellular patterns. This work highlights the broad applicability and
potential of the algorithm to advance the understanding of detonation wave
dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 12 figures, submitted to Comb. and Flame</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ransomware Detection Using Machine Learning in the Linux Kernel 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrian Brodzik, Tomasz Malec-Kruszyński, Wojciech Niewolski, Mikołaj Tkaczyk, Krzysztof Bocianiak, Sok-Yen Loui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Linux-based cloud environments have become lucrative targets for ransomware
attacks, employing various encryption schemes at unprecedented speeds.
Addressing the urgency for real-time ransomware protection, we propose
leveraging the extended Berkeley Packet Filter (eBPF) to collect system call
information regarding active processes and infer about the data directly at the
kernel level. In this study, we implement two Machine Learning (ML) models in
eBPF - a decision tree and a multilayer perceptron. Benchmarking latency and
accuracy against their user space counterparts, our findings underscore the
efficacy of this approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06446v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06446v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hossein Hajipour, Lea Schönherr, Thorsten Holz, Mario Fritz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown great potential for automatic code
generation and form the basis for various tools such as GitHub Copilot.
However, recent studies highlight that many LLM-generated code contains serious
security vulnerabilities. While previous work tries to address this by training
models that generate secure code, these attempts remain constrained by limited
access to training data and labor-intensive data preparation.
  In this paper, we introduce HexaCoder, a novel approach to enhance the
ability of LLMs to generate secure codes by automatically synthesizing secure
codes, which reduces the effort of finding suitable training data. HexaCoder
comprises two key components: an oracle-guided data synthesis pipeline and a
two-step process for secure code generation. The data synthesis pipeline
generates pairs of vulnerable and fixed codes for specific Common Weakness
Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing
vulnerable code. A security oracle identifies vulnerabilities, and a
state-of-the-art LLM repairs them by extending and/or editing the codes,
creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA)
method. Each example of our fine-tuning dataset includes the necessary
security-related libraries and code that form the basis of our novel two-step
generation approach. This allows the model to integrate security-relevant
libraries before generating the main code, significantly reducing the number of
generated vulnerable codes by up to 85% compared to the baseline methods. We
perform extensive evaluations on three different benchmarks for four LLMs,
demonstrating that HexaCoder not only improves the security of the generated
code but also maintains a high level of functional correctness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 16 tables, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extending Explainable Ensemble Trees (E2Tree) to regression contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Massimo Aria, Agostino Gnasso, Carmela Iorio, Marjolein Fokkema
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensemble methods such as random forests have transformed the landscape of
supervised learning, offering highly accurate prediction through the
aggregation of multiple weak learners. However, despite their effectiveness,
these methods often lack transparency, impeding users' comprehension of how RF
models arrive at their predictions. Explainable ensemble trees (E2Tree) is a
novel methodology for explaining random forests, that provides a graphical
representation of the relationship between response variables and predictors. A
striking characteristic of E2Tree is that it not only accounts for the effects
of predictor variables on the response but also accounts for associations
between the predictor variables through the computation and use of
dissimilarity measures. The E2Tree methodology was initially proposed for use
in classification tasks. In this paper, we extend the methodology to encompass
regression contexts. To demonstrate the explanatory power of the proposed
algorithm, we illustrate its use on real-world datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Short Information-Theoretic Analysis of Linear Auto-Regressive
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06437v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06437v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ingvar Ziemann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this note, we give a short information-theoretic proof of the consistency
of the Gaussian maximum likelihood estimator in linear auto-regressive models.
Our proof yields nearly optimal non-asymptotic rates for parameter recovery and
works without any invocation of stability in the case of finite hypothesis
classes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fine-tuning and <span class="highlight-title">Prompt</span> Engineering with Cognitive Knowledge Graphs for
  Scholarly Knowledge Organization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06433v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06433v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gollam Rabby, Sören Auer, Jennifer D'Souza, Allard Oelen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing amount of published scholarly articles, exceeding 2.5 million
yearly, raises the challenge for researchers in following scientific progress.
Integrating the contributions from scholarly articles into a novel type of
cognitive knowledge graph (CKG) will be a crucial element for accessing and
organizing scholarly knowledge, surpassing the insights provided by titles and
abstracts. This research focuses on effectively conveying structured scholarly
knowledge by utilizing large language models (LLMs) to categorize scholarly
articles and describe their contributions in a structured and comparable
manner. While previous studies explored language models within specific
research domains, the extensive domain-independent knowledge captured by LLMs
offers a substantial opportunity for generating structured contribution
descriptions as CKGs. Additionally, LLMs offer customizable pathways through
prompt engineering or fine-tuning, thus facilitating to leveraging of smaller
LLMs known for their efficiency, cost-effectiveness, and environmental
considerations. Our methodology involves harnessing LLM knowledge, and
complementing it with domain expert-verified scholarly data sourced from a CKG.
This strategic fusion significantly enhances LLM performance, especially in
tasks like scholarly article categorization and predicate recommendation. Our
method involves fine-tuning LLMs with CKG knowledge and additionally injecting
knowledge from a CKG with a novel prompting technique significantly increasing
the accuracy of scholarly knowledge extraction. We integrated our approach in
the Open Research Knowledge Graph (ORKG), thus enabling precise access to
organized scholarly knowledge, crucially benefiting domain-independent
scholarly knowledge exchange and dissemination among policymakers, industrial
practitioners, and the general public.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spectral Map for Slow Collective Variables, Markovian Dynamics, and
  Transition State Ensembles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06428v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06428v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakub Rydzewski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the behavior of complex molecular systems is a fundamental
problem in physical chemistry. To describe the long-time dynamics of such
systems, which is responsible for their most informative characteristics, we
can identify a few slow collective variables (CVs) while treating the remaining
fast variables as thermal noise. This enables us to simplify the dynamics and
treat it as diffusion in a free-energy landscape spanned by slow CVs,
effectively rendering the dynamics Markovian. Our recent statistical learning
technique, spectral map [Rydzewski, J. Phys. Chem. Lett. 2023, 14, 22,
5216-5220], explores this strategy to learn slow CVs by maximizing a spectral
gap of a transition matrix. In this work, we introduce several advancements
into our framework, using a high-dimensional reversible folding process of a
protein as an example. We implement an algorithm for coarse-graining Markov
transition matrices to partition the reduced space of slow CVs kinetically and
use it to define a transition state ensemble. We show that slow CVs learned by
spectral map closely approach the Markovian limit for an overdamped diffusion.
We demonstrate that coordinate-dependent diffusion coefficients only slightly
affect the constructed free-energy landscapes. Finally, we present how spectral
map can be used to quantify the importance of features and compare slow CVs
with structural descriptors commonly used in protein folding. Overall, we
demonstrate that a single slow CV learned by spectral map can be used as a
physical reaction coordinate to capture essential characteristics of protein
folding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as part of J. Chem. Theory Comput. special issue "Machine
  Learning and Statistical Mechanics: Shared Synergies for Next Generation of
  Chemical Theory and Computation."</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GeMuCo: Generalized Multisensory Correlational Model for Body Schema
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06427v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06427v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kento Kawaharazuka, Kei Okada, Masayuki Inaba
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans can autonomously learn the relationship between sensation and motion
in their own bodies, estimate and control their own body states, and move while
continuously adapting to the current environment. On the other hand, current
robots control their bodies by learning the network structure described by
humans from their experiences, making certain assumptions on the relationship
between sensors and actuators. In addition, the network model does not adapt to
changes in the robot's body, the tools that are grasped, or the environment,
and there is no unified theory, not only for control but also for state
estimation, anomaly detection, simulation, and so on. In this study, we propose
a Generalized Multisensory Correlational Model (GeMuCo), in which the robot
itself acquires a body schema describing the correlation between sensors and
actuators from its own experience, including model structures such as network
input/output. The robot adapts to the current environment by updating this body
schema model online, estimates and controls its body state, and even performs
anomaly detection and simulation. We demonstrate the effectiveness of this
method by applying it to tool-use considering changes in grasping state for an
axis-driven robot, to joint-muscle mapping learning for a musculoskeletal
robot, and to full-body tool manipulation for a low-rigidity plastic-made
humanoid.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at IEEE Robotics and Automation Magazine</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring the Integration of Large Language Models in Industrial Test
  Maintenance Processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ludvig Lemner, Linnea Wahlgren, Gregory Gay, Nasser Mohammadiha, Jingxiong Liu, Joakim Wennerberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Much of the cost and effort required during the software testing process is
invested in performing test maintenance - the addition, removal, or
modification of test cases to keep the test suite in sync with the
system-under-test or to otherwise improve its quality. Tool support could
reduce the cost - and improve the quality - of test maintenance by automating
aspects of the process or by providing guidance and support to developers.
  In this study, we explore the capabilities and applications of large language
models (LLMs) - complex machine learning models adapted to textual analysis -
to support test maintenance. We conducted a case study at Ericsson AB where we
explored the triggers that indicate the need for test maintenance, the actions
that LLMs can take, and the considerations that must be made when deploying
LLMs in an industrial setting. We also proposed and demonstrated
implementations of two multi-agent architectures that can predict which test
cases require maintenance following a change to the source code. Collectively,
these contributions advance our theoretical and practical understanding of how
LLMs can be deployed to benefit industrial test maintenance processes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under submission to ACM TOSEM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Length Desensitization in Directed Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Liu, Yang Bai, Chengcheng Han, Rongxiang Weng, Jun Xu, Xuezhi Cao, Jingang Wang, Xunliang Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) is widely utilized in the Reinforcement
Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs)
with human preferences, thereby enhancing both their harmlessness and efficacy.
However, it has been observed that DPO tends to over-optimize for verbosity,
which can detrimentally affect both performance and user experience. In this
paper, we conduct an in-depth theoretical analysis of DPO's optimization
objective and reveal a strong correlation between its implicit reward and data
length. This correlation misguides the optimization direction, resulting in
length sensitivity during the DPO training and leading to verbosity. To address
this issue, we propose a length-desensitization improvement method for DPO,
termed LD-DPO. The proposed method aims to desensitize DPO to data length by
decoupling explicit length preference, which is relatively insignificant, from
the other implicit preferences, thereby enabling more effective learning of the
intrinsic preferences. We utilized two settings (Base and Instruct) of
Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various
benchmarks including MT-Bench and AlpacaEval 2. The experimental results
indicate that LD-DPO consistently outperforms DPO and other baseline methods,
achieving more concise responses with a 10-40\% reduction in length compared to
DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can
indeed achieve length desensitization and align the model more closely with
human-real preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sources of Uncertainty in 3D Scene Reconstruction <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06407v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06407v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcus Klasson, Riccardo Mereu, Juho Kannala, Arno Solin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The process of 3D scene reconstruction can be affected by numerous
uncertainty sources in real-world scenes. While Neural Radiance Fields (NeRFs)
and 3D Gaussian Splatting (GS) achieve high-fidelity rendering, they lack
built-in mechanisms to directly address or quantify uncertainties arising from
the presence of noise, occlusions, confounding outliers, and imprecise camera
pose inputs. In this paper, we introduce a taxonomy that categorizes different
sources of uncertainty inherent in these methods. Moreover, we extend NeRF- and
GS-based methods with uncertainty estimation techniques, including learning
uncertainty outputs and ensembles, and perform an empirical study to assess
their ability to capture the sensitivity of the reconstruction. Our study
highlights the need for addressing various uncertainty aspects when designing
NeRF/GS-based methods for uncertainty-aware 3D reconstruction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in ECCV 2024 Workshop Proceedings. Project page at
  https://aaltoml.github.io/uncertainty-nerf-gs/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Symmetry Breaking in Neural Network Optimization: Insights from Input
  Dimension Expansion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06402v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06402v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun-Jie Zhang, Nan Cheng, Fu-Peng Li, Xiu-Cheng Wang, Jian-Nan Chen, Long-Gang Pang, Deyu Meng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the mechanisms behind neural network optimization is crucial
for improving network design and performance. While various optimization
techniques have been developed, a comprehensive understanding of the underlying
principles that govern these techniques remains elusive. Specifically, the role
of symmetry breaking, a fundamental concept in physics, has not been fully
explored in neural network optimization. This gap in knowledge limits our
ability to design networks that are both efficient and effective. Here, we
propose the symmetry breaking hypothesis to elucidate the significance of
symmetry breaking in enhancing neural network optimization. We demonstrate that
a simple input expansion can significantly improve network performance across
various tasks, and we show that this improvement can be attributed to the
underlying symmetry breaking mechanism. We further develop a metric to quantify
the degree of symmetry breaking in neural networks, providing a practical
approach to evaluate and guide network design. Our findings confirm that
symmetry breaking is a fundamental principle that underpins various
optimization techniques, including dropout, batch normalization, and
equivariance. By quantifying the degree of symmetry breaking, our work offers a
practical technique for performance enhancement and a metric to guide network
design without the need for complete datasets and extensive training processes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One Policy to Run Them All: an End-to-end Learning Approach to
  Multi-Embodiment Locomotion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06366v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06366v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nico Bohlinger, Grzegorz Czechmanowski, Maciej Krupka, Piotr Kicki, Krzysztof Walas, Jan Peters, Davide Tateo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Reinforcement Learning techniques are achieving state-of-the-art results
in robust legged locomotion. While there exists a wide variety of legged
platforms such as quadruped, humanoids, and hexapods, the field is still
missing a single learning framework that can control all these different
embodiments easily and effectively and possibly transfer, zero or few-shot, to
unseen robot embodiments. We introduce URMA, the Unified Robot Morphology
Architecture, to close this gap. Our framework brings the end-to-end Multi-Task
Reinforcement Learning approach to the realm of legged robots, enabling the
learned policy to control any type of robot morphology. The key idea of our
method is to allow the network to learn an abstract locomotion controller that
can be seamlessly shared between embodiments thanks to our morphology-agnostic
encoders and decoders. This flexible architecture can be seen as a potential
first step in building a foundation model for legged robot locomotion. Our
experiments show that URMA can learn a locomotion policy on multiple
embodiments that can be easily transferred to unseen robot platforms in
simulation and the real world.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What happens to diffusion model likelihood when your model is
  conditional? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06364v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06364v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mattias Cross, Anton Ragni
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion Models (DMs) iteratively denoise random samples to produce
high-quality data. The iterative sampling process is derived from Stochastic
Differential Equations (SDEs), allowing a speed-quality trade-off chosen at
inference. Another advantage of sampling with differential equations is exact
likelihood computation. These likelihoods have been used to rank unconditional
DMs and for out-of-domain classification. Despite the many existing and
possible uses of DM likelihoods, the distinct properties captured are unknown,
especially in conditional contexts such as Text-To-Image (TTI) or
Text-To-Speech synthesis (TTS). Surprisingly, we find that TTS DM likelihoods
are agnostic to the text input. TTI likelihood is more expressive but cannot
discern confounding prompts. Our results show that applying DMs to conditional
tasks reveals inconsistencies and strengthens claims that the properties of DM
likelihood are unknown. This impact sheds light on the previously unknown
nature of DM likelihoods. Although conditional DMs maximise likelihood, the
likelihood in question is not as sensitive to the conditioning input as one
expects. This investigation provides a new point-of-view on diffusion
likelihoods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Connecting Concept Convexity and Human-Machine Alignment in Deep Neural
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06362v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06362v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Teresa Dorszewski, Lenka Tětková, Lorenz Linhardt, Lars Kai Hansen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding how neural networks align with human cognitive processes is a
crucial step toward developing more interpretable and reliable AI systems.
Motivated by theories of human cognition, this study examines the relationship
between \emph{convexity} in neural network representations and
\emph{human-machine alignment} based on behavioral data. We identify a
correlation between these two dimensions in pretrained and fine-tuned vision
transformer models. Our findings suggest that the convex regions formed in
latent spaces of neural networks to some extent align with human-defined
categories and reflect the similarity relations humans use in cognitive tasks.
While optimizing for alignment generally enhances convexity, increasing
convexity through fine-tuning yields inconsistent effects on alignment, which
suggests a complex relationship between the two. This study presents a first
step toward understanding the relationship between the convexity of latent
representations and human-machine alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First two authors contributed equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Double Successive Over-Relaxation Q-Learning with an Extension to Deep
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06356v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06356v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shreyas S R
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Q-learning is a widely used algorithm in reinforcement learning (RL), but its
convergence can be slow, especially when the discount factor is close to one.
Successive Over-Relaxation (SOR) Q-learning, which introduces a relaxation
factor to speed up convergence, addresses this issue but has two major
limitations: In the tabular setting, the relaxation parameter depends on
transition probability, making it not entirely model-free, and it suffers from
overestimation bias. To overcome these limitations, we propose a sample-based,
model-free double SOR Q-learning algorithm. Theoretically and empirically, this
algorithm is shown to be less biased than SOR Q-learning. Further, in the
tabular setting, the convergence analysis under boundedness assumptions on
iterates is discussed. The proposed algorithm is extended to large-scale
problems using deep RL. Finally, the tabular version of the proposed algorithm
is compared using roulette and grid world environments, while the deep RL
version is tested on a maximization bias example and OpenAI Gym environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Conditional Level Generation using Automated Validation in
  Match-3 Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06349v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06349v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Monica Villanueva Aylagas, Joakim Bergdahl, Jonas Gillberg, Alessandro Sestini, Theodor Tolstoy, Linus Gisslén
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models for level generation have shown great potential in game
production. However, they often provide limited control over the generation,
and the validity of the generated levels is unreliable. Despite this fact, only
a few approaches that learn from existing data provide the users with ways of
controlling the generation, simultaneously addressing the generation of
unsolvable levels. %One of the main challenges it faces is that levels
generated through automation may not be solvable thus requiring validation. are
not always engaging, challenging, or even solvable. This paper proposes Avalon,
a novel method to improve models that learn from existing level designs using
difficulty statistics extracted from gameplay. In particular, we use a
conditional variational autoencoder to generate layouts for match-3 levels,
conditioning the model on pre-collected statistics such as game mechanics like
difficulty and relevant visual features like size and symmetry. Our method is
general enough that multiple approaches could potentially be used to generate
these statistics. We quantitatively evaluate our approach by comparing it to an
ablated model without difficulty conditioning. Additionally, we analyze both
quantitatively and qualitatively whether the style of the dataset is preserved
in the generated levels. Our approach generates more valid levels than the same
method without difficulty conditioning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Compute-Update Federated Learning: A Lattice Coding Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06343v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06343v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seyed Mohammad Azimi-Abarghouyi, Lav R. Varshney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a federated learning framework that enables
over-the-air computation via digital communications, using a new joint
source-channel coding scheme. Without relying on channel state information at
devices, this scheme employs lattice codes to both quantize model parameters
and exploit interference from the devices. We propose a novel receiver
structure at the server, designed to reliably decode an integer combination of
the quantized model parameters as a lattice point for the purpose of
aggregation. We present a mathematical approach to derive a convergence bound
for the proposed scheme and offer design remarks. In this context, we suggest
an aggregation metric and a corresponding algorithm to determine effective
integer coefficients for the aggregation in each communication round. Our
results illustrate that, regardless of channel dynamics and data heterogeneity,
our scheme consistently delivers superior learning accuracy across various
parameters and markedly surpasses other over-the-air methodologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Extended version of the preprint available at arXiv:2403.01023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modified Meta-Thompson Sampling for Linear Bandits and Its Bayes Regret
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06329v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06329v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Li, Dong Liang, Zheng Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Meta-learning is characterized by its ability to learn how to learn, enabling
the adaptation of learning strategies across different tasks. Recent research
introduced the Meta-Thompson Sampling (Meta-TS), which meta-learns an unknown
prior distribution sampled from a meta-prior by interacting with bandit
instances drawn from it. However, its analysis was limited to Gaussian bandit.
The contextual multi-armed bandit framework is an extension of the Gaussian
Bandit, which challenges agent to utilize context vectors to predict the most
valuable arms, optimally balancing exploration and exploitation to minimize
regret over time. This paper introduces Meta-TSLB algorithm, a modified Meta-TS
for linear contextual bandits. We theoretically analyze Meta-TSLB and derive an
$ O\left( \left( m+\log \left( m \right) \right) \sqrt{n\log \left( n \right)}
\right)$ bound on its Bayes regret, in which $m$ represents the number of
bandit instances, and $n$ the number of rounds of Thompson Sampling.
Additionally, our work complements the analysis of Meta-TS for linear
contextual bandits. The performance of Meta-TSLB is evaluated experimentally
under different settings, and we experimente and analyze the generalization
capability of Meta-TSLB, showcasing its potential to adapt to unseen instances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for
  Heterogeneous Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06323v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06323v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siqing Li, Jin-Duk Park, Wei Huang, Xin Cao, Won-Yong Shin, Zhiqiang Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Heterogeneous graph neural networks (HGNNs) have significantly propelled the
information retrieval (IR) field. Still, the effectiveness of HGNNs heavily
relies on high-quality labels, which are often expensive to acquire. This
challenge has shifted attention towards Heterogeneous Graph Contrastive
Learning (HGCL), which usually requires pre-defined meta-paths. However, our
findings reveal that meta-path combinations significantly affect performance in
unsupervised settings, an aspect often overlooked in current literature.
Existing HGCL methods have considerable variability in outcomes across
different meta-path combinations, thereby challenging the optimization process
to achieve consistent and high performance. In response, we introduce
\textsf{LAMP} (\underline{\textbf{L}}earn\underline{\textbf{A}}ble
\underline{\textbf{M}}eta-\underline{\textbf{P}}ath), a novel adversarial
contrastive learning approach that integrates various meta-path sub-graphs into
a unified and stable structure, leveraging the overlap among these sub-graphs.
To address the denseness of this integrated sub-graph, we propose an
adversarial training strategy for edge pruning, maintaining sparsity to enhance
model performance and robustness. \textsf{LAMP} aims to maximize the difference
between meta-path and network schema views for guiding contrastive learning to
capture the most meaningful information. Our extensive experimental study
conducted on four diverse datasets from the Heterogeneous Graph Benchmark (HGB)
demonstrates that \textsf{LAMP} significantly outperforms existing
state-of-the-art unsupervised models in terms of accuracy and robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rate-Constrained Quantization for Communication-Efficient Federated
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shayan Mohajer Hamidi, Ali Bereyhi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quantization is a common approach to mitigate the communication cost of
federated learning (FL). In practice, the quantized local parameters are
further encoded via an entropy coding technique, such as Huffman coding, for
efficient data compression. In this case, the exact communication overhead is
determined by the bit rate of the encoded gradients. Recognizing this fact,
this work deviates from the existing approaches in the literature and develops
a novel quantized FL framework, called \textbf{r}ate-\textbf{c}onstrained
\textbf{fed}erated learning (RC-FED), in which the gradients are quantized
subject to both fidelity and data rate constraints. We formulate this scheme,
as a joint optimization in which the quantization distortion is minimized while
the rate of encoded gradients is kept below a target threshold. This enables
for a tunable trade-off between quantization distortion and communication cost.
We analyze the convergence behavior of RC-FED, and show its superior
performance against baseline quantized FL schemes on several datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PharmacoMatch: Efficient 3D Pharmacophore Screening through Neural
  Subgraph Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Rose, Oliver Wieder, Thomas Seidel, Thierry Langer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing size of screening libraries poses a significant challenge for
the development of virtual screening methods for drug discovery, necessitating
a re-evaluation of traditional approaches in the era of big data. Although 3D
pharmacophore screening remains a prevalent technique, its application to very
large datasets is limited by the computational cost associated with matching
query pharmacophores to database ligands. In this study, we introduce
PharmacoMatch, a novel contrastive learning approach based on neural subgraph
matching. Our method reinterprets pharmacophore screening as an approximate
subgraph matching problem and enables efficient querying of conformational
databases by encoding query-target relationships in the embedding space. We
conduct comprehensive evaluations of the learned representations and benchmark
our method on virtual screening datasets in a zero-shot setting. Our findings
demonstrate significantly shorter runtimes for pharmacophore matching, offering
a promising speed-up for screening very large datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ User Preferences for Large Language Model versus Template-Based
  Explanations of Movie Recommendations: A Pilot Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julien Albert, Martin Balfroid, Miriam Doh, Jeremie Bogaert, Luca La Fisca, Liesbet De Vos, Bryan Renard, Vincent Stragier, Emmanuel Jean
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems have become integral to our digital experiences, from
online shopping to streaming platforms. Still, the rationale behind their
suggestions often remains opaque to users. While some systems employ a
graph-based approach, offering inherent explainability through paths
associating recommended items and seed items, non-experts could not easily
understand these explanations. A popular alternative is to convert graph-based
explanations into textual ones using a template and an algorithm, which we
denote here as ''template-based'' explanations. Yet, these can sometimes come
across as impersonal or uninspiring. A novel method would be to employ large
language models (LLMs) for this purpose, which we denote as ''LLM-based''. To
assess the effectiveness of LLMs in generating more resonant explanations, we
conducted a pilot study with 25 participants. They were presented with three
explanations: (1) traditional template-based, (2) LLM-based rephrasing of the
template output, and (3) purely LLM-based explanations derived from the
graph-based explanations. Although subject to high variance, preliminary
findings suggest that LLM-based explanations may provide a richer and more
engaging user experience, further aligning with user expectations. This study
sheds light on the potential limitations of current explanation methods and
offers promising directions for leveraging large language models to improve
user satisfaction and trust in recommender systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented to the Dutch-Belgian Workshop on Recommender Systems 2023
  (14-15 December, 2023 - Antwerp, Belgium)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automate Strategy Finding with LLM in Quant investment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06289v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06289v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhizhuo Kou, Holam Yu, Jingshu Peng, Lei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant progress in deep learning for financial trading, existing
models often face instability and high uncertainty, hindering their practical
application. Leveraging advancements in Large Language Models (LLMs) and
multi-agent architectures, we propose a novel framework for quantitative stock
investment in portfolio management and alpha mining. Our framework addresses
these issues by integrating LLMs to generate diversified alphas and employing a
multi-agent approach to dynamically evaluate market conditions. This paper
proposes a framework where large language models (LLMs) mine alpha factors from
multimodal financial data, ensuring a comprehensive understanding of market
dynamics. The first module extracts predictive signals by integrating numerical
data, research papers, and visual charts. The second module uses ensemble
learning to construct a diverse pool of trading agents with varying risk
preferences, enhancing strategy performance through a broader market analysis.
In the third module, a dynamic weight-gating mechanism selects and assigns
weights to the most relevant agents based on real-time market conditions,
enabling the creation of an adaptive and context-aware composite alpha formula.
Extensive experiments on the Chinese stock markets demonstrate that this
framework significantly outperforms state-of-the-art baselines across multiple
financial metrics. The results underscore the efficacy of combining
LLM-generated alphas with a multi-agent architecture to achieve superior
trading performance and stability. This work highlights the potential of
AI-driven approaches in enhancing quantitative investment strategies and sets a
new benchmark for integrating advanced machine learning techniques in financial
trading can also be applied on diverse markets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Augmentation Policies from A Model Zoo for Time Series
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06282v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06282v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haochen Yuan, Xuelin Li, Yunbo Wang, Xiaokang Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series forecasting models typically rely on a fixed-size training set
and treat all data uniformly, which may not effectively capture the specific
patterns present in more challenging training samples. To address this issue,
we introduce AutoTSAug, a learnable data augmentation method based on
reinforcement learning. Our approach begins with an empirical analysis to
determine which parts of the training data should be augmented. Specifically,
we identify the so-called marginal samples by considering the prediction
diversity across a set of pretrained forecasting models. Next, we propose using
variational masked autoencoders as the augmentation model and applying the
REINFORCE algorithm to transform the marginal samples into new data. The goal
of this generative model is not only to mimic the distribution of real data but
also to reduce the variance of prediction errors across the model zoo. By
augmenting the marginal samples with a learnable policy, AutoTSAug
substantially improves forecasting performance, advancing the prior art in this
field with minimal additional computational cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ferret: Federated Full-Parameter Tuning at Scale for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06277v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06277v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yao Shu, Wenyang Hu, See-Kiong Ng, Bryan Kian Hsiang Low, Fei Richard Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have become indispensable in numerous real-world
applications. Unfortunately, fine-tuning these models at scale, especially in
federated settings where data privacy and communication efficiency are
critical, presents significant challenges. Existing methods often resort to
parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but
this typically comes at the cost of model accuracy. To address these
limitations, we propose federated full-parameter tuning at scale for LLMs
(Ferret), the first first-order method with shared randomness to enable
scalable full-parameter tuning of LLMs across decentralized data sources while
maintaining competitive model accuracy. Ferret accomplishes this through three
aspects: (1) it employs widely applied first-order methods for efficient local
updates; (2) it projects these updates into a low-dimensional space to
considerably reduce communication overhead; and (3) it reconstructs local
updates from this low-dimensional space with shared randomness to facilitate
effective full-parameter global aggregation, ensuring fast convergence and
competitive final performance. Our rigorous theoretical analyses and insights
along with extensive experiments, show that Ferret significantly enhances the
scalability of existing federated full-parameter tuning approaches by achieving
high computational efficiency, reduced communication overhead, and fast
convergence, all while maintaining competitive model accuracy. Our
implementation is available at https://github.com/allen4747/Ferret.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A new paradigm for global sensitivity analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gildas Mazo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  <div><p>Current theory of global sensitivity analysis, based on a nonlinear
functional ANOVA decomposition of the random output, is limited in scope-for
instance, the analysis is limited to the output's variance and the inputs have
to be mutually independent-and leads to sensitivity indices the interpretation
of which is not fully clear, especially interaction effects. Alternatively,
sensitivity indices built for arbitrary user-defined importance measures have
been proposed but a theory to define interactions in a systematic fashion
and/or establish a decomposition of the total importance measure is still
missing. It is shown that these important problems are solved all at once by
adopting a new paradigm. By partitioning the inputs into those causing the
change in the output and those which do not, arbitrary user-defined variability
measures are identified with the outcomes of a factorial experiment at two
levels, leading to all factorial effects without assuming any functional
decomposition. To link various well-known sensitivity indices of the literature
(Sobol indices and Shapley effects), weighted factorial effects are studied and
utilized.</p></div>
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Robust Uncertainty-Aware Incomplete Multi-View Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06270v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06270v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mulin Chen, Haojian Huang, Qiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Handling incomplete data in multi-view classification is challenging,
especially when traditional imputation methods introduce biases that compromise
uncertainty estimation. Existing Evidential Deep Learning (EDL) based
approaches attempt to address these issues, but they often struggle with
conflicting evidence due to the limitations of the Dempster-Shafer combination
rule, leading to unreliable decisions. To address these challenges, we propose
the Alternating Progressive Learning Network (APLN), specifically designed to
enhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates
bias from corrupted observed data by first applying coarse imputation, followed
by mapping the data to a latent space. In this latent space, we progressively
learn an evidence distribution aligned with the target domain, incorporating
uncertainty considerations through EDL. Additionally, we introduce a
conflict-aware Dempster-Shafer combination rule (DSCR) to better handle
conflicting evidence. By sampling from the learned distribution, we optimize
the latent representations of missing views, reducing bias and enhancing
decision-making robustness. Extensive experiments demonstrate that APLN,
combined with DSCR, significantly outperforms traditional methods, particularly
in environments characterized by high uncertainty and conflicting evidence,
establishing it as a promising solution for incomplete multi-view
classification.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work: 9 pages, 6 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Market Reaction to News Flows in Supply Chain Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06255v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06255v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hiroyasu Inoue, Yasuyuki Todo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study examines whether positive news about firms increases their stock
prices and, moreover, whether it increases stock prices of the firms' suppliers
and customers, using a large sample of publicly listed firms across the world
and another of Japanese listed firms. The level of positiveness of each news
article is determined by FinBERT, a natural language processing model
fine-tuned specifically for financial information. Supply chains of firms
across the world are identified mostly by financial statements, while those of
Japanese firms are taken from large-scale firm-level surveys. We find that
positive news increases the change rate of stock prices of firms mentioned in
the news before its disclosure, most likely because of diffusion of information
through informal channels. Positive news also raises stock prices of the firms'
suppliers and customers before its disclosure, confirming propagation of market
values through supply chains. In addition, we generally find a larger post-news
effect on stock prices of the mentioned firms and their suppliers and customers
than the pre-news effect. The positive difference between the post- and
pre-news effects can be considered as the net effect of the disclosure of
positive news, controlling for informal information diffusion. However, the
post-news effect on suppliers and customers in Japan is smaller than the
pre-news effect, a result opposite to those from firms across the world. This
notable result is possibly because supply chain links of Japanese firms are
stronger than global supply chains while such knowledge is restricted to
selected investors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiPT: Enhancing LLM reasoning through diversified perspective-taking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06241v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06241v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hoang Anh Just, Mahavir Dabas, Lifu Huang, Ming Jin, Ruoxi Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing work on improving language model reasoning typically explores a
single solution path, which can be prone to errors. Inspired by
perspective-taking in social studies, this paper introduces DiPT, a novel
approach that complements current reasoning methods by explicitly incorporating
diversified viewpoints. This approach allows the model to gain a deeper
understanding of the problem's context and identify the most effective solution
path during the inference stage. Additionally, it provides a general
data-centric AI recipe for augmenting existing data to improve their quality
for fine-tuning.
  Our empirical results demonstrate that DiPT can be flexibly integrated into
existing methods that focus on a single reasoning approach, enhancing their
reasoning performance and stability when presented with paraphrased problems.
Furthermore, we illustrate improved context understanding by maintaining the
model's safe outputs against "jailbreaking" prompts intentionally designed to
bypass safeguards built into deployed models. Lastly, we show that fine-tuning
with data enriched with diverse perspectives can boost the reasoning
capabilities of the model compared to fine-tuning with raw data alone.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>LLM Reasoning with Perspectives, Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recurrent Neural Networks for Still Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06235v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06235v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Dmitri,  Lvov, Yair Smadar, Ran Bezen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we explore the application of Recurrent Neural Network (RNN)
for still images. Typically, Convolutional Neural Networks (CNNs) are the
prevalent method applied for this type of data, and more recently, transformers
have gained popularity, although they often require large models. Unlike these
methods, RNNs are generally associated with processing sequences over time
rather than single images. We argue that RNNs can effectively handle still
images by interpreting the pixels as a sequence. This approach could be
particularly advantageous for compact models designed for embedded systems,
where resources are limited. Additionally, we introduce a novel RNN design
tailored for two-dimensional inputs, such as images, and a custom version of
BiDirectional RNN (BiRNN) that is more memory-efficient than traditional
implementations. In our research, we have tested these layers in Convolutional
Recurrent Neural Networks (CRNNs), predominantly composed of Conv2D layers,
with RNN layers at or close to the end. Experiments on the COCO and CIFAR100
datasets show better results, particularly for small networks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NLP-Powered Repository and Search Engine for Academic Papers: A Case
  Study on Cyber Risk Literature with CyLit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06226v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06226v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linfeng Zhang, Changyue Hu, Zhiyu Quan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the body of academic literature continues to grow, researchers face
increasing difficulties in effectively searching for relevant resources.
Existing databases and search engines often fall short of providing a
comprehensive and contextually relevant collection of academic literature. To
address this issue, we propose a novel framework that leverages Natural
Language Processing (NLP) techniques. This framework automates the retrieval,
summarization, and clustering of academic literature within a specific research
domain. To demonstrate the effectiveness of our approach, we introduce CyLit,
an NLP-powered repository specifically designed for the cyber risk literature.
CyLit empowers researchers by providing access to context-specific resources
and enabling the tracking of trends in the dynamic and rapidly evolving field
of cyber risk. Through the automatic processing of large volumes of data, our
NLP-powered solution significantly enhances the efficiency and specificity of
academic literature searches. We compare the literature categorization results
of CyLit to those presented in survey papers or generated by ChatGPT,
highlighting the distinctive insights this tool provides into cyber risk
research literature. Using NLP techniques, we aim to revolutionize the way
researchers discover, analyze, and utilize academic resources, ultimately
fostering advancements in various domains of knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIP-GAF: A MLLM-annotated Benchmark for Most Important Person
  Localization and Group Context Understanding <span class="chip">WACV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06224v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06224v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Surbhi Madan, Shreya Ghosh, Lownish Rai Sookha, M. A. Ganaie, Ramanathan Subramanian, Abhinav Dhall, Tom Gedeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the Most Important Person (MIP) in any social event setup is a
challenging problem mainly due to contextual complexity and scarcity of labeled
data. Moreover, the causality aspects of MIP estimation are quite subjective
and diverse. To this end, we aim to address the problem by annotating a
large-scale `in-the-wild' dataset for identifying human perceptions about the
`Most Important Person (MIP)' in an image. The paper provides a thorough
description of our proposed Multimodal Large Language Model (MLLM) based data
annotation strategy, and a thorough data quality analysis. Further, we perform
a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art
MIP localization methods, indicating a significant drop in performance compared
to existing datasets. The performance drop shows that the existing MIP
localization algorithms must be more robust with respect to `in-the-wild'
situations. We believe the proposed dataset will play a vital role in building
the next-generation social situation understanding methods. The code and data
is available at https://github.com/surbhimadan92/MIP-GAF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at WACV 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Denoising: A Powerful Building-Block for Imaging, Inverse Problems, and
  Machine Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peyman Milanfar, Mauricio Delbracio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Denoising, the process of reducing random fluctuations in a signal to
emphasize essential patterns, has been a fundamental problem of interest since
the dawn of modern scientific inquiry. Recent denoising techniques,
particularly in imaging, have achieved remarkable success, nearing theoretical
limits by some measures. Yet, despite tens of thousands of research papers, the
wide-ranging applications of denoising beyond noise removal have not been fully
recognized. This is partly due to the vast and diverse literature, making a
clear overview challenging.
  This paper aims to address this gap. We present a comprehensive perspective
on denoisers, their structure, and desired properties. We emphasize the
increasing importance of denoising and showcase its evolution into an essential
building block for complex tasks in imaging, inverse problems, and machine
learning. Despite its long history, the community continues to uncover
unexpected and groundbreaking uses for denoising, further solidifying its place
as a cornerstone of scientific and engineering practice.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06211v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06211v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaeseong Lee, seung-won hwang, Aurick Qiao, Daniel F Campos, Zhewei Yao, Yuxiong He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-experts (MoEs) have been adopted for reducing inference costs by
sparsely activating experts in Large language models (LLMs). Despite this
reduction, the massive number of experts in MoEs still makes them expensive to
serve. In this paper, we study how to address this, by pruning MoEs. Among
pruning methodologies, unstructured pruning has been known to achieve the
highest performance for a given pruning ratio, compared to structured pruning,
since the latter imposes constraints on the sparsification structure. This is
intuitive, as the solution space of unstructured pruning subsumes that of
structured pruning. However, our counterintuitive finding reveals that expert
pruning, a form of structured pruning, can actually precede unstructured
pruning to outperform unstructured-only pruning. As existing expert pruning,
requiring $O(\frac{k^n}{\sqrt{n}})$ forward passes for $n$ experts, cannot
scale for recent MoEs, we propose a scalable alternative with $O(1)$
complexity, yet outperforming the more expensive methods. The key idea is
leveraging a latent structure between experts, based on behavior similarity,
such that the greedy decision of whether to prune closely captures the joint
pruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized
MoE with 128 experts, our method needs only one H100 and two hours to achieve
nearly no loss in performance with 40% sparsity, even in generative tasks such
as GSM8K, where state-of-the-art unstructured pruning fails to. The code will
be made publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive <span class="highlight-title">Transformer</span> Modelling of Density Function for Nonparametric
  Survival Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06209v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06209v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Zhang, Deval Mehta, Yanan Hu, Chao Zhu, David Darby, Zhen Yu, Daniel Merlo, Melissa Gresle, Anneke Van Der Walt, Helmut Butzkueven, Zongyuan Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Survival analysis holds a crucial role across diverse disciplines, such as
economics, engineering and healthcare. It empowers researchers to analyze both
time-invariant and time-varying data, encompassing phenomena like customer
churn, material degradation and various medical outcomes. Given the complexity
and heterogeneity of such data, recent endeavors have demonstrated successful
integration of deep learning methodologies to address limitations in
conventional statistical approaches. However, current methods typically involve
cluttered probability distribution function (PDF), have lower sensitivity in
censoring prediction, only model static datasets, or only rely on recurrent
neural networks for dynamic modelling. In this paper, we propose a novel
survival regression method capable of producing high-quality unimodal PDFs
without any prior distribution assumption, by optimizing novel
Margin-Mean-Variance loss and leveraging the flexibility of Transformer to
handle both temporal and non-temporal data, coined UniSurv. Extensive
experiments on several datasets demonstrate that UniSurv places a significantly
higher emphasis on censoring compared to other methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MTDA-HSED: Mutual-Assistance Tuning and Dual-Branch Aggregating for
  Heterogeneous Sound Event Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06196v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06196v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zehao Wang, Haobo Yue, Zhicheng Zhang, Da Mu, Jin Tang, Jianqin Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sound Event Detection (SED) plays a vital role in comprehending and
perceiving acoustic scenes. Previous methods have demonstrated impressive
capabilities. However, they are deficient in learning features of complex
scenes from heterogeneous dataset. In this paper, we introduce a novel
dual-branch architecture named Mutual-Assistance Tuning and Dual-Branch
Aggregating for Heterogeneous Sound Event Detection (MTDA-HSED). The MTDA-HSED
architecture employs the Mutual-Assistance Audio Adapter (M3A) to effectively
tackle the multi-scenario problem and uses the Dual-Branch Mid-Fusion (DBMF)
module to tackle the multi-granularity problem. Specifically, M3A is integrated
into the BEATs block as an adapter to improve the BEATs' performance by
fine-tuning it on the multi-scenario dataset. The DBMF module connects BEATs
and CNN branches, which facilitates the deep fusion of information from the
BEATs and the CNN branches. Experimental results show that the proposed methods
exceed the baseline of mpAUC by \textbf{$5\%$} on the DESED and MAESTRO Real
datasets. Code is \href{https://github.com/Visitor-W/MTDA}{here}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submit to Icassp2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Source Music Generation with Latent Diffusion <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06190v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06190v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhongweiyang Xu, Debottam Dutta, Yu-Lin Wei, Romit Roy Choudhury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most music generation models directly generate a single music mixture. To
allow for more flexible and controllable generation, the Multi-Source Diffusion
Model (MSDM) has been proposed to model music as a mixture of multiple
instrumental sources (e.g., piano, drums, bass, and guitar). Its goal is to use
one single diffusion model to generate consistent music sources, which are
further mixed to form the music. Despite its capabilities, MSDM is unable to
generate songs with rich melodies and often generates empty sounds. Also, its
waveform diffusion introduces significant Gaussian noise artifacts, which
compromises audio quality. In response, we introduce a multi-source latent
diffusion model (MSLDM) that employs Variational Autoencoders (VAEs) to encode
each instrumental source into a distinct latent representation. By training a
VAE on all music sources, we efficiently capture each source's unique
characteristics in a source latent that our diffusion model models jointly.
This approach significantly enhances the total and partial generation of music
by leveraging the VAE's latent compression and noise-robustness. The compressed
source latent also facilitates more efficient generation. Subjective listening
tests and Frechet Audio Distance (FAD) scores confirm that our model
outperforms MSDM, showcasing its practical and enhanced applicability in music
generation systems. We also emphasize that modeling sources is more effective
than direct music mixture modeling. Codes and models are available at
https://github.com/XZWY/MSLDM. Demos are available at
https://xzwy.github.io/MSLDMDemo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICASSP 2025 in Submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bottleneck-based Encoder-decoder ARchitecture (BEAR) for Learning
  Unbiased Consumer-to-Consumer Image Representations <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06187v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06187v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pablo Rivas, Gisela Bichler, Tomas Cerny, Laurie Giddens, Stacie Petter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unbiased representation learning is still an object of study under specific
applications and contexts. Novel architectures are usually crafted to resolve
particular problems using mixtures of fundamental pieces. This paper presents
different image feature extraction mechanisms that work together with residual
connections to encode perceptual image information in an autoencoder
configuration. We use image data that aims to support a larger research agenda
dealing with issues regarding criminal activity in consumer-to-consumer online
platforms. Preliminary results suggest that the proposed architecture can learn
rich spaces using ours and other image datasets resolving important challenges
that are identified.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2022 LXAI Workshop at the 39th International Conference on Machine
  Learning (ICML), Baltimore, Maryland</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Large Language Models Unlock Novel Scientific Research Ideas? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06185v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06185v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sandeep Kumar, Tirthankar Ghosal, Vinayak Goyal, Asif Ekbal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  "An idea is nothing more nor less than a new combination of old elements"
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 12 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Loss Distillation via Gradient Matching for Point Cloud Completion with
  Weighted Chamfer Distance <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06171v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06171v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fangzhou Lin, Haotian Liu, Haoying Zhou, Songlin Hou, Kazunori D Yamada, Gregory S. Fischer, Yanhua Li, Haichong K. Zhang, Ziming Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D point clouds enhanced the robot's ability to perceive the geometrical
information of the environments, making it possible for many downstream tasks
such as grasp pose detection and scene understanding. The performance of these
tasks, though, heavily relies on the quality of data input, as incomplete can
lead to poor results and failure cases. Recent training loss functions designed
for deep learning-based point cloud completion, such as Chamfer distance (CD)
and its variants (\eg HyperCD ), imply a good gradient weighting scheme can
significantly boost performance. However, these CD-based loss functions usually
require data-related parameter tuning, which can be time-consuming for
data-extensive tasks. To address this issue, we aim to find a family of
weighted training losses ({\em weighted CD}) that requires no parameter tuning.
To this end, we propose a search scheme, {\em Loss Distillation via Gradient
Matching}, to find good candidate loss functions by mimicking the learning
behavior in backpropagation between HyperCD and weighted CD. Once this is done,
we propose a novel bilevel optimization formula to train the backbone network
based on the weighted CD loss. We observe that: (1) with proper weighted
functions, the weighted CD can always achieve similar performance to HyperCD,
and (2) the Landau weighted CD, namely {\em Landau CD}, can outperform HyperCD
for point cloud completion and lead to new state-of-the-art results on several
benchmark datasets. {\it Our demo code is available at
\url{https://github.com/Zhang-VISLab/IROS2024-LossDistillationWeightedCD}.}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures, 7 tables, this paper was accepted to IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VE: Modeling Multivariate Time Series Correlation with Variate Embedding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06169v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06169v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shangjiong Wang, Zhihong Man, Zhengwei Cao, Jinchuan Zheng, Zhikang Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multivariate time series forecasting relies on accurately capturing the
correlations among variates. Current channel-independent (CI) models and models
with a CI final projection layer are unable to capture these dependencies. In
this paper, we present the variate embedding (VE) pipeline, which learns a
unique and consistent embedding for each variate and combines it with Mixture
of Experts (MoE) and Low-Rank Adaptation (LoRA) techniques to enhance
forecasting performance while controlling parameter size. The VE pipeline can
be integrated into any model with a CI final projection layer to improve
multivariate forecasting. The learned VE effectively groups variates with
similar temporal patterns and separates those with low correlations. The
effectiveness of the VE pipeline is demonstrated through extensive experiments
on four widely-used datasets. The code is available at:
\url{https://github.com/swang-song/VE}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MCDGLN: Masked Connection-based Dynamic Graph Learning Network for
  Autism Spectrum Disorder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06163v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06163v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Wang, Xin Wen, Ruochen Cao, Chengxin Gao, Yanrong Hao, Rui Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized
by complex physiological processes. Previous research has predominantly focused
on static cerebral interactions, often neglecting the brain's dynamic nature
and the challenges posed by network noise. To address these gaps, we introduce
the Masked Connection-based Dynamic Graph Learning Network (MCDGLN). Our
approach first segments BOLD signals using sliding temporal windows to capture
dynamic brain characteristics. We then employ a specialized weighted edge
aggregation (WEA) module, which uses the cross convolution with channel-wise
element-wise convolutional kernel, to integrate dynamic functional connectivity
and to isolating task-relevant connections. This is followed by topological
feature extraction via a hierarchical graph convolutional network (HGCN), with
key attributes highlighted by a self-attention module. Crucially, we refine
static functional connections using a customized task-specific mask, reducing
noise and pruning irrelevant links. The attention-based connection encoder
(ACE) then enhances critical connections and compresses static features. The
combined features are subsequently used for classification. Applied to the
Autism Brain Imaging Data Exchange I (ABIDE I) dataset, our framework achieves
a 73.3\% classification accuracy between ASD and Typical Control (TC) groups
among 1,035 subjects. The pivotal roles of WEA and ACE in refining connectivity
and enhancing classification accuracy underscore their importance in capturing
ASD-specific features, offering new insights into the disorder.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causal Analysis of Shapley Values: Conditional vs. Marginal 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06157v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06157v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilya Rozenfeld
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Shapley values, a game theoretic concept, has been one of the most popular
tools for explaining Machine Learning (ML) models in recent years.
Unfortunately, the two most common approaches, conditional and marginal, to
calculating Shapley values can lead to different results along with some
undesirable side effects when features are correlated. This in turn has led to
the situation in the literature where contradictory recommendations regarding
choice of an approach are provided by different authors. In this paper we aim
to resolve this controversy through the use of causal arguments. We show that
the differences arise from the implicit assumptions that are made within each
method to deal with missing causal information. We also demonstrate that the
conditional approach is fundamentally unsound from a causal perspective. This,
together with previous work in [1], leads to the conclusion that the marginal
approach should be preferred over the conditional one.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Configuration Interaction Guided Sampling with Interpretable Restricted
  Boltzmann Machine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06146v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06146v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jorge I. Hernandez-Martinez, Gerardo Rodriguez-Hernandez, Andres Mendez-Vazquez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a data-driven approach using a Restricted Boltzmann Machine (RBM)
to solve the Schr\"odinger equation in configuration space. Traditional
Configuration Interaction (CI) methods, while powerful, are computationally
expensive due to the large number of determinants required. Our approach
leverages RBMs to efficiently identify and sample the most significant
determinants, accelerating convergence and reducing computational cost. This
method achieves up to 99.99\% of the correlation energy even by four orders of
magnitude less determinants compared to full CI calculations and up to two
orders of magnitude less than previous state of the art works. Additionally,
our study demonstrate that the RBM can learn the underlying quantum properties,
providing more detail insights than other methods . This innovative data-driven
approach offers a promising tool for quantum chemistry, enhancing both
efficiency and understanding of complex systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint to be submitted to Computer Physics Communications</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Variational Search Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06142v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06142v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel M. Steinberg, Rafael Oliveira, Cheng Soon Ong, Edwin V. Bonilla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop variational search distributions (VSD), a method for finding
discrete, combinatorial designs of a rare desired class in a batch sequential
manner with a fixed experimental budget. We formalize the requirements and
desiderata for this problem and formulate a solution via variational inference
that fulfill these. In particular, VSD uses off-the-shelf gradient based
optimization routines, and can take advantage of scalable predictive models. We
show that VSD can outperform existing baseline methods on a set of real
sequence-design problems in various biological systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 5 figures, Appendix material included</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DECOLLAGE: 3D Detailization by Controllable, Localized, and Learned
  Geometry Enhancement <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06129v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06129v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qimin Chen, Zhiqin Chen, Vladimir G. Kim, Noam Aigerman, Hao Zhang, Siddhartha Chaudhuri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a 3D modeling method which enables end-users to refine or
detailize 3D shapes using machine learning, expanding the capabilities of
AI-assisted 3D content creation. Given a coarse voxel shape (e.g., one produced
with a simple box extrusion tool or via generative modeling), a user can
directly "paint" desired target styles representing compelling geometric
details, from input exemplar shapes, over different regions of the coarse
shape. These regions are then up-sampled into high-resolution geometries which
adhere with the painted styles. To achieve such controllable and localized 3D
detailization, we build on top of a Pyramid GAN by making it masking-aware. We
devise novel structural losses and priors to ensure that our method preserves
both desired coarse structures and fine-grained features even if the painted
styles are borrowed from diverse sources, e.g., different semantic parts and
even different shape categories. Through extensive experiments, we show that
our ability to localize details enables novel interactive creative workflows
and applications. Our experiments further demonstrate that in comparison to
prior techniques built on global detailization, our method generates
structure-preserving, high-resolution stylized geometries with more coherent
shape details and style transitions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ECCV 2024 (poster). Code: https://qiminchen.github.io/decollage/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contrastive Federated Learning with Tabular Data Silos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06123v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06123v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Achmad Ginanjar, Xue Li, Wen Hua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning from data silos is a difficult task for organizations that need to
obtain knowledge of objects that appeared in multiple independent data silos.
Objects in multi-organizations, such as government agents, are referred by
different identifiers, such as driver license, passport number, and tax file
number. The data distributions in data silos are mostly non-IID (Independently
and Identically Distributed), labelless, and vertically partitioned (i.e.,
having different attributes). Privacy concerns harden the above issues.
Conditions inhibit enthusiasm for collaborative work. While Federated Learning
(FL) has been proposed to address these issues, the difficulty of labeling,
namely, label costliness, often hinders optimal model performance. A potential
solution lies in contrastive learning, an unsupervised self-learning technique
to represent semantic data by contrasting similar data pairs. However,
contrastive learning is currently not designed to handle tabular data silos
that existed within multiple organizations where data linkage by quasi
identifiers are needed. To address these challenges, we propose using
semi-supervised contrastive federated learning, which we refer to as
Contrastive Federated Learning with Data Silos (CFL). Our approach tackles the
aforementioned issues with an integrated solution. Our experimental results
demonstrate that CFL outperforms current methods in addressing these challenges
and providing improvements in accuracy. Additionally, we present positive
results that showcase the advantages of our contrastive federated learning
approach in complex client environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 Pages. Was submitted on Artificial Intelligence Journal, Jan 29,
  2024, ARTINT-D-24-00098</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ QueryBuilder: Human-in-the-Loop Query Development for Information
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hemanth Kandula, Damianos Karakos, Haoling Qiu, Benjamin Rozonoyer, Ian Soboroff, Lee Tarlin, Bonan Min
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Frequently, users of an Information Retrieval (IR) system start with an
overarching information need (a.k.a., an analytic task) and proceed to define
finer-grained queries covering various important aspects (i.e., sub-topics) of
that analytic task. We present a novel, interactive system called
$\textit{QueryBuilder}$, which allows a novice, English-speaking user to create
queries with a small amount of effort, through efficient exploration of an
English development corpus in order to rapidly develop cross-lingual
information retrieval queries corresponding to the user's information needs.
QueryBuilder performs near real-time retrieval of documents based on
user-entered search terms; the user looks through the retrieved documents and
marks sentences as relevant to the information needed. The marked sentences are
used by the system as additional information in query formation and refinement:
query terms (and, optionally, event features, which capture event $'triggers'$
(indicator terms) and agent/patient roles) are appropriately weighted, and a
neural-based system, which better captures textual meaning, retrieves other
relevant content. The process of retrieval and marking is repeated as many
times as desired, giving rise to increasingly refined queries in each
iteration. The final product is a fine-grained query used in Cross-Lingual
Information Retrieval (CLIR). Our experiments using analytic tasks and requests
from the IARPA BETTER IR datasets show that with a small amount of effort (at
most 10 minutes per sub-topic), novice users can form $\textit{useful}$
fine-grained queries including in languages they don't understand. QueryBuilder
also provides beneficial capabilities to the traditional corpus exploration and
query formation process. A demonstration video is released at
https://vimeo.com/734795835
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SORSA: Singular Values and Orthonormal Regularized Singular Vectors
  Adaptation of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00055v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00055v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Cao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement in large language models (LLMs) comes with a
significant increase in their parameter size, presenting challenges for
adaptation and fine-tuning. Parameter-efficient fine-tuning (PEFT) methods are
widely used to adapt LLMs for downstream tasks efficiently. In this paper, we
propose Singular Values and Orthonormal Regularized Singular Vectors
Adaptation, or SORSA, a novel PEFT method. We introduce a method to analyze the
variation of the parameters by performing singular value decomposition (SVD)
and discuss and analyze SORSA's superiority in minimizing the alteration in the
SVD aspect. Each SORSA adapter consists of two main parts: trainable principal
singular weights $W_p = U_p \Sigma_p V^\top_p$, and frozen residual weights
$W_r = U_r \Sigma_r V^\top_r$. These parts are initialized by performing SVD on
pre-trained weights. Moreover, we implement and analyze an orthonormal
regularizer, which could effectively transfer the scaling information into
$\Sigma_p$ and ultimately allows the training process to be more efficient.
SORSA adapters could be merged during inference, thus eliminating any inference
latency. After all, SORSA shows a faster convergence than PiSSA and LoRA in our
experiments. On the MATH benchmark, Llama 2 7B adapted using SORSA achieved
10.36% accuracy, outperforming LoRA (5.50%), Full FT (7.22%), and PiSSA
(7.44%). On the GSM-8K benchmark, SORSA achieved 56.03% accuracy, surpassing
LoRA (42.30%), Full FT (49.05%), and PiSSA (53.07%). We conclude that SORSA
offers a new perspective on parameter-efficient fine-tuning, demonstrating
remarkable performance. The code is available at
https://github.com/Gunale0926/SORSA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ System Neural Diversity: Measuring Behavioral Heterogeneity in
  Multi-Agent Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.02128v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.02128v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Bettini, Ajay Shankar, Amanda Prorok
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evolutionary science provides evidence that diversity confers resilience in
natural systems. Yet, traditional multi-agent reinforcement learning techniques
commonly enforce homogeneity to increase training sample efficiency. When a
system of learning agents is not constrained to homogeneous policies,
individuals may develop diverse behaviors, resulting in emergent
complementarity that benefits the system. Despite this, there is a surprising
lack of tools that quantify behavioral diversity. Such techniques would pave
the way towards understanding the impact of diversity in collective artificial
intelligence and enabling its control. In this paper, we introduce System
Neural Diversity (SND): a measure of behavioral heterogeneity in multi-agent
systems. We discuss and prove its theoretical properties, and compare it with
alternate, state-of-the-art behavioral diversity metrics used in the robotics
domain. Through simulations of a variety of cooperative multi-robot tasks, we
show how our metric constitutes an important tool that enables measurement and
control of behavioral heterogeneity. In dynamic tasks, where the problem is
affected by repeated disturbances during training, we show that SND allows us
to measure latent resilience skills acquired by the agents, while other
proxies, such as task performance (reward), fail to. Finally, we show how the
metric can be employed to control diversity, allowing us to enforce a desired
heterogeneity set-point or range. We demonstrate how this paradigm can be used
to bootstrap the exploration phase, finding optimal policies faster, thus
enabling novel and more efficient MARL paradigms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generalization of Graph Neural Networks is Robust to Model Mismatch 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13878v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13878v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyang Wang, Juan Cervino, Alejandro Ribeiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph neural networks (GNNs) have demonstrated their effectiveness in various
tasks supported by their generalization capabilities. However, the current
analysis of GNN generalization relies on the assumption that training and
testing data are independent and identically distributed (i.i.d). This imposes
limitations on the cases where a model mismatch exists when generating testing
data. In this paper, we examine GNNs that operate on geometric graphs generated
from manifold models, explicitly focusing on scenarios where there is a
mismatch between manifold models generating training and testing data. Our
analysis reveals the robustness of the GNN generalization in the presence of
such model mismatch. This indicates that GNNs trained on graphs generated from
a manifold can still generalize well to unseen nodes and graphs generated from
a mismatched manifold. We attribute this mismatch to both node feature
perturbations and edge perturbations within the generated graph. Our findings
indicate that the generalization gap decreases as the number of nodes grows in
the training graph while increasing with larger manifold dimension as well as
larger mismatch. Importantly, we observe a trade-off between the generalization
of GNNs and the capability to discriminate high-frequency components when
facing a model mismatch. The most important practical consequence of this
analysis is to shed light on the filter design of generalizable GNNs robust to
model mismatch. We verify our theoretical findings with experiments on multiple
real-world datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 6 figures. arXiv admin note: substantial text overlap with
  arXiv:2406.05225</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Manifold Perspective on the Statistical Generalization of Graph Neural
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05225v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05225v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiyang Wang, Juan Cervino, Alejandro Ribeiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Convolutional neural networks have been successfully extended to operate on
graphs, giving rise to Graph Neural Networks (GNNs). GNNs combine information
from adjacent nodes by successive applications of graph convolutions. GNNs have
been implemented successfully in various learning tasks while the theoretical
understanding of their generalization capability is still in progress. In this
paper, we leverage manifold theory to analyze the statistical generalization
gap of GNNs operating on graphs constructed on sampled points from manifolds.
We study the generalization gaps of GNNs on both node-level and graph-level
tasks. We show that the generalization gaps decrease with the number of nodes
in the training graphs, which guarantees the generalization of GNNs to unseen
points over manifolds. We validate our theoretical results in multiple
real-world datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages,22 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeFL: Nested Model Scaling for Federated Learning with System
  Heterogeneous Clients 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.07761v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.07761v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Honggu Kang, Seohyeon Cha, Jinwoo Shin, Jongmyeong Lee, Joonhyuk Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning (FL) enables distributed training while preserving data
privacy, but stragglers-slow or incapable clients-can significantly slow down
the total training time and degrade performance. To mitigate the impact of
stragglers, system heterogeneity, including heterogeneous computing and network
bandwidth, has been addressed. While previous studies have addressed system
heterogeneity by splitting models into submodels, they offer limited
flexibility in model architecture design, without considering potential
inconsistencies arising from training multiple submodel architectures. We
propose nested federated learning (NeFL), a generalized framework that
efficiently divides deep neural networks into submodels using both depthwise
and widthwise scaling. To address the inconsistency arising from training
multiple submodel architectures, NeFL decouples a subset of parameters from
those being trained for each submodel. An averaging method is proposed to
handle these decoupled parameters during aggregation. NeFL enables
resource-constrained devices to effectively participate in the FL pipeline,
facilitating larger datasets for model training. Experiments demonstrate that
NeFL achieves performance gain, especially for the worst-case submodel compared
to baseline approaches (7.63% improvement on CIFAR-100). Furthermore, NeFL
aligns with recent advances in FL, such as leveraging pre-trained models and
accounting for statistical heterogeneity. Our code is available online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.08131v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.08131v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elena Tiukhova, Emiliano Penaloza, María Óskarsdóttir, Bart Baesens, Monique Snoeck, Cristián Bravo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging network information for predictive modeling has become widespread
in many domains. Within the realm of referral and targeted marketing,
influencer detection stands out as an area that could greatly benefit from the
incorporation of dynamic network representation due to the continuous evolution
of customer-brand relationships. In this paper, we present INFLECT-DGNN, a new
method for profit-driven INFLuencer prEdiCTion with Dynamic Graph Neural
Networks that innovatively combines Graph Neural Networks (GNNs) and Recurrent
Neural Networks (RNNs) with weighted loss functions, synthetic minority
oversampling adapted to graph data, and a carefully crafted rolling-window
strategy. We introduce a novel profit-driven framework that supports
decision-making based on model predictions. To test the framework, we use a
unique corporate dataset with diverse networks, capturing the customer
interactions across three cities with different socioeconomic and demographic
characteristics. Our results show how using RNNs to encode temporal attributes
alongside GNNs significantly improves predictive performance, while the
profit-driven framework determines the optimal classification threshold for
profit maximization. We compare the results of different models to demonstrate
the importance of capturing network representation, temporal dependencies, and
using a profit-driven evaluation. Our research has significant implications for
the fields of referral and targeted marketing, expanding the technical use of
deep graph learning within corporate environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Developing A Multi-Agent and Self-Adaptive Framework with Deep
  Reinforcement Learning for Dynamic Portfolio Risk Management 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.00515v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.00515v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenglong Li, Vincent Tam, Kwan L. Yeung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep or reinforcement learning (RL) approaches have been adapted as reactive
agents to quickly learn and respond with new investment strategies for
portfolio management under the highly turbulent financial market environments
in recent years. In many cases, due to the very complex correlations among
various financial sectors, and the fluctuating trends in different financial
markets, a deep or reinforcement learning based agent can be biased in
maximising the total returns of the newly formulated investment portfolio while
neglecting its potential risks under the turmoil of various market conditions
in the global or regional sectors. Accordingly, a multi-agent and self-adaptive
framework namely the MASA is proposed in which a sophisticated multi-agent
reinforcement learning (RL) approach is adopted through two cooperating and
reactive agents to carefully and dynamically balance the trade-off between the
overall portfolio returns and their potential risks. Besides, a very flexible
and proactive agent as the market observer is integrated into the MASA
framework to provide some additional information on the estimated market trends
as valuable feedbacks for multi-agent RL approach to quickly adapt to the
ever-changing market conditions. The obtained empirical results clearly reveal
the potential strengths of our proposed MASA framework based on the multi-agent
RL approach against many well-known RL-based approaches on the challenging data
sets of the CSI 300, Dow Jones Industrial Average and S&P 500 indexes over the
past 10 years. More importantly, our proposed MASA framework shed lights on
many possible directions for future investigation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings of the 23rd International Conference on Autonomous
  Agents and Multiagent Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deeper-PINNs: Element-wise Multiplication Based Physics-informed Neural
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04170v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04170v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Feilong Jiang, Xiaonan Hou, Min Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a promising framework for resolving partial differential equations (PDEs),
physics-informed neural networks (PINNs) have received widespread attention
from industrial and scientific fields. However, lack of expressive ability and
initialization pathology issues are found to prevent the application of PINNs
in complex PDEs. In this work, we propose Deeper Physics-Informed Neural
Network (Deeper-PINN) to resolve these issues. The element-wise multiplication
operation is adopted to transform features into high-dimensional, non-linear
spaces. Benefiting from element-wise multiplication operation, Deeper-PINNs can
alleviate the initialization pathologies of PINNs and enhance the expressive
capability of PINNs. The proposed structure is verified on various benchmarks.
The results show that Deeper-PINNs can effectively resolve the initialization
pathology and exhibit strong expressive ability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DispaRisk: Auditing Fairness Through Usable Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12372v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12372v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Vasquez, Carlotta Domeniconi, Huzefa Rangwala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine Learning algorithms (ML) impact virtually every aspect of human lives
and have found use across diverse sectors including healthcare, finance, and
education. Often, ML algorithms have been found to exacerbate societal biases
present in datasets leading to adversarial impacts on subsets/groups of
individuals and in many cases on minority groups. To effectively mitigate these
untoward effects, it is crucial that disparities/biases are identified early in
a ML pipeline. This proactive approach facilitates timely interventions to
prevent bias amplification and reduce complexity at later stages of model
development. In this paper, we leverage recent advancements in usable
information theory to introduce DispaRisk, a novel framework designed to
proactively assess the potential risks of disparities in datasets during the
initial stages of the ML pipeline. We evaluate DispaRisk's effectiveness by
benchmarking it against commonly used datasets in fairness research. Our
findings demonstrate DispaRisk's capabilities to identify datasets with a high
risk of discrimination, detect model families prone to biases within an ML
pipeline, and enhance the explainability of these bias risks. This work
contributes to the development of fairer ML systems by providing a robust tool
for early bias detection and mitigation. The code for our experiments is
available in the following repository: https://github.com/jovasque156/disparisk
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Margin Cosine Loss: Proposal and Application in Recommender
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04614v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04614v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Makbule Gulcin Ozsoy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems guide users through vast amounts of information by
suggesting items based on their predicted preferences. Collaborative
filtering-based deep learning techniques have regained popularity due to their
straightforward nature, relying only on user-item interactions. Typically,
these systems consist of three main components: an interaction module, a loss
function, and a negative sampling strategy. Initially, researchers focused on
enhancing performance by developing complex interaction modules. However, there
has been a recent shift toward refining loss functions and negative sampling
strategies. This shift has led to an increased interest in contrastive
learning, which pulls similar pairs closer while pushing dissimilar ones apart.
Contrastive learning may bring challenges like high memory demands and
under-utilization of some negative samples. The proposed Multi-Margin Cosine
Loss (MMCL) addresses these challenges by introducing multiple margins and
varying weights for negative samples. It efficiently utilizes not only the
hardest negatives but also other non-trivial negatives, offers a simpler yet
effective loss function that outperforms more complex methods, especially when
resources are limited. Experiments on two well-known datasets demonstrated that
MMCL achieved up to a 20\% performance improvement compared to a baseline loss
function when fewer number of negative samples are used.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Some Results on Neural Network Stability, Consistency, and Convergence:
  Insights into Non-IID Data, High-Dimensional Settings, and Physics-Informed
  Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05030v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05030v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ronald Katende, Henry Kasumba, Godwin Kakuba, John M. Mango
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses critical challenges in machine learning, particularly
the stability, consistency, and convergence of neural networks under non-IID
data, distribution shifts, and high-dimensional settings. We provide new
theoretical results on uniform stability for neural networks with dynamic
learning rates in non-convex settings. Further, we establish consistency bounds
for federated learning models in non-Euclidean spaces, accounting for
distribution shifts and curvature effects. For Physics-Informed Neural Networks
(PINNs), we derive stability, consistency, and convergence guarantees for
solving Partial Differential Equations (PDEs) in noisy environments. These
results fill significant gaps in understanding model behavior in complex,
non-ideal conditions, paving the way for more robust and reliable machine
learning applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Neural Network Approximation for High-Dimensional Continuous
  Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02363v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02363v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayan Maiti, Michelle Michelle, Haizhao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the authors of Shen Yang Zhang (JMLR, 2022) developed a neural
network with width $36d(2d + 1)$ and depth $11$, which utilizes a special
activation function called the elementary universal activation function, to
achieve the super approximation property for functions in $C([a,b]^d)$. That
is, the constructed network only requires a fixed number of neurons to
approximate a $d$-variate continuous function on a $d$-dimensional hypercube
with arbitrary accuracy. Their network uses $\mathcal{O}(d^2)$ fixed neurons.
One natural question to address is whether we can reduce the number of these
neurons in such a network. By leveraging a variant of the Kolmogorov
Superposition Theorem, our analysis shows that there is a neural network
generated by the elementary universal activation function with only $366d +365$
fixed, intrinsic (non-repeated) neurons that attains this super approximation
property. Furthermore, we present a family of continuous functions that
requires at least width $d$, and therefore at least $d$ intrinsic neurons, to
achieve arbitrary accuracy in its approximation. This shows that the
requirement of $\mathcal{O}(d)$ intrinsic neurons is optimal in the sense that
it grows linearly with the input dimension $d$, unlike some approximation
methods where parameters may grow exponentially with $d$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EMCNet : Graph-Nets for Electron Micrographs Classification <span class="chip">KDD 2022</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03767v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03767v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Characterization of materials via electron micrographs is an important and
challenging task in several materials processing industries. Classification of
electron micrographs is complex due to the high intra-class dissimilarity, high
inter-class similarity, and multi-spatial scales of patterns. However, existing
methods are ineffective in learning complex image patterns. We propose an
effective end-to-end electron micrograph representation learning-based
framework for nanomaterial identification to overcome the challenges. We
demonstrate that our framework outperforms the popular baselines on the
open-source datasets in nanomaterials-based identification tasks. The ablation
studies are reported in great detail to support the efficacy of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 10 figures, Accepted in a ACM SIGKDD 2022 Workshop on
  Machine Learning for Materials</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shedding More Light on Robust Classifiers under the lens of Energy-based
  Models <span class="chip">ECCV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06315v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06315v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mujtaba Hussain Mirza, Maria Rosaria Briglia, Senad Beadini, Iacopo Masi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  By reinterpreting a robust discriminative classifier as Energy-based Model
(EBM), we offer a new take on the dynamics of adversarial training (AT). Our
analysis of the energy landscape during AT reveals that untargeted attacks
generate adversarial images much more in-distribution (lower energy) than the
original data from the point of view of the model. Conversely, we observe the
opposite for targeted attacks. On the ground of our thorough analysis, we
present new theoretical and practical results that show how interpreting AT
energy dynamics unlocks a better understanding: (1) AT dynamic is governed by
three phases and robust overfitting occurs in the third phase with a drastic
divergence between natural and adversarial energies (2) by rewriting the loss
of TRadeoff-inspired Adversarial DEfense via Surrogate-loss minimization
(TRADES) in terms of energies, we show that TRADES implicitly alleviates
overfitting by means of aligning the natural energy with the adversarial one
(3) we empirically show that all recent state-of-the-art robust classifiers are
smoothing the energy landscape and we reconcile a variety of studies about
understanding AT and weighting the loss function under the umbrella of EBMs.
Motivated by rigorous evidence, we propose Weighted Energy Adversarial Training
(WEAT), a novel sample weighting scheme that yields robust accuracy matching
the state-of-the-art on multiple benchmarks such as CIFAR-10 and SVHN and going
beyond in CIFAR-100 and Tiny-ImageNet. We further show that robust classifiers
vary in the intensity and quality of their generative capabilities, and offer a
simple method to push this capability, reaching a remarkable Inception Score
(IS) and FID using a robust classifier without training for generative
modeling. The code to reproduce our results is available at
http://github.com/OmnAI-Lab/Robust-Classifiers-under-the-lens-of-EBM/ .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at European Conference on Computer Vision (ECCV) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-intention Inverse Q-learning for Interpretable Behavior
  Representation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.13870v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.13870v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Zhu, Brice De La Crompe, Gabriel Kalweit, Artur Schneider, Maria Kalweit, Ilka Diester, Joschka Boedecker
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In advancing the understanding of natural decision-making processes, inverse
reinforcement learning (IRL) methods have proven instrumental in reconstructing
animal's intentions underlying complex behaviors. Given the recent development
of a continuous-time multi-intention IRL framework, there has been persistent
inquiry into inferring discrete time-varying rewards with IRL. To address this
challenge, we introduce the class of hierarchical inverse Q-learning (HIQL)
algorithms. Through an unsupervised learning process, HIQL divides expert
trajectories into multiple intention segments, and solves the IRL problem
independently for each. Applying HIQL to simulated experiments and several real
animal behavior datasets, our approach outperforms current benchmarks in
behavior prediction and produces interpretable reward functions. Our results
suggest that the intention transition dynamics underlying complex
decision-making behavior is better modeled by a step function instead of a
smoothly varying function. This advancement holds promise for neuroscience and
cognitive science, contributing to a deeper understanding of decision-making
and uncovering underlying brain mechanisms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Surrogate uncertainty estimation for your time series forecasting
  black-box: learn when to trust 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.02834v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.02834v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leonid Erlygin, Vladimir Zholobov, Valeriia Baklanova, Evgeny Sokolovskiy, Alexey Zaytsev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning models play a vital role in time series forecasting. These
models, however, often overlook an important element: point uncertainty
estimates. Incorporating these estimates is crucial for effective risk
management, informed model selection, and decision-making.To address this
issue, our research introduces a method for uncertainty estimation. We employ a
surrogate Gaussian process regression model. It enhances any base regression
model with reasonable uncertainty estimates. This approach stands out for its
computational efficiency. It only necessitates training one supplementary
surrogate and avoids any data-specific assumptions. Furthermore, this method
for work requires only the presence of the base model as a black box and its
respective training data. The effectiveness of our approach is supported by
experimental results. Using various time-series forecasting data, we found that
our surrogate model-based technique delivers significantly more accurate
confidence intervals. These techniques outperform both bootstrap-based and
built-in methods in a medium-data regime. This superiority holds across a range
of base model types, including a linear regression, ARIMA, gradient boosting
and a neural network.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Probabilistic energy forecasting through quantile regression in
  reproducing kernel Hil<span class="highlight-title">bert</span> spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.04405v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.04405v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Pernigo, Rohan Sen, Davide Baroli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate energy demand forecasting is crucial for sustainable and resilient
energy development. To meet the Net Zero Representative Concentration Pathways
(RCP) $4.5$ scenario in the DACH countries, increased renewable energy
production, energy storage, and reduced commercial building consumption are
needed. This scenario's success depends on hydroelectric capacity and climatic
factors. Informed decisions require quantifying uncertainty in forecasts. This
study explores a non-parametric method based on \emph{reproducing kernel
Hilbert spaces (RKHS)}, known as kernel quantile regression, for energy
prediction. Our experiments demonstrate its reliability and sharpness, and we
benchmark it against state-of-the-art methods in load and price forecasting for
the DACH region. We offer our implementation in conjunction with additional
scripts to ensure the reproducibility of our research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, {Owner/Author | ACM} {2024}. This is the author's version
  of the work. It is posted here for your personal use. Not for redistribution.
  The definitive Version of Record will published in https://energy.acm.org/eir</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Epistemic Uncertainty and Observation Noise with the Neural Tangent
  Kernel 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03953v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03953v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergio Calvo-Ordoñez, Konstantina Palla, Kamil Ciosek
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work has shown that training wide neural networks with gradient
descent is formally equivalent to computing the mean of the posterior
distribution in a Gaussian Process (GP) with the Neural Tangent Kernel (NTK) as
the prior covariance and zero aleatoric noise \parencite{jacot2018neural}. In
this paper, we extend this framework in two ways. First, we show how to deal
with non-zero aleatoric noise. Second, we derive an estimator for the posterior
covariance, giving us a handle on epistemic uncertainty. Our proposed approach
integrates seamlessly with standard training pipelines, as it involves training
a small number of additional predictors using gradient descent on a mean
squared error loss. We demonstrate the proof-of-concept of our method through
empirical evaluation on synthetic regression.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages including appendix. Fix incorrect author affiliations in the
  initial revision due to typos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Relational <span class="highlight-title">Prompt</span>-based <span class="highlight-title">Pre-train</span>ed Language Models for Social Event
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08263v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08263v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pu Li, Xiaoyan Yu, Hao Peng, Yantuan Xian, Linqin Wang, Li Sun, Jingyun Zhang, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social Event Detection (SED) aims to identify significant events from social
streams, and has a wide application ranging from public opinion analysis to
risk management. In recent years, Graph Neural Network (GNN) based solutions
have achieved state-of-the-art performance. However, GNN-based methods often
struggle with missing and noisy edges between messages, affecting the quality
of learned message embedding. Moreover, these methods statically initialize
node embedding before training, which, in turn, limits the ability to learn
from message texts and relations simultaneously. In this paper, we approach
social event detection from a new perspective based on Pre-trained Language
Models (PLMs), and present RPLM_SED (Relational prompt-based Pre-trained
Language Models for Social Event Detection). We first propose a new pairwise
message modeling strategy to construct social messages into message pairs with
multi-relational sequences. Secondly, a new multi-relational prompt-based
pairwise message learning mechanism is proposed to learn more comprehensive
message representation from message pairs with multi-relational prompts using
PLMs. Thirdly, we design a new clustering constraint to optimize the encoding
process by enhancing intra-cluster compactness and inter-cluster dispersion,
making the message representation more distinguishable. We evaluate the
RPLM_SED on three real-world datasets, demonstrating that the RPLM_SED model
achieves state-of-the-art performance in offline, online, low-resource, and
long-tail distribution scenarios for social event detection tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM TOIS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pseudo-rigid body networks: learning interpretable deformable object
  dynamics from partial observations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.07975v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.07975v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shamil Mamedov, A. René Geist, Jan Swevers, Sebastian Trimpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately predicting deformable linear object (DLO) dynamics is challenging,
especially when the task requires a model that is both human-interpretable and
computationally efficient. In this work, we draw inspiration from the
pseudo-rigid body method (PRB) and model a DLO as a serial chain of rigid
bodies whose internal state is unrolled through time by a dynamics network.
This dynamics network is trained jointly with a physics-informed encoder that
maps observed motion variables to the DLO's hidden state. To encourage the
state to acquire a physically meaningful representation, we leverage the
forward kinematics of the PRB model as a decoder. We demonstrate in robot
experiments that the proposed DLO dynamics model provides physically
interpretable predictions from partial observations while being on par with
black-box models regarding prediction accuracy. The project code is available
at: http://tinyurl.com/prb-networks
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MaxCutPool: differentiable feature-aware Maxcut for pooling in graph
  neural networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05100v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05100v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carlo Abate, Filippo Maria Bianchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a novel approach to compute the MAXCUT in attributed graphs, i.e.,
graphs with features associated with nodes and edges. Our approach is robust to
the underlying graph topology and is fully differentiable, making it possible
to find solutions that jointly optimize the MAXCUT along with other objectives.
Based on the obtained MAXCUT partition, we implement a hierarchical graph
pooling layer for Graph Neural Networks, which is sparse, differentiable, and
particularly suitable for downstream tasks on heterophilic graphs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Memory of recurrent networks: Do we compute it right? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.01457v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.01457v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giovanni Ballarin, Lyudmila Grigoryeva, Juan-Pablo Ortega
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerical evaluations of the memory capacity (MC) of recurrent neural
networks reported in the literature often contradict well-established
theoretical bounds. In this paper, we study the case of linear echo state
networks, for which the total memory capacity has been proven to be equal to
the rank of the corresponding Kalman controllability matrix. We shed light on
various reasons for the inaccurate numerical estimations of the memory, and we
show that these issues, often overlooked in the recent literature, are of an
exclusively numerical nature. More explicitly, we prove that when the Krylov
structure of the linear MC is ignored, a gap between the theoretical MC and its
empirical counterpart is introduced. As a solution, we develop robust numerical
approaches by exploiting a result of MC neutrality with respect to the input
mask matrix. Simulations show that the memory curves that are recovered using
the proposed methods fully agree with the theory.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Retrofitting Temporal Graph Neural Networks with <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05477v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05477v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiang Huang, Xiao Yan, Xin Wang, Susie Xi Rao, Zhichao Han, Fangcheng Fu, Wentao Zhang, Jiawei Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Temporal graph neural networks (TGNNs) outperform regular GNNs by
incorporating time information into graph-based operations. However, TGNNs
adopt specialized models (e.g., TGN, TGAT, and APAN ) and require tailored
training frameworks (e.g., TGL and ETC). In this paper, we propose TF-TGN,
which uses Transformer decoder as the backbone model for TGNN to enjoy
Transformer's codebase for efficient training. In particular, Transformer
achieves tremendous success for language modeling, and thus the community
developed high-performance kernels (e.g., flash-attention and memory-efficient
attention) and efficient distributed training schemes (e.g., PyTorch FSDP,
DeepSpeed, and Megatron-LM). We observe that TGNN resembles language modeling,
i.e., the message aggregation operation between chronologically occurring nodes
and their temporal neighbors in TGNNs can be structured as sequence modeling.
Beside this similarity, we also incorporate a series of algorithm designs
including suffix infilling, temporal graph attention with self-loop, and causal
masking self-attention to make TF-TGN work. During training, existing systems
are slow in transforming the graph topology and conducting graph sampling. As
such, we propose methods to parallelize the CSR format conversion and graph
sampling. We also adapt Transformer codebase to train TF-TGN efficiently with
multiple GPUs. We experiment with 9 graphs and compare with 2 state-of-the-art
TGNN training frameworks. The results show that TF-TGN can accelerate training
by over 2.20 while providing comparable or even superior accuracy to existing
SOTA TGNNs. TF-TGN is available at https://github.com/qianghuangwhu/TF-TGN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>conference Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Discovering Dynamic Symbolic Policies with Genetic Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02765v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02765v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sigur de Vries, Sander Keemink, Marcel van Gerven
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence techniques are increasingly being applied to solve
control problems, but often rely on black-box methods without transparent
output generation. To improve the interpretability and transparency in control
systems, models can be defined as white-box symbolic policies described by
mathematical expressions. While current approaches to learn symbolic policies
focus on static policies that directly map observations to control signals,
these may fail in partially observable and volatile environments. We instead
consider dynamic symbolic policies with memory, optimised with genetic
programming. The resulting policies are robust, and consist of easy to
interpret coupled differential equations. Our results show that dynamic
symbolic policies compare with black-box policies on a variety of control
tasks. Furthermore, the benefit of the memory in dynamic policies is
demonstrated on experiments where static policies fall short. Overall, we
present a method for evolving high-performing symbolic policies that offer
interpretability and transparency, which lacks in black-box models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages including references and appendix, 5 figures, 1 algorithm, 5
  tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross Layer Optimization and Distributed Reinforcement Learning for
  Wireless 360° Video Streaming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2011.06356v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2011.06356v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anis Elgabli, Mohammed S. Elbamby, Cristina Perfecto, Mounssif Krouka, Mehdi Bennis, Vaneet Aggarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Wirelessly streaming high quality 360 degree videos is still a challenging
problem. When there are many users watching different 360 degree videos and
competing for the computing and communication resources, the streaming
algorithm at hand should maximize the average quality of experience (QoE) while
guaranteeing a minimum rate for each user. In this paper, we propose a cross
layer optimization approach that maximizes the available rate to each user and
efficiently uses it to maximize users' QoE. Particularly, we consider a tile
based 360 degree video streaming, and we optimize a QoE metric that balances
the tradeoff between maximizing each user's QoE and ensuring fairness among
users. We show that the problem can be decoupled into two interrelated
subproblems: (i) a physical layer subproblem whose objective is to find the
download rate for each user, and (ii) an application layer subproblem whose
objective is to use that rate to find a quality decision per tile such that the
user's QoE is maximized. We prove that the physical layer subproblem can be
solved optimally with low complexity and an actor-critic deep reinforcement
learning (DRL) is proposed to leverage the parallel training of multiple
independent agents and solve the application layer subproblem. Extensive
experiments reveal the robustness of our scheme and demonstrate its significant
performance improvement compared to several baseline algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Pre-Train</span>ing and Personalized Fine-Tuning via Over-the-Air Federated
  Meta-Learning: Convergence-Generalization Trade-Offs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haifeng Wen, Hong Xing, Osvaldo Simeone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For modern artificial intelligence (AI) applications such as large language
models (LLMs), the training paradigm has recently shifted to pre-training
followed by fine-tuning. Furthermore, owing to dwindling open repositories of
data and thanks to efforts to democratize access to AI models, pre-training is
expected to increasingly migrate from the current centralized deployments to
federated learning (FL) implementations. Meta-learning provides a general
framework in which pre-training and fine-tuning can be formalized.
Meta-learning-based personalized FL (meta-pFL) moves beyond basic
personalization by targeting generalization to new agents and tasks. This paper
studies the generalization performance of meta-pFL for a wireless setting in
which the agents participating in the pre-training phase, i.e., meta-learning,
are connected via a shared wireless channel to the server. Adopting
over-the-air computing, we study the trade-off between generalization to new
agents and tasks, on the one hand, and convergence, on the other hand. The
trade-off arises from the fact that channel impairments may enhance
generalization, while degrading convergence. Extensive numerical results
validate the theory.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>38 pages, 7 figures, submitted for possible journal publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sparse Attention Regression Network Based Soil Fertility Prediction With
  Ummaso 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10274v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10274v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R V Raghavendra Rao, U Srinivasulu Reddy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The challenge of imbalanced soil nutrient datasets significantly hampers
accurate predictions of soil fertility. To tackle this, a new method is
suggested in this research, combining Uniform Manifold Approximation and
Projection (UMAP) with Least Absolute Shrinkage and Selection Operator (LASSO).
The main aim is to counter the impact of uneven data distribution and improve
soil fertility models' predictive precision. The model introduced uses Sparse
Attention Regression, effectively incorporating pertinent features from the
imbalanced dataset. UMAP is utilized initially to reduce data complexity,
unveiling hidden structures and important patterns. Following this, LASSO is
applied to refine features and enhance the model's interpretability. The
experimental outcomes highlight the effectiveness of the UMAP and LASSO hybrid
approach. The proposed model achieves outstanding performance metrics, reaching
a predictive accuracy of 98%, demonstrating its capability in accurate soil
fertility predictions. Additionally, it showcases a Precision of 91.25%,
indicating its adeptness in identifying fertile soil instances accurately. The
Recall metric stands at 90.90%, emphasizing the model's ability to capture true
positive cases effectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>There is an error in the result section</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ViSaRL: Visual Reinforcement Learning Guided by Human Saliency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10940v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10940v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anthony Liang, Jesse Thomason, Erdem Bıyık
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training robots to perform complex control tasks from high-dimensional pixel
input using reinforcement learning (RL) is sample-inefficient, because image
observations are comprised primarily of task-irrelevant information. By
contrast, humans are able to visually attend to task-relevant objects and
areas. Based on this insight, we introduce Visual Saliency-Guided Reinforcement
Learning (ViSaRL). Using ViSaRL to learn visual representations significantly
improves the success rate, sample efficiency, and generalization of an RL agent
on diverse tasks including DeepMind Control benchmark, robot manipulation in
simulation and on a real robot. We present approaches for incorporating
saliency into both CNN and Transformer-based encoders. We show that visual
representations learned using ViSaRL are robust to various sources of visual
perturbations including perceptual noise and scene variations. ViSaRL nearly
doubles success rate on the real-robot tasks compared to the baseline which
does not use saliency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OT-VP: Optimal Transport-guided Visual <span class="highlight-title">Prompt</span>ing for Test-Time
  Adaptation <span class="chip">WACV2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09498v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09498v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunbei Zhang, Akshay Mehra, Jihun Hamm
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision Transformers (ViTs) have demonstrated remarkable capabilities in
learning representations, but their performance is compromised when applied to
unseen domains. Previous methods either engage in prompt learning during the
training phase or modify model parameters at test time through entropy
minimization. The former often overlooks unlabeled target data, while the
latter doesn't fully address domain shifts. In this work, our approach, Optimal
Transport-guided Test-Time Visual Prompting (OT-VP), handles these problems by
leveraging prompt learning at test time to align the target and source domains
without accessing the training process or altering pre-trained model
parameters. This method involves learning a universal visual prompt for the
target domain by optimizing the Optimal Transport distance.OT-VP, with only
four learned prompt tokens, exceeds state-of-the-art performance across three
stylistic datasets-PACS, VLCS, OfficeHome, and one corrupted dataset
ImageNet-C. Additionally, OT-VP operates efficiently, both in terms of memory
and computation, and is adaptable for extension to online settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WACV2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02969v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02969v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyuan Zhang, Liang Zhao, Yingying Yu, Xi Lin, Zhenkun Wang, Han Zhao, Qingfu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multiobjective optimization problems (MOPs) are prevalent in machine
learning, with applications in multi-task learning, learning under fairness or
robustness constraints, etc. Instead of reducing multiple objective functions
into a scalar objective, MOPs aim to optimize for the so-called Pareto
optimality or Pareto set learning, which involves optimizing more than one
objective function simultaneously, over models with millions of parameters.
Existing benchmark libraries for MOPs mainly focus on evolutionary algorithms,
most of which are zeroth-order methods that do not effectively utilize
higher-order information from objectives and cannot scale to large-scale models
with millions of parameters. In light of the above gap, this paper introduces
LibMOON, the first multiobjective optimization library that supports
state-of-the-art gradient-based methods, provides a fair benchmark, and is
open-sourced for the community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> on <span class="highlight-title">Self-Supervised</span> Learning for Non-Sequential Tabular Data <span class="chip">ACML-24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01204v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01204v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei-Yao Wang, Wei-Wei Du, Derek Xu, Wei Wang, Wen-Chih Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning (SSL) has been incorporated into many
state-of-the-art models in various domains, where SSL defines pretext tasks
based on unlabeled datasets to learn contextualized and robust representations.
Recently, SSL has become a new trend in exploring the representation learning
capability in the realm of tabular data, which is more challenging due to not
having explicit relations for learning descriptive representations. This survey
aims to systematically review and summarize the recent progress and challenges
of SSL for non-sequential tabular data (SSL4NS-TD). We first present a formal
definition of NS-TD and clarify its correlation to related studies. Then, these
approaches are categorized into three groups - predictive learning, contrastive
learning, and hybrid learning, with their motivations and strengths of
representative methods in each direction. Moreover, application issues of
SSL4NS-TD are presented, including automatic data engineering, cross-table
transferability, and domain knowledge integration. In addition, we elaborate on
existing benchmarks and datasets for NS-TD applications to analyze the
performance of existing tabular models. Finally, we discuss the challenges of
SSL4NS-TD and provide potential directions for future research. We expect our
work to be useful in terms of encouraging more research on lowering the barrier
to entry SSL for the tabular domain, and of improving the foundations for
implicit tabular data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACML-24 Journal Track. The paper list can be found at
  https://github.com/wwweiwei/awesome-self-supervised-learning-for-tabular-data</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Targeting the partition function of chemically disordered materials with
  a generative approach based on inverse variational autoencoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14928v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14928v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maciej J. Karcz, Luca Messina, Eiji Kawasaki, Emeric Bourasseau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computing atomic-scale properties of chemically disordered materials requires
an efficient exploration of their vast configuration space. Traditional
approaches such as Monte Carlo or Special Quasirandom Structures either entail
sampling an excessive amount of configurations or do not ensure that the
configuration space has been properly covered. In this work, we propose a novel
approach where generative machine learning is used to yield a representative
set of configurations for accurate property evaluation and provide accurate
estimations of atomic-scale properties with minimal computational cost. Our
method employs a specific type of variational autoencoder with inverse roles
for the encoder and decoder, enabling the application of an unsupervised active
learning scheme that does not require any initial training database. The model
iteratively generates configuration batches, whose properties are computed with
conventional atomic-scale methods. These results are then fed back into the
model to estimate the partition function, repeating the process until
convergence. We illustrate our approach by computing point-defect formation
energies and concentrations in (U, Pu)O2 mixed-oxide fuels. In addition, the ML
model provides valuable insights into the physical factors influencing the
target property. Our method is generally applicable to explore other
properties, such as atomic-scale diffusion coefficients, in ideally or
non-ideally disordered materials like high-entropy alloys.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revisiting Trace Norm Minimization for Tensor Tucker Completion: A
  Direct Multilinear Rank Learning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05139v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05139v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xueke Tong, Hancheng Zhu, Lei Cheng, Yik-Chung Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To efficiently express tensor data using the Tucker format, a critical task
is to minimize the multilinear rank such that the model would not be
over-flexible and lead to overfitting. Due to the lack of rank minimization
tools in tensor, existing works connect Tucker multilinear rank minimization to
trace norm minimization of matrices unfolded from the tensor data. While these
formulations try to exploit the common aim of identifying the low-dimensional
structure of the tensor and matrix, this paper reveals that existing trace
norm-based formulations in Tucker completion are inefficient in multilinear
rank minimization. We further propose a new interpretation of Tucker format
such that trace norm minimization is applied to the factor matrices of the
equivalent representation, rather than some matrices unfolded from tensor data.
Based on the newly established problem formulation, a fixed point iteration
algorithm is proposed, and its convergence is proved. Numerical results are
presented to show that the proposed algorithm exhibits significant improved
performance in terms of multilinear rank learning and consequently tensor
signal recovery accuracy, compared to existing trace norm based Tucker
completion methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpikeCLIP: A Contrastive Language-Image <span class="highlight-title">Pretrain</span>ed Spiking Neural
  Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06488v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06488v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianlong Li, Wenhao Liu, Changze Lv, Yufei Gu, Jianhan Xu, Cenyuan Zhang, Muling Wu, Xiaoqing Zheng, Xuanjing Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spiking Neural Networks (SNNs) have emerged as a promising alternative to
conventional Artificial Neural Networks (ANNs), demonstrating comparable
performance in both visual and linguistic tasks while offering the advantage of
improved energy efficiency. Despite these advancements, the integration of
linguistic and visual features into a unified representation through spike
trains poses a significant challenge, and the application of SNNs to multimodal
scenarios remains largely unexplored. This paper presents SpikeCLIP, a novel
framework designed to bridge the modality gap in spike-based computation. Our
approach employs a two-step recipe: an ``alignment pre-training'' to align
features across modalities, followed by a ``dual-loss fine-tuning'' to refine
the model's performance. Extensive experiments reveal that SNNs achieve results
on par with ANNs while substantially reducing energy consumption across various
datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP
maintains robust image classification capabilities, even when dealing with
classes that fall outside predefined categories. This study marks a significant
advancement in the development of energy-efficient and biologically plausible
multimodal learning systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-Time Machine-Learning-Based Optimization Using Input Convex Long
  Short-Term Memory Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07202v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07202v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Wang, Donghan Yu, Zhe Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural network-based optimization and control methods, often referred to as
black-box approaches, are increasingly gaining attention in energy and
manufacturing systems, particularly in situations where first-principles models
are either unavailable or inaccurate. However, their non-convex nature
significantly slows down the optimization and control processes, limiting their
application in real-time decision-making processes. To address this challenge,
we propose a novel Input Convex Long Short-Term Memory (IC-LSTM) network to
enhance the computational efficiency of neural network-based optimization.
Through two case studies employing real-time neural network-based optimization
for optimizing energy and chemical systems, we demonstrate the superior
performance of IC-LSTM-based optimization in terms of runtime. Specifically, in
a real-time optimization problem of a real-world solar photovoltaic energy
system at LHT Holdings in Singapore, IC-LSTM-based optimization achieved at
least 4-fold speedup compared to conventional LSTM-based optimization. These
results highlight the potential of IC-LSTM networks to significantly enhance
the efficiency of neural network-based optimization and control in practical
applications. Source code is available at
https://github.com/killingbear999/ICLSTM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Applied Energy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Estimation of conditional average treatment effects on distributed
  confidential data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02672v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02672v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuji Kawamata, Ryoki Motai, Yukihiko Okada, Akira Imakura, Tetsuya Sakurai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimation of conditional average treatment effects (CATEs) is an important
topic in sciences. CATEs can be estimated with high accuracy if distributed
data across multiple parties can be centralized. However, it is difficult to
aggregate such data owing to confidential or privacy concerns. To address this
issue, we proposed data collaboration double machine learning, a method that
can estimate CATE models from privacy-preserving fusion data constructed from
distributed data, and evaluated our method through simulations. Our
contributions are summarized in the following three points. First, our method
enables estimation and testing of semi-parametric CATE models without iterative
communication on distributed data. Our semi-parametric CATE method enable
estimation and testing that is more robust to model mis-specification than
parametric methods. Second, our method enables collaborative estimation between
multiple time points and different parties through the accumulation of a
knowledge base. Third, our method performed equally or better than other
methods in simulations using synthetic, semi-synthetic and real-world datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gaussian-Mixture-Model Q-Functions for Reinforcement Learning by
  Riemannian Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04374v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04374v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minh Vu, Konstantinos Slavakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper establishes a novel role for Gaussian-mixture models (GMMs) as
functional approximators of Q-function losses in reinforcement learning (RL).
Unlike the existing RL literature, where GMMs play their typical role as
estimates of probability density functions, GMMs approximate here Q-function
losses. The new Q-function approximators, coined GMM-QFs, are incorporated in
Bellman residuals to promote a Riemannian-optimization task as a novel
policy-evaluation step in standard policy-iteration schemes. The paper
demonstrates how the hyperparameters (means and covariance matrices) of the
Gaussian kernels are learned from the data, opening thus the door of RL to the
powerful toolbox of Riemannian optimization. Numerical tests show that with no
use of experienced data, the proposed design outperforms state-of-the-art
methods, even deep Q-networks which use experienced data, on benchmark RL
tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Disentangling Hippocampal Shape Variations: A Study of Neurological
  Disorders Using Mesh Variational Autoencoder with Contrastive Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00785v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00785v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakaria Rabbi, Johannes Kiechle, Christian Beaulieu, Nilanjan Ray, Dana Cobzas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a comprehensive study focused on disentangling
hippocampal shape variations from diffusion tensor imaging (DTI) datasets
within the context of neurological disorders. Leveraging a Graph Variational
Autoencoder (VAE) enhanced with Supervised Contrastive Learning, our approach
aims to improve interpretability by disentangling two distinct latent variables
corresponding to age and the presence of diseases. In our ablation study, we
investigate a range of VAE architectures and contrastive loss functions,
showcasing the enhanced disentanglement capabilities of our approach. This
evaluation uses synthetic 3D torus mesh data and real 3D hippocampal mesh
datasets derived from the DTI hippocampal dataset. Our supervised
disentanglement model outperforms several state-of-the-art (SOTA) methods like
attribute and guided VAEs in terms of disentanglement scores. Our model
distinguishes between age groups and disease status in patients with Multiple
Sclerosis (MS) using the hippocampus data. Our Graph VAE with Supervised
Contrastive Learning shows the volume changes of the hippocampus of MS
populations at different ages, and the result is consistent with the current
neuroimaging literature. This research provides valuable insights into the
relationship between neurological disorder and hippocampal shape changes in
different age groups of MS populations using a Graph VAE with Supervised
Contrastive loss.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Length: 25 pages and submitted to the journal: MELBA (Machine
  Learning for Biomedical Imaging)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ STD-PLM: Understanding Both Spatial and Temporal Properties of
  Spatial-Temporal Data with PLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09096v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09096v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        YiHeng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Junfeng Shen, Tiankuo Li, Youfang Lin, Huaiyu Wan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatial-temporal forecasting and imputation are important for real-world
intelligent systems. Most existing methods are tailored for individual
forecasting or imputation tasks but are not designed for both. Additionally,
they are less effective for zero-shot and few-shot learning. While pre-trained
language model (PLM) have exhibited strong pattern recognition and reasoning
abilities across various tasks, including few-shot and zero-shot learning,
their applications in spatial-temporal data understanding has been constrained
by insufficient modeling of complex correlations such as the temporal
correlations, spatial connectivity, non-pairwise and high-order
spatial-temporal correlations within data. In this paper, we propose STD-PLM
for understanding both spatial and temporal properties of
\underline{S}patial-\underline{T}emporal \underline{D}ata with \underline{PLM},
which is capable of implementing both spatial-temporal forecasting and
imputation tasks. STD-PLM understands spatial-temporal correlations via
explicitly designed spatial and temporal tokenizers. Topology-aware node
embeddings are designed for PLM to comprehend and exploit the topology
structure of data in inductive manner. Furthermore, to mitigate the efficiency
issues introduced by the PLM, we design a sandglass attention module (SGA)
combined with a specific constrained loss function, which significantly
improves the model's efficiency while ensuring performance. Extensive
experiments demonstrate that STD-PLM exhibits competitive performance and
generalization capabilities across the forecasting and imputation tasks on
various datasets. Moreover, STD-PLM achieves promising results on both few-shot
and zero-shot tasks.The code is made available at
\href{https://anonymous.4open.science/r/STD-PLM-F3BA}{https://anonymous.4open.science/r/STD-PLM-F3BA}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning a Cross-modality Anomaly Detector for Remote Sensing Imagery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingtao Li, Xinyu Wang, Hengwei Zhao, Liangpei Zhang, Yanfei Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote sensing anomaly detector can find the objects deviating from the
background as potential targets for Earth monitoring. Given the diversity in
earth anomaly types, designing a transferring model with cross-modality
detection ability should be cost-effective and flexible to new earth
observation sources and anomaly types. However, the current anomaly detectors
aim to learn the certain background distribution, the trained model cannot be
transferred to unseen images. Inspired by the fact that the deviation metric
for score ranking is consistent and independent from the image distribution,
this study exploits the learning target conversion from the varying background
distribution to the consistent deviation metric. We theoretically prove that
the large-margin condition in labeled samples ensures the transferring ability
of learned deviation metric. To satisfy this condition, two large margin losses
for pixel-level and feature-level deviation ranking are proposed respectively.
Since the real anomalies are difficult to acquire, anomaly simulation
strategies are designed to compute the model loss. With the large-margin
learning for deviation metric, the trained model achieves cross-modality
detection ability in five modalities including hyperspectral, visible light,
synthetic aperture radar (SAR), infrared and low-light in zero-shot manner.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Journal paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mean-Field Approximation of Cooperative Constrained Multi-Agent
  Reinforcement Learning (CMARL) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.07437v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.07437v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Washim Uddin Mondal, Vaneet Aggarwal, Satish V. Ukkusuri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mean-Field Control (MFC) has recently been proven to be a scalable tool to
approximately solve large-scale multi-agent reinforcement learning (MARL)
problems. However, these studies are typically limited to unconstrained
cumulative reward maximization framework. In this paper, we show that one can
use the MFC approach to approximate the MARL problem even in the presence of
constraints. Specifically, we prove that, an $N$-agent constrained MARL
problem, with state, and action spaces of each individual agents being of sizes
$|\mathcal{X}|$, and $|\mathcal{U}|$ respectively, can be approximated by an
associated constrained MFC problem with an error, $e\triangleq
\mathcal{O}\left([\sqrt{|\mathcal{X}|}+\sqrt{|\mathcal{U}|}]/\sqrt{N}\right)$.
In a special case where the reward, cost, and state transition functions are
independent of the action distribution of the population, we prove that the
error can be improved to $e=\mathcal{O}(\sqrt{|\mathcal{X}|}/\sqrt{N})$. Also,
we provide a Natural Policy Gradient based algorithm and prove that it can
solve the constrained MARL problem within an error of $\mathcal{O}(e)$ with a
sample complexity of $\mathcal{O}(e^{-6})$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ vTrain: A Simulation Framework for Evaluating Cost-effective and
  Compute-optimal Large Language Model Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.12391v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.12391v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jehyeon Bang, Yujeong Choi, Myeongwoo Kim, Yongdeok Kim, Minsoo Rhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) become widespread in various application
domains, a critical challenge the AI community is facing is how to train these
large AI models in a cost-effective manner. Existing LLM training plans
typically employ a heuristic based parallel training strategy which is based on
empirical observations rather than grounded upon a thorough examination of the
search space of LLM parallelization. Such limitation renders existing systems
to leave significant performance left on the table, wasting millions of dollars
worth of training cost. This paper presents our profiling-driven simulator
called vTrain, providing AI practitioners a fast yet accurate software
framework to determine an efficient and cost-effective LLM training system
configuration. We demonstrate vTrain's practicality through several case
studies, e.g., effectively evaluating optimal training parallelization
strategies that balances training time and its associated training cost,
efficient multi-tenant GPU cluster schedulers targeting multiple LLM training
jobs, and determining a compute-optimal LLM model architecture given a fixed
compute budget.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Private SCO for Heavy-Tailed Data via Averaged Clipping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2206.13011v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2206.13011v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenhan Jin, Kaiwen Zhou, Bo Han, James Cheng, Tieyong Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider stochastic convex optimization for heavy-tailed data with the
guarantee of being differentially private (DP). Most prior works on
differentially private stochastic convex optimization for heavy-tailed data are
either restricted to gradient descent (GD) or performed multi-times clipping on
stochastic gradient descent (SGD), which is inefficient for large-scale
problems. In this paper, we consider a one-time clipping strategy and provide
principled analyses of its bias and private mean estimation. We establish new
convergence results and improved complexity bounds for the proposed algorithm
called AClipped-dpSGD for constrained and unconstrained convex problems. We
also extend our convergent analysis to the strongly convex case and non-smooth
case (which works for generalized smooth objectives with
H$\ddot{\text{o}}$lder-continuous gradients). All the above results are
guaranteed with a high probability for heavy-tailed data. Numerical experiments
are conducted to justify the theoretical improvement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hybrid Focal and Full-Range Attention Based Graph <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.04653v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.04653v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minhong Zhu, Zhenhao Zhao, Weiran Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The paradigm of Transformers using the self-attention mechanism has
manifested its advantage in learning graph-structured data. Yet, Graph
Transformers are capable of modeling full range dependencies but are often
deficient in extracting information from locality. A common practice is to
utilize Message Passing Neural Networks (MPNNs) as an auxiliary to capture
local information, which however are still inadequate for comprehending
substructures. In this paper, we present a purely attention-based architecture,
namely Focal and Full-Range Graph Transformer (FFGT), which can mitigate the
loss of local information in learning global correlations. The core component
of FFGT is a new mechanism of compound attention, which combines the
conventional full-range attention with K-hop focal attention on ego-nets to
aggregate both global and local information. Beyond the scope of canonical
Transformers, the FFGT has the merit of being more substructure-aware. Our
approach enhances the performance of existing Graph Transformers on various
open datasets, while achieves compatible SOTA performance on several Long-Range
Graph Benchmark (LRGB) datasets even with a vanilla transformer. We further
examine influential factors on the optimal focal length of attention via
introducing a novel synthetic dataset based on SBM-PATTERN.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning force laws in many-body systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.05273v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.05273v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wentao Yu, Eslam Abdelaleem, Ilya Nemenman, Justin C. Burton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scientific laws describing natural systems may be more complex than our
intuition can handle, thus how we discover laws must change. Machine learning
(ML) models can analyze large quantities of data, but their structure should
match the underlying physical constraints to provide useful insight. While
progress has been made using simulated data where the underlying physics is
known, training and validating ML models on experimental data requires
fundamentally new approaches. Here we demonstrate and experimentally validate
an ML approach that incorporates physical intuition to infer force laws in
dusty plasma, a complex, many-body system. Trained on 3D particle trajectories,
the model accounts for inherent symmetries, non-identical particles, and learns
the effective non-reciprocal forces between particles with exquisite accuracy
(R^2>0.99). We validate the model by inferring particle masses in two
independent yet consistent ways. The model's accuracy enables precise
measurements of particle charge and screening length, discovering violations of
common theoretical assumptions. Our ability to identify new physics from
experimental data demonstrates how ML-powered approaches can guide new routes
of scientific discovery in many-body systems. Furthermore, we anticipate our ML
approach to be a starting point for inferring laws from dynamics in a wide
range of many-body systems, from colloids to living organisms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 4 Figures, 2 Supplemental Figures, 8 Supplemental Videos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Passive Inference Attacks on Split Learning via Adversarial
  Regularization <span class="chip">NDSS 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.10483v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.10483v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochen Zhu, Xinjian Luo, Yuncheng Wu, Yangfan Jiang, Xiaokui Xiao, Beng Chin Ooi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Split Learning (SL) has emerged as a practical and efficient alternative to
traditional federated learning. While previous attempts to attack SL have often
relied on overly strong assumptions or targeted easily exploitable models, we
seek to develop more capable attacks. We introduce SDAR, a novel attack
framework against SL with an honest-but-curious server. SDAR leverages
auxiliary data and adversarial regularization to learn a decodable simulator of
the client's private model, which can effectively infer the client's private
features under the vanilla SL, and both features and labels under the U-shaped
SL. We perform extensive experiments in both configurations to validate the
effectiveness of our proposed attacks. Notably, in challenging scenarios where
existing passive attacks struggle to reconstruct the client's private data
effectively, SDAR consistently achieves significantly superior attack
performance, even comparable to active attacks. On CIFAR-10, at the deep split
level of 7, SDAR achieves private feature reconstruction with less than 0.025
mean squared error in both the vanilla and the U-shaped SL, and attains a label
inference accuracy of over 98% in the U-shaped setting, while existing attacks
fail to produce non-trivial results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at NDSS 2025; 25 pages, 27 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Physics-Inspired Deep Learning and Transferable Models for Bridge Scour
  Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01258v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01258v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Negin Yousefpour, Bo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces scour physics-inspired neural networks (SPINNs), a
hybrid physics-data-driven framework for bridge scour prediction using deep
learning. SPINNs integrate physics-based, empirical equations into deep neural
networks and are trained using site-specific historical scour monitoring data.
Long-short Term Memory Network (LSTM) and Convolutional Neural Network (CNN)
are considered as the base deep learning (DL) models. We also explore
transferable/general models, trained by aggregating datasets from a cluster of
bridges, versus the site/bridge-specific models. Despite variation in
performance, SPINNs outperformed pure data-driven models in the majority of
cases. In some bridge cases, SPINN reduced forecasting errors by up to 50
percent. The pure data-driven models showed better transferability compared to
hybrid models. The transferable DL models particularly proved effective for
bridges with limited data. In addition, the calibrated time-dependent empirical
equations derived from SPINNs showed great potential for maximum scour depth
estimation, providing more accurate predictions compared to commonly used
HEC-18 model. Comparing SPINNs with traditional empirical models indicates
substantial improvements in scour prediction accuracy. This study can pave the
way for further exploration of physics-inspired machine learning methods for
scour prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stabilizing Sharpness-aware Minimization Through A Simple
  Renormalization Strategy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07250v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07250v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengli Tan, Jiangshe Zhang, Junmin Liu, Yicheng Wang, Yunda Hao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, sharpness-aware minimization (SAM) has attracted much attention
because of its surprising effectiveness in improving generalization
performance. However, compared to stochastic gradient descent (SGD), it is more
prone to getting stuck at the saddle points, which as a result may lead to
performance degradation. To address this issue, we propose a simple
renormalization strategy, dubbed Stable SAM (SSAM), so that the gradient norm
of the descent step maintains the same as that of the ascent step. Our strategy
is easy to implement and flexible enough to integrate with SAM and its
variants, almost at no computational cost. With elementary tools from convex
optimization and learning theory, we also conduct a theoretical analysis of
sharpness-aware training, revealing that compared to SGD, the effectiveness of
SAM is only assured in a limited regime of learning rate. In contrast, we show
how SSAM extends this regime of learning rate and then it can consistently
perform better than SAM with the minor modification. Finally, we demonstrate
the improved performance of SSAM on several representative data sets and tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Influence-based Attributions can be Manipulated 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05208v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05208v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Influence Functions are a standard tool for attributing predictions to
training data in a principled manner and are widely used in applications such
as data valuation and fairness. In this work, we present realistic incentives
to manipulate influencebased attributions and investigate whether these
attributions can be systematically tampered by an adversary. We show that this
is indeed possible and provide efficient attacks with backward-friendly
implementations. Our work raises questions on the reliability of
influence-based attributions under adversarial circumstances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with
  Counterfactual Reasoning-based Artifact Disentanglement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05484v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05484v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seungheun Baek, Soyon Park, Yan Ting Chok, Junhyun Lee, Jueon Park, Mogan Gim, Jaewoo Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting cellular responses to various perturbations is a critical focus in
drug discovery and personalized therapeutics, with deep learning models playing
a significant role in this endeavor. Single-cell datasets contain technical
artifacts that may hinder the predictability of such models, which poses
quality control issues highly regarded in this area. To address this, we
propose CRADLE-VAE, a causal generative framework tailored for single-cell gene
perturbation modeling, enhanced with counterfactual reasoning-based artifact
disentanglement. Throughout training, CRADLE-VAE models the underlying latent
distribution of technical artifacts and perturbation effects present in
single-cell datasets. It employs counterfactual reasoning to effectively
disentangle such artifacts by modulating the latent basal spaces and learns
robust features for generating cellular response data with improved quality.
Experimental results demonstrate that this approach improves not only treatment
effect estimation performance but also generative quality as well. The
CRADLE-VAE codebase is publicly available at
https://github.com/dmis-lab/CRADLE-VAE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dreaming is All You Need 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01633v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01633v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingze Ni, Wei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In classification tasks, achieving a harmonious balance between exploration
and precision is of paramount importance. To this end, this research introduces
two novel deep learning models, SleepNet and DreamNet, to strike this balance.
SleepNet seamlessly integrates supervised learning with unsupervised ``sleep"
stages using pre-trained encoder models. Dedicated neurons within SleepNet are
embedded in these unsupervised features, forming intermittent ``sleep" blocks
that facilitate exploratory learning. Building upon the foundation of SleepNet,
DreamNet employs full encoder-decoder frameworks to reconstruct the hidden
states, mimicking the human "dreaming" process. This reconstruction process
enables further exploration and refinement of the learned representations.
Moreover, the principle ideas of our SleepNet and DreamNet are generic and can
be applied to both computer vision and natural language processing downstream
tasks. Through extensive empirical evaluations on diverse image and text
datasets, SleepNet and DreanNet have demonstrated superior performance compared
to state-of-the-art models, showcasing the strengths of unsupervised
exploration and supervised precision afforded by our innovative approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Performance Law of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09895v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09895v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuhan Wu, Ruiming Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Guided by the belief of the scaling law, large language models (LLMs) have
achieved impressive performance in recent years. However, scaling law only
gives a qualitative estimation of loss, which is influenced by various factors
such as model architectures, data distributions, tokenizers, and computation
precision. Thus, estimating the real performance of LLMs with different
training settings rather than loss may be quite useful in practical
development. In this article, we present an empirical equation named
"Performance Law" to directly predict the MMLU score of an LLM, which is a
widely used metric to indicate the general capability of LLMs in real-world
conversations and applications. Based on only a few key hyperparameters of the
LLM architecture and the size of training data, we obtain a quite accurate MMLU
prediction of various LLMs with diverse sizes and architectures developed by
different organizations in different years. Performance law can be used to
guide the choice of LLM architecture and the effective allocation of
computational resources without extensive experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Personal opinions of the authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explanation as a Watermark: Towards Harmless and Multi-bit Model
  Ownership Verification via Watermarking Feature Attribution <span class="chip">NDSS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04825v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04825v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Shao, Yiming Li, Hongwei Yao, Yiling He, Zhan Qin, Kui Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ownership verification is currently the most critical and widely adopted
post-hoc method to safeguard model copyright. In general, model owners exploit
it to identify whether a given suspicious third-party model is stolen from them
by examining whether it has particular properties `inherited' from their
released models. Currently, backdoor-based model watermarks are the primary and
cutting-edge methods to implant such properties in the released models.
However, backdoor-based methods have two fatal drawbacks, including harmfulness
and ambiguity. The former indicates that they introduce maliciously
controllable misclassification behaviors ($i.e.$, backdoor) to the watermarked
released models. The latter denotes that malicious users can easily pass the
verification by finding other misclassified samples, leading to ownership
ambiguity.
  In this paper, we argue that both limitations stem from the `zero-bit' nature
of existing watermarking schemes, where they exploit the status ($i.e.$,
misclassified) of predictions for verification. Motivated by this
understanding, we design a new watermarking paradigm, $i.e.$, Explanation as a
Watermark (EaaW), that implants verification behaviors into the explanation of
feature attribution instead of model predictions. Specifically, EaaW embeds a
`multi-bit' watermark into the feature attribution explanation of specific
trigger samples without changing the original prediction. We correspondingly
design the watermark embedding and extraction algorithms inspired by
explainable artificial intelligence. In particular, our approach can be used
for different tasks ($e.g.$, image classification and text generation).
Extensive experiments verify the effectiveness and harmlessness of our EaaW and
its resistance to potential attacks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted by Network and Distributed System Security
  Symposium (NDSS) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ZNorm: Z-Score Gradient Normalization for Deep Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01215v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01215v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juyoung Yun, Hoyoung Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancements in deep learning necessitate better training methods
for deep neural networks (DNNs). As models grow in complexity, vanishing and
exploding gradients impede performance. We propose Z-Score Normalization for
Gradient Descent (ZNorm), an innovative technique that adjusts only the
gradients to accelerate training and improve model performance. ZNorm
normalizes the overall gradients, providing consistent gradient scaling across
layers, thereby reducing the risks of vanishing and exploding gradients, having
better performances. Our extensive experiments on CIFAR-10 and medical datasets
demonstrate that ZNorm enhances performance metrics. ZNorm consistently
outperforms existing methods, achieving superior results using the same
experimental settings. In medical imaging applications, ZNorm improves tumor
prediction and segmentation performances, underscoring its practical utility.
These findings highlight ZNorm's potential as a robust and versatile tool for
enhancing the training speed and effectiveness of deep neural networks across a
wide range of architectures and applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Large Language Models Learn Independent Causal Mechanisms? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02636v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02636v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaël Gendron, Bao Trung Nguyen, Alex Yuxuan Peng, Michael Witbrock, Gillian Dobbie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite impressive performance on language modelling and complex reasoning
tasks, Large Language Models (LLMs) fall short on the same tasks in uncommon
settings or with distribution shifts, exhibiting a lack of generalisation
ability. By contrast, systems such as causal models, that learn abstract
variables and causal relationships, can demonstrate increased robustness
against changes in the distribution. One reason for this success is the
existence and use of Independent Causal Mechanisms (ICMs) representing
high-level concepts that only sparsely interact. In this work, we apply two
concepts from causality to learn ICMs within LLMs. We develop a new LLM
architecture composed of multiple sparsely interacting language modelling
modules. We show that such causal constraints can improve out-of-distribution
performance on abstract and causal reasoning tasks. We also investigate the
level of independence and domain specialisation and show that LLMs rely on
pre-trained partially domain-invariant mechanisms resilient to fine-tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 7 pages for the main paper and 13 pages for references and
  appendices, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Sub-Genre Classification For Mainstage Dance Music <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongzhi Shu, Xinglin Li, Hongyu Jiang, Minghao Fu, Xinyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music classification, with a wide range of applications, is one of the most
prominent tasks in music information retrieval. To address the absence of
comprehensive datasets and high-performing methods in the classification of
mainstage dance music, this work introduces a novel benchmark comprising a new
dataset and a baseline. Our dataset extends the number of sub-genres to cover
most recent mainstage live sets by top DJs worldwide in music festivals. A
continuous soft labeling approach is employed to account for tracks that span
multiple sub-genres, preserving the inherent sophistication. For the baseline,
we developed deep learning models that outperform current state-of-the-art
multimodel language models, which struggle to identify house music sub-genres,
emphasizing the need for specialized models trained on fine-grained datasets.
Our benchmark is applicable to serve for application scenarios such as music
recommendation, DJ set curation, and interactive multimedia, where we also
provide video demos. Our code is on
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distilling Generative-Discriminative Representations for Very
  Low-Resolution Face Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junzheng Zhang, Weijia Guo, Bochao Liu, Ruixin Shi, Yong Li, Shiming Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Very low-resolution face recognition is challenging due to the serious loss
of informative facial details in resolution degradation. In this paper, we
propose a generative-discriminative representation distillation approach that
combines generative representation with cross-resolution aligned knowledge
distillation. This approach facilitates very low-resolution face recognition by
jointly distilling generative and discriminative models via two distillation
modules. Firstly, the generative representation distillation takes the encoder
of a diffusion model pretrained for face super-resolution as the generative
teacher to supervise the learning of the student backbone via feature
regression, and then freezes the student backbone. After that, the
discriminative representation distillation further considers a pretrained face
recognizer as the discriminative teacher to supervise the learning of the
student head via cross-resolution relational contrastive distillation. In this
way, the general backbone representation can be transformed into discriminative
head representation, leading to a robust and discriminative student model for
very low-resolution face recognition. Our approach improves the recovery of the
missing details in very low-resolution faces and achieves better knowledge
transfer. Extensive experiments on face datasets demonstrate that our approach
enhances the recognition accuracy of very low-resolution faces, showcasing its
effectiveness and adaptability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MIP-GAF: A MLLM-annotated Benchmark for Most Important Person
  Localization and Group Context Understanding <span class="chip">WACV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06224v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06224v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Surbhi Madan, Shreya Ghosh, Lownish Rai Sookha, M. A. Ganaie, Ramanathan Subramanian, Abhinav Dhall, Tom Gedeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating the Most Important Person (MIP) in any social event setup is a
challenging problem mainly due to contextual complexity and scarcity of labeled
data. Moreover, the causality aspects of MIP estimation are quite subjective
and diverse. To this end, we aim to address the problem by annotating a
large-scale `in-the-wild' dataset for identifying human perceptions about the
`Most Important Person (MIP)' in an image. The paper provides a thorough
description of our proposed Multimodal Large Language Model (MLLM) based data
annotation strategy, and a thorough data quality analysis. Further, we perform
a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art
MIP localization methods, indicating a significant drop in performance compared
to existing datasets. The performance drop shows that the existing MIP
localization algorithms must be more robust with respect to `in-the-wild'
situations. We believe the proposed dataset will play a vital role in building
the next-generation social situation understanding methods. The code and data
is available at https://github.com/surbhimadan92/MIP-GAF.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at WACV 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Design and Implementation of Online Live Streaming System Using A 3D
  Engine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06207v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06207v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aizierjiang Aiersilan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing demand for live video streaming, there is an increasing need
for low-latency and high-quality transmission, especially with the advent of 5G
networks. While 5G offers hardware-level improvements, effective software
solutions for minimizing latency remain essential. Current methods, such as
multi-channel streaming, fail to address latency issues fundamentally, often
only adding new channels without optimizing overall performance. This thesis
proposes a novel approach using a 3D engine (e.g., Unity 3D) to stream
multi-input video data through a single channel with reduced latency. By
leveraging 3D engine capabilities, such as World/Screen Space Cameras, 3D
Canvases, and Webcam Textures, the proposed system consolidates video streams
from multiple external cameras into a unified, low-latency output. The
affiliated project of this thesis demonstrates the implementation of a
low-latency multi-channel live video streaming system. It employs the RTSP
protocol and examines video encoding techniques, alongside a client-side
application based on Unity 3D. The system architecture includes a WebSocket
server for persistent connections, an HTTP server for communication, a MySQL
database for storage, Redis for caching, and Nginx for load balancing. Each
module operates independently, ensuring flexibility and scalability in the
system's design. A key innovation of this system is its use of a 3D scene to
map multiple video inputs onto a virtual canvas, recorded by an in-engine
camera for transmission. This design minimizes redundant data, enabling an
efficient and director-guided live streaming network. The thesis concludes by
discussing challenges encountered during the project and provides solutions for
future improvement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do LLMs Understand Visual Anomalies? Uncovering LLM's Capabilities in
  Zero-shot Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.09654v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.09654v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Zhu, Shaofeng Cai, Fang Deng, Beng Chin Ooi, Junran Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large vision-language models (LVLMs) are markedly proficient in deriving
visual representations guided by natural language. Recent explorations have
utilized LVLMs to tackle zero-shot visual anomaly detection (VAD) challenges by
pairing images with textual descriptions indicative of normal and abnormal
conditions, referred to as anomaly prompts. However, existing approaches depend
on static anomaly prompts that are prone to cross-semantic ambiguity, and
prioritize global image-level representations over crucial local pixel-level
image-to-text alignment that is necessary for accurate anomaly localization. In
this paper, we present ALFA, a training-free approach designed to address these
challenges via a unified model. We propose a run-time prompt adaptation
strategy, which first generates informative anomaly prompts to leverage the
capabilities of a large language model (LLM). This strategy is enhanced by a
contextual scoring mechanism for per-image anomaly prompt adaptation and
cross-semantic ambiguity mitigation. We further introduce a novel fine-grained
aligner to fuse local pixel-level semantics for precise anomaly localization,
by projecting the image-text alignment from global to local semantic spaces.
Extensive evaluations on MVTec and VisA datasets confirm ALFA's effectiveness
in harnessing the language potential for zero-shot VAD, achieving significant
PRO improvements of 12.1% on MVTec and 8.9% on VisA compared to
state-of-the-art approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MM'24 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Question-Answering Dense Video Events 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04388v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04388v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hangyu Qin, Junbin Xiao, Angela Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have shown excellent performance in
question-answering of single-event videos. In this paper, we present
question-answering dense video events, a novel task that requires answering and
grounding the dense-event questions in long videos, thus challenging MLLMs to
faithfully comprehend and reason about multiple events occurring over extended
time periods. To facilitate the study, we construct DeVE-QA - a dataset
featuring 78K questions about 26K events on 10.6K long videos. We then
benchmark and show that existing MLLMs excelling at single-event QA struggle to
perform well in DeVE-QA. For improvement, we propose DeVi, a novel
training-free MLLM approach that highlights a hierarchical captioning module, a
temporal event memory module, and a self-consistency checking module to
respectively detect, contextualize and memorize, and ground dense-events in
long videos for question answering. Extensive experiments show that DeVi is
superior at answering dense-event questions and grounding relevant video
moments. Compared with existing MLLMs, it achieves a remarkable increase of 4.1
percent and 3.7 percent for G(round)QA accuracy on DeVE-QA and NExT-GQA
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FrameCorr: Adaptive, Autoencoder-based Neural Compression for Video
  Reconstruction in Resource and Timing Constrained Network Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02453v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02453v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Li, Shehab Sarar Ahmed, Deepak Nair
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing adoption of video processing via Internet of Things (IoT)
devices due to their cost-effectiveness, transmitting captured data to nearby
servers poses challenges due to varying timing constraints and scarcity of
network bandwidth. Existing video compression methods face difficulties in
recovering compressed data when incomplete data is provided. Here, we introduce
FrameCorr, a deep-learning based solution that utilizes previously received
data to predict the missing segments of a frame, enabling the reconstruction of
a frame from partially received data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Machine Learning-Driven Open-Source Framework for Assessing QoE in
  Multimedia Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.08564v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.08564v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Parsa Hassani Shariat Panahi, Amir Hossein Jalilvand, Abolfazl Diyanat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Internet is integral to modern life, influencing communication, business,
and lifestyles globally. As dependence on Internet services grows, the demand
for high-quality service delivery increases. Service providers must maintain
high standards of quality of service and quality of experience (QoE) to ensure
user satisfaction. QoE, which reflects user satisfaction with service quality,
is a key metric for multimedia services, yet it is challenging to measure due
to its subjective nature and the complexities of real-time feedback. This paper
introduces a machine learning-based framework for objectively assessing QoE in
multimedia networks. The open-source framework complies with the ITU-T P.1203
standard. It automates data collection and user satisfaction prediction using
key network parameters such as delay, jitter, packet loss, bitrate, and
throughput. Using a dataset of over 20,000 records from various network
conditions, the Random Forest model predicts the mean opinion score with 95.8%
accuracy. Our framework addresses the limitations of existing QoE models by
integrating real-time data collection, machine learning predictions, and
adherence to international standards. This approach enhances QoE evaluation
accuracy and allows dynamic network resource management, optimizing performance
and cost-efficiency. Its open-source nature encourages adaptation and extension
for various multimedia services. The findings significantly affect the
telecommunications industry in managing and optimizing multimedia services. The
network centric QoE prediction of the framework offers a scalable solution to
improve user satisfaction without the need for content-specific data. Future
enhancements could include advanced machine learning models and broader
applicability to digital services. This research contributes a practical,
standardized tool for QoE assessment across diverse networks and platforms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-09T00:00:00Z">2024-09-09</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">67</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Estimating the Completeness of Discrete Speech Units 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06109v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06109v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sung-Lin Yeh, Hao Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representing speech with discrete units has been widely used in speech codec
and speech generation. However, there are several unverified claims about
self-supervised discrete units, such as disentangling phonetic and speaker
information with k-means, or assuming information loss after k-means. In this
work, we take an information-theoretic perspective to answer how much
information is present (information completeness) and how much information is
accessible (information accessibility), before and after residual vector
quantization. We show a lower bound for information completeness and estimate
completeness on discretized HuBERT representations after residual vector
quantization. We find that speaker information is sufficiently present in
HuBERT discrete units, and that phonetic information is sufficiently present in
the residual, showing that vector quantization does not achieve
disentanglement. Our results offer a comprehensive assessment on the choice of
discrete units, and suggest that a lot more information in the residual should
be mined rather than discarded.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Doppelgänger's Watch: A Split Objective Approach to Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06107v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06107v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shervin Ghasemlou, Ashish Katiyar, Aparajita Saraf, Seungwhan Moon, Mangesh Pujari, Pinar Donmez, Babak Damavandi, Anuj Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the problem of "generation supervision" in
large language models, and present a novel bicameral architecture to separate
supervision signals from their core capability, helpfulness. Doppelg\"anger, a
new module parallel to the underlying language model, supervises the generation
of each token, and learns to concurrently predict the supervision score(s) of
the sequences up to and including each token. In this work, we present the
theoretical findings, and leave the report on experimental results to a
forthcoming publication.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information
  in Task-Oriented Dialog 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujian Gan, Changling Li, Jinxia Xie, Luou Wen, Matthew Purver, Massimo Poesio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce ClarQ-LLM, an evaluation framework consisting of bilingual
English-Chinese conversation tasks, conversational agents and evaluation
metrics, designed to serve as a strong benchmark for assessing agents' ability
to ask clarification questions in task-oriented dialogues. The benchmark
includes 31 different task types, each with 10 unique dialogue scenarios
between information seeker and provider agents. The scenarios require the
seeker to ask questions to resolve uncertainty and gather necessary information
to complete tasks. Unlike traditional benchmarks that evaluate agents based on
fixed dialogue content, ClarQ-LLM includes a provider conversational agent to
replicate the original human provider in the benchmark. This allows both
current and future seeker agents to test their ability to complete information
gathering tasks through dialogue by directly interacting with our provider
agent. In tests, LLAMA3.1 405B seeker agent managed a maximum success rate of
only 60.05\%, showing that ClarQ-LLM presents a strong challenge for future
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DetoxBench: Benchmarking Large Language Models for Multitask Fraud &
  Abuse Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joymallya Chakraborty, Wei Xia, Anirban Majumder, Dan Ma, Walid Chaabene, Naveed Janvekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Identifying the sources of ideological bias in <span class="highlight-title">GPT</span> models through
  linguistic variation in output 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06043v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06043v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christina Walker, Joan C. Timoneda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extant work shows that generative AI models such as GPT-3.5 and 4 perpetuate
social stereotypes and biases. One concerning but less explored source of bias
is ideology. Do GPT models take ideological stances on politically sensitive
topics? In this article, we provide an original approach to identifying
ideological bias in generative models, showing that bias can stem from both the
training data and the filtering algorithm. We leverage linguistic variation in
countries with contrasting political attitudes to evaluate bias in average GPT
responses to sensitive political topics in those languages. First, we find that
GPT output is more conservative in languages that map well onto conservative
societies (i.e., Polish), and more liberal in languages used uniquely in
liberal societies (i.e., Swedish). This result provides strong evidence of
training data bias in GPT models. Second, differences across languages observed
in GPT-3.5 persist in GPT-4, even though GPT-4 is significantly more liberal
due to OpenAI's filtering policy. Our main takeaway is that generative model
training must focus on high-quality, curated datasets to reduce bias, even if
it entails a compromise in training data size. Filtering responses after
training only introduces new biases and does not remove the underlying training
biases.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating Causal Cues: Strengthening Spoofed Audio Detection with
  Human-Discernible Linguistic Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06033v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06033v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zahra Khanjani, Tolulope Ale, Jianwu Wang, Lavon Davis, Christine Mallinson, Vandana P. Janeja
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Several types of spoofed audio, such as mimicry, replay attacks, and
deepfakes, have created societal challenges to information integrity. Recently,
researchers have worked with sociolinguistics experts to label spoofed audio
samples with Expert Defined Linguistic Features (EDLFs) that can be discerned
by the human ear: pitch, pause, word-initial and word-final release bursts of
consonant stops, audible intake or outtake of breath, and overall audio
quality. It is established that there is an improvement in several deepfake
detection algorithms when they augmented the traditional and common features of
audio data with these EDLFs. In this paper, using a hybrid dataset comprised of
multiple types of spoofed audio augmented with sociolinguistic annotations, we
investigate causal discovery and inferences between the discernible linguistic
features and the label in the audio clips, comparing the findings of the causal
models with the expert ground truth validation labeling process. Our findings
suggest that the causal models indicate the utility of incorporating linguistic
features to help discern spoofed audio, as well as the overall need and
opportunity to incorporate human knowledge into models and techniques for
strengthening AI models. The causal discovery and inference can be used as a
foundation of training humans to discern spoofed audio as well as automating
EDLFs labeling for the purpose of performance improvement of the common
AI-based spoofed audio detectors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improved Visually <span class="highlight-title">Prompt</span>ed Keyword Localisation in Real Low-Resource
  Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leanne Nortje, Dan Oneata, Herman Kamper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given an image query, visually prompted keyword localisation (VPKL) aims to
find occurrences of the depicted word in a speech collection. This can be
useful when transcriptions are not available for a low-resource language (e.g.
if it is unwritten). Previous work showed that VPKL can be performed with a
visually grounded speech model trained on paired images and unlabelled speech.
But all experiments were done on English. Moreover, transcriptions were used to
get positive and negative pairs for the contrastive loss. This paper introduces
a few-shot learning scheme to mine pairs automatically without transcriptions.
On English, this results in only a small drop in performance. We also - for the
first time - consider VPKL on a real low-resource language, Yoruba. While
scores are reasonable, here we see a bigger drop in performance compared to
using ground truth pairs because the mining is less accurate in Yoruba.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Transformer</span>Ranker: A Tool for Efficiently Finding the Best-Suited
  Language Models for Downstream Classification Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05997v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05997v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Garbas, Max Ploner, Alan Akbik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classification tasks in NLP are typically addressed by selecting a
pre-trained language model (PLM) from a model hub, and fine-tuning it for the
task at hand. However, given the very large number of PLMs that are currently
available, a practical challenge is to determine which of them will perform
best for a specific downstream task. With this paper, we introduce
TransformerRanker, a lightweight library that efficiently ranks PLMs for
classification tasks without the need for computationally costly fine-tuning.
Our library implements current approaches for transferability estimation
(LogME, H-Score, kNN), in combination with layer aggregation options, which we
empirically showed to yield state-of-the-art rankings of PLMs (Garbas et al.,
2024). We designed the interface to be lightweight and easy to use, allowing
users to directly connect to the HuggingFace Transformers and Dataset
libraries. Users need only select a downstream classification task and a list
of PLMs to create a ranking of likely best-suited PLMs for their task. We make
TransformerRanker available as a pip-installable open-source library
https://github.com/flairNLP/transformer-ranker.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MessIRve: A Large-Scale Spanish Information Retrieval <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05994v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05994v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisco Valentini, Viviana Cotik, Damián Furman, Ivan Bercovich, Edgar Altszyler, Juan Manuel Pérez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval (IR) is the task of finding relevant documents in
response to a user query. Although Spanish is the second most spoken native
language, current IR benchmarks lack Spanish data, hindering the development of
information access tools for Spanish speakers. We introduce MessIRve, a
large-scale Spanish IR dataset with around 730 thousand queries from Google's
autocomplete API and relevant documents sourced from Wikipedia. MessIRve's
queries reflect diverse Spanish-speaking regions, unlike other datasets that
are translated from English or do not consider dialectal variations. The large
size of the dataset allows it to cover a wide variety of topics, unlike smaller
datasets. We provide a comprehensive description of the dataset, comparisons
with existing datasets, and baseline evaluations of prominent IR models. Our
contributions aim to advance Spanish IR research and improve information access
for Spanish speakers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AI for Mathematics Mathematical Formalized Problem Solving and Theorem
  Proving in Different Fields in Lean4 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05977v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05977v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xichen Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Using computerized verifiable formal languages like Lean 4 to prove
mathematical theorems has a significant impact on mathematical formalization.
Lean 4 offers prominent potential for advancing mathematical reasoning.
However, existing efforts are limited to mathematical formalization languages
in substantial online corpora and are dedicated to keeping pace with rapidly
evolving languages. To bridge the gap between the traditional and computerized
proof, my approach to formalizing theorem proving involves generating formal
steps and complete proofs using Large Language Models (LLMs) based on Natural
Language (NL) proofs. The method is to introduce the basic structure and
tactics in general, determine how AI can assist the mathematical formalization
process to improve its performance, and give examples of solving problems in
Lean 4 comparing to NL, mainly in IMO, and a sample theorem proving in abstract
algebra.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Small Claims Court for the NLP: Judging Legal Text Classification
  Strategies With Small <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05972v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05972v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mariana Yukari Noguti, Edduardo Vellasques, Luiz Eduardo Soares Oliveira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in language modelling has significantly decreased the need of
labelled data in text classification tasks. Transformer-based models,
pre-trained on unlabeled data, can outmatch the performance of models trained
from scratch for each task. However, the amount of labelled data need to
fine-tune such type of model is still considerably high for domains requiring
expert-level annotators, like the legal domain. This paper investigates the
best strategies for optimizing the use of a small labeled dataset and large
amounts of unlabeled data and perform a classification task in the legal area
with 50 predefined topics. More specifically, we use the records of demands to
a Brazilian Public Prosecutor's Office aiming to assign the descriptions in one
of the subjects, which currently demands deep legal knowledge for manual
filling. The task of optimizing the performance of classifiers in this scenario
is especially challenging, given the low amount of resources available
regarding the Portuguese language, especially in the legal domain. Our results
demonstrate that classic supervised models such as logistic regression and SVM
and the ensembles random forest and gradient boosting achieve better
performance along with embeddings extracted with word2vec when compared to BERT
language model. The latter demonstrates superior performance in association
with the architecture of the model itself as a classifier, having surpassed all
previous models in that regard. The best result was obtained with Unsupervised
Data Augmentation (UDA), which jointly uses BERT, data augmentation, and
strategies of semi-supervised learning, with an accuracy of 80.7% in the
aforementioned task.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05840v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05840v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of Multimodal Large Language Models (MLLMs) has seen
significant advancements. However, the quantity and quality of multimodal
instruction data have emerged as significant bottlenecks in their progress.
Manually creating multimodal instruction data is both time-consuming and
inefficient, posing challenges in producing instructions of high complexity.
Moreover, distilling instruction data from black-box commercial models (e.g.,
GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains
performance to that of these models. The challenge of curating diverse and
complex instruction data remains substantial. We propose MMEvol, a novel
multimodal instruction data evolution framework that combines fine-grained
perception evolution, cognitive reasoning evolution, and interaction evolution.
This iterative approach breaks through data quality bottlenecks to generate a
complex and diverse image-text instruction dataset, thereby empowering MLLMs
with enhanced capabilities. Beginning with an initial set of instructions,
SEED-163K, we utilize MMEvol to systematically broadens the diversity of
instruction types, integrates reasoning steps to enhance cognitive
capabilities, and extracts detailed information from images to improve visual
understanding and robustness. To comprehensively evaluate the effectiveness of
our data, we train LLaVA-NeXT using the evolved data and conduct experiments
across 13 vision-language tasks. Compared to the baseline trained with seed
data, our approach achieves an average accuracy improvement of 3.1 points and
reaches state-of-the-art (SOTA) performance on 9 of these tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving <span class="highlight-title">Pretrain</span>ing Data Using Perplexity Correlations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05816v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05816v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tristan Thrush, Christopher Potts, Tatsunori Hashimoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quality pretraining data is often seen as the key to high-performance
language models. However, progress in understanding pretraining data has been
slow due to the costly pretraining runs required for data selection
experiments. We present a framework that avoids these costs and selects
high-quality pretraining data without any LLM training of our own. Our work is
based on a simple observation: LLM losses on many pretraining texts are
correlated with downstream benchmark performance, and selecting
high-correlation documents is an effective pretraining data selection method.
We build a new statistical framework for data selection centered around
estimates of perplexity-benchmark correlations and perform data selection using
a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of
thousands of web domains. In controlled pretraining experiments at the 160M
parameter scale on 8 benchmarks, our approach outperforms DSIR on every
benchmark, while matching the best data selector found in DataComp-LM, a
hand-engineered bigram classifier.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Chinese Knowledge Rectification in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05806v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05806v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While Large Language Models (LLMs) exhibit remarkable generative
capabilities, they are not without flaws, particularly in the form of
hallucinations. This issue is even more pronounced when LLMs are applied to
specific languages and domains. For example, LLMs may generate nonsense
information when handling Chinese ancient poetry, proverbs, or idioms, owing to
the lack of specific knowledge. To this end, this paper introduces a benchmark
for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,
we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of
knowledge from various sources, including classical texts, idioms, and content
from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,
antithesis, and logical constructs inherent in the Chinese language. Through
the analysis of this dataset, we uncover the challenges faced by current LLMs
in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge
editing techniques on this dataset unveil the substantial scope for advancement
in the rectification of Chinese knowledge. Code and dataset are available at
https://github.com/zjunlp/EasyEdit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work; code and dataset are available at
  https://github.com/zjunlp/EasyEdit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PDAF: A Phonetic Debiasing Attention Framework For Speaker Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05799v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05799v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Massa Baali, Abdulhamid Aldoobi, Hira Dhamyal, Rita Singh, Bhiksha Raj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speaker verification systems are crucial for authenticating identity through
voice. Traditionally, these systems focus on comparing feature vectors,
overlooking the speech's content. However, this paper challenges this by
highlighting the importance of phonetic dominance, a measure of the frequency
or duration of phonemes, as a crucial cue in speaker verification. A novel
Phoneme Debiasing Attention Framework (PDAF) is introduced, integrating with
existing attention frameworks to mitigate biases caused by phonetic dominance.
PDAF adjusts the weighting for each phoneme and influences feature extraction,
allowing for a more nuanced analysis of speech. This approach paves the way for
more accurate and reliable identity authentication through voice. Furthermore,
by employing various weighting strategies, we evaluate the influence of
phonetic features on the efficacy of the speaker verification system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SLT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evidence from fMRI Supports a Two-Phase Abstraction Process in Language
  Models <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05771v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05771v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emily Cheng, Richard J. Antonello
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research has repeatedly demonstrated that intermediate hidden states
extracted from large language models are able to predict measured brain
response to natural language stimuli. Yet, very little is known about the
representation properties that enable this high prediction performance. Why is
it the intermediate layers, and not the output layers, that are most capable
for this unique and highly general transfer task? In this work, we show that
evidence from language encoding models in fMRI supports the existence of a
two-phase abstraction process within LLMs. We use manifold learning methods to
show that this abstraction process naturally arises over the course of training
a language model and that the first "composition" phase of this abstraction
process is compressed into fewer layers as training continues. Finally, we
demonstrate a strong correspondence between layerwise encoding performance and
the intrinsic dimensionality of representations from LLMs. We give initial
evidence that this correspondence primarily derives from the inherent
compositionality of LLMs and not their next-word prediction properties.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Equal contribution from both authors. Submitted to NeurIPS NeuroAI
  workshop 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Democratizing Multilingual Large Language Models For Medicine
  Through A Two-Stage Instruction Fine-tuning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05732v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05732v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Zhou, Surajsinh Parmar, Anubhav Bhatti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open-source, multilingual medical large language models (LLMs) have the
potential to serve linguistically diverse populations across different regions.
Adapting generic LLMs for healthcare often requires continual pretraining, but
this approach is computationally expensive and sometimes impractical.
Instruction fine-tuning on a specific task may not always guarantee optimal
performance due to the lack of broader domain knowledge that the model needs to
understand and reason effectively in diverse scenarios. To address these
challenges, we introduce two multilingual instruction fine-tuning datasets,
MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in
six languages. We propose a two-stage training paradigm: the first stage
injects general medical knowledge using MMed-IFT, while the second stage
fine-tunes task-specific multiple-choice questions with MMed-IFT-MC. Our method
achieves competitive results on both English and multilingual benchmarks,
striking a balance between computational efficiency and performance. We plan to
make our dataset and model weights public at
\url{https://github.com/SpassMed/Med-Llama3} in the future.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report v1, work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Referring Expression Generation in Visually Grounded Dialogue with
  Discourse-aware Comprehension Guiding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05721v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05721v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bram Willemsen, Gabriel Skantze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an approach to referring expression generation (REG) in visually
grounded dialogue that is meant to produce referring expressions (REs) that are
both discriminative and discourse-appropriate. Our method constitutes a
two-stage process. First, we model REG as a text- and image-conditioned
next-token prediction task. REs are autoregressively generated based on their
preceding linguistic context and a visual representation of the referent.
Second, we propose the use of discourse-aware comprehension guiding as part of
a generate-and-rerank strategy through which candidate REs generated with our
REG model are reranked based on their discourse-dependent discriminatory power.
Results from our human evaluation indicate that our proposed two-stage approach
is effective in producing discriminative REs, with higher performance in terms
of text-image retrieval accuracy for reranked REs compared to those generated
using greedy decoding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at INLG 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RegNLP in Action: Facilitating Compliance Through Automated Information
  Retrieval and Answer Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuba Gokhan, Kexin Wang, Iryna Gurevych, Ted Briscoe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Regulatory documents, issued by governmental regulatory bodies, establish
rules, guidelines, and standards that organizations must adhere to for legal
compliance. These documents, characterized by their length, complexity and
frequent updates, are challenging to interpret, requiring significant
allocation of time and expertise on the part of organizations to ensure ongoing
compliance.Regulatory Natural Language Processing (RegNLP) is a
multidisciplinary subfield aimed at simplifying access to and interpretation of
regulatory rules and obligations. We define an Automated Question-Passage
Generation task for RegNLP, create the ObliQA dataset containing 27,869
questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation
document collection, design a baseline Regulatory Information Retrieval and
Answer Generation system, and evaluate it with RePASs, a novel evaluation
metric that tests whether generated answers accurately capture all relevant
obligations and avoid contradictions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluation of real-time transcriptions using end-to-end ASR models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carlos Arriaga, Alejandro Pozo, Javier Conde, Alvaro Alonso
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly
evolved in the last few years. Traditional architectures based on pipelines
have been replaced by joint end-to-end (E2E) architectures that simplify and
streamline the model training process. In addition, new AI training methods,
such as weak-supervised learning have reduced the need for high-quality audio
datasets for model training. However, despite all these advancements, little to
no research has been done on real-time transcription. In real-time scenarios,
the audio is not pre-recorded, and the input audio must be fragmented to be
processed by the ASR systems. To achieve real-time requirements, these
fragments must be as short as possible to reduce latency. However, audio cannot
be split at any point as dividing an utterance into two separate fragments will
generate an incorrect transcription. Also, shorter fragments provide less
context for the ASR model. For this reason, it is necessary to design and test
different splitting algorithms to optimize the quality and delay of the
resulting transcription. In this paper, three audio splitting algorithms are
evaluated with different ASR models to determine their impact on both the
quality of the transcription and the end-to-end delay. The algorithms are
fragmentation at fixed intervals, voice activity detection (VAD), and
fragmentation with feedback. The results are compared to the performance of the
same model, without audio fragmentation, to determine the effects of this
division. The results show that VAD fragmentation provides the best quality
with the highest delay, whereas fragmentation at fixed intervals provides the
lowest quality and the lowest delay. The newly proposed feedback algorithm
exchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively,
to the VAD splitting.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting English Winogender Schemas for Consistency, Coverage, and
  Grammatical Case 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05653v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05653v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vagrant Gautam, Julius Steuer, Eileen Bingert, Ray Johns, Anne Lauscher, Dietrich Klakow
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While measuring bias and robustness in coreference resolution are important
goals, such measurements are only as good as the tools we use to measure them
with. Winogender schemas (Rudinger et al., 2018) are an influential dataset
proposed to evaluate gender bias in coreference resolution, but a closer look
at the data reveals issues with the instances that compromise their use for
reliable evaluation, including treating different grammatical cases of pronouns
in the same way, violations of template constraints, and typographical errors.
We identify these issues and fix them, contributing a new dataset: Winogender
2.0. Our changes affect performance with state-of-the-art supervised
coreference resolution systems as well as all model sizes of the language model
FLAN-T5, with F1 dropping on average 0.1 points. We also propose a new method
to evaluate pronominal bias in coreference resolution that goes beyond the
binary. With this method and our new dataset which is balanced for grammatical
case, we empirically demonstrate that bias characteristics vary not just across
pronoun sets, but also across surface forms of those sets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Longer is (Not Necessarily) Stronger: Punctuated Long-Sequence Training
  for Enhanced Speech Recognition and Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nithin Rao Koluguri, Travis Bartley, Hainan Xu, Oleksii Hrinchuk, Jagadeesh Balam, Boris Ginsburg, Georg Kucsko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a new method for training sequence-to-sequence models for
speech recognition and translation tasks. Instead of the traditional approach
of training models on short segments containing only lowercase or partial
punctuation and capitalization (PnC) sentences, we propose training on longer
utterances that include complete sentences with proper punctuation and
capitalization. We achieve this by using the FastConformer architecture which
allows training 1 Billion parameter models with sequences up to 60 seconds long
with full attention. However, while training with PnC enhances the overall
performance, we observed that accuracy plateaus when training on sequences
longer than 40 seconds across various evaluation settings. Our proposed method
significantly improves punctuation and capitalization accuracy, showing a 25%
relative word error rate (WER) improvement on the Earnings-21 and Earnings-22
benchmarks. Additionally, training on longer audio segments increases the
overall model accuracy across speech recognition and translation benchmarks.
The model weights and training code are open-sourced though NVIDIA NeMo.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at SLT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ExDDI: Explaining Drug-Drug Interaction Predictions with Natural
  Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05592v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05592v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoyue Sun, Jiazheng Li, Gabriele Pergola, Yulan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting unknown drug-drug interactions (DDIs) is crucial for improving
medication safety. Previous efforts in DDI prediction have typically focused on
binary classification or predicting DDI categories, with the absence of
explanatory insights that could enhance trust in these predictions. In this
work, we propose to generate natural language explanations for DDI predictions,
enabling the model to reveal the underlying pharmacodynamics and
pharmacokinetics mechanisms simultaneously as making the prediction. To do
this, we have collected DDI explanations from DDInter and DrugBank and
developed various models for extensive experiments and analysis. Our models can
provide accurate explanations for unknown DDIs between known drugs. This paper
contributes new tools to the field of DDI prediction and lays a solid
foundation for further research on generating explanations for DDI predictions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spatially-Aware Speaker for Vision-and-Language Navigation Instruction
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muraleekrishna Gopinathan, Martin Masek, Jumana Abu-Khalaf, David Suter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embodied AI aims to develop robots that can \textit{understand} and execute
human language instructions, as well as communicate in natural languages. On
this front, we study the task of generating highly detailed navigational
instructions for the embodied robots to follow. Although recent studies have
demonstrated significant leaps in the generation of step-by-step instructions
from sequences of images, the generated instructions lack variety in terms of
their referral to objects and landmarks. Existing speaker models learn
strategies to evade the evaluation metrics and obtain higher scores even for
low-quality sentences. In this work, we propose SAS (Spatially-Aware Speaker),
an instruction generator or \textit{Speaker} model that utilises both
structural and semantic knowledge of the environment to produce richer
instructions. For training, we employ a reward learning method in an
adversarial setting to avoid systematic bias introduced by language evaluation
metrics. Empirically, our method outperforms existing instruction generation
models, evaluated using standard metrics. Our code is available at
\url{https://github.com/gmuraleekrishna/SAS}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SciAgents: Automating scientific discovery through multi-agent
  intelligent graph reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Ghafarollahi, Markus J. Buehler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A key challenge in artificial intelligence is the creation of systems capable
of autonomously advancing scientific understanding by exploring novel domains,
identifying complex patterns, and uncovering previously unseen connections in
vast scientific data. In this work, we present SciAgents, an approach that
leverages three core concepts: (1) the use of large-scale ontological knowledge
graphs to organize and interconnect diverse scientific concepts, (2) a suite of
large language models (LLMs) and data retrieval tools, and (3) multi-agent
systems with in-situ learning capabilities. Applied to biologically inspired
materials, SciAgents reveals hidden interdisciplinary relationships that were
previously considered unrelated, achieving a scale, precision, and exploratory
power that surpasses traditional human-driven research methods. The framework
autonomously generates and refines research hypotheses, elucidating underlying
mechanisms, design principles, and unexpected material properties. By
integrating these capabilities in a modular fashion, the intelligent system
yields material discoveries, critique and improve existing hypotheses, retrieve
up-to-date data about existing research, and highlights their strengths and
limitations. Our case studies demonstrate scalable capabilities to combine
generative AI, ontological representations, and multi-agent modeling,
harnessing a `swarm of intelligence' similar to biological systems. This
provides new avenues for materials discovery and accelerates the development of
advanced materials by unlocking Nature's design principles.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Qi<span class="highlight-title">BERT</span> -- Classifying Online Conversations Messages with <span class="highlight-title">BERT</span> as a
  Feature 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05530v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05530v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bruno D. Ferreira-Saraiva, Zuil Pirola, João P. Matos-Carvalho, Manuel Marques-Pita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent developments in online communication and their usage in everyday life
have caused an explosion in the amount of a new genre of text data, short text.
Thus, the need to classify this type of text based on its content has a
significant implication in many areas. Online debates are no exception, once
these provide access to information about opinions, positions and preferences
of its users. This paper aims to use data obtained from online social
conversations in Portuguese schools (short text) to observe behavioural trends
and to see if students remain engaged in the discussion when stimulated. This
project used the state of the art (SoA) Machine Learning (ML) algorithms and
methods, through BERT based models to classify if utterances are in or out of
the debate subject. Using SBERT embeddings as a feature, with supervised
learning, the proposed model achieved results above 0.95 average accuracy for
classifying online messages. Such improvements can help social scientists
better understand human communication, behaviour, discussion and persuasion.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Harmonic Reasoning in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05521v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05521v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Kruspe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are becoming very popular and are used for many
different purposes, including creative tasks in the arts. However, these models
sometimes have trouble with specific reasoning tasks, especially those that
involve logical thinking and counting. This paper looks at how well LLMs
understand and reason when dealing with musical tasks like figuring out notes
from intervals and identifying chords and scales. We tested GPT-3.5 and GPT-4o
to see how they handle these tasks. Our results show that while LLMs do well
with note intervals, they struggle with more complicated tasks like recognizing
chords and scales. This points out clear limits in current LLM abilities and
shows where we need to make them better, which could help improve how they
think and work in both artistic and other complex areas. We also provide an
automatically generated benchmark data set for the described tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Elsevier Arena: Human Evaluation of Chemistry/Biology/Health
  Foundational Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05486v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05486v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Camilo Thorne, Christian Druckenbrodt, Kinga Szarkowska, Deepika Goyal, Pranita Marajan, Vijay Somanath, Corey Harper, Mao Yan, Tony Scerri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The quality and capabilities of large language models cannot be currently
fully assessed with automated, benchmark evaluations. Instead, human
evaluations that expand on traditional qualitative techniques from natural
language generation literature are required. One recent best-practice consists
in using A/B-testing frameworks, which capture preferences of human evaluators
for specific models. In this paper we describe a human evaluation experiment
focused on the biomedical domain (health, biology, chemistry/pharmacology)
carried out at Elsevier. In it a large but not massive (8.8B parameter)
decoder-only foundational transformer trained on a relatively small (135B
tokens) but highly curated collection of Elsevier datasets is compared to
OpenAI's GPT-3.5-turbo and Meta's foundational 7B parameter Llama 2 model
against multiple criteria. Results indicate -- even if IRR scores were
generally low -- a preference towards GPT-3.5-turbo, and hence towards models
that possess conversational abilities, are very large and were trained on very
large datasets. But at the same time, indicate that for less massive models
training on smaller but well-curated training sets can potentially give rise to
viable alternatives in the biomedical domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 tables, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representational Analysis of Binding in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05448v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05448v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qin Dai, Benjamin Heinzerling, Kentaro Inui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity tracking is essential for complex reasoning. To perform in-context
entity tracking, language models (LMs) must bind an entity to its attribute
(e.g., bind a container to its content) to recall attribute for a given entity.
For example, given a context mentioning ``The coffee is in Box Z, the stone is
in Box M, the map is in Box H'', to infer ``Box Z contains the coffee'' later,
LMs must bind ``Box Z'' to ``coffee''. To explain the binding behaviour of LMs,
Feng and Steinhardt (2023) introduce a Binding ID mechanism and state that LMs
use a abstract concept called Binding ID (BI) to internally mark
entity-attribute pairs. However, they have not directly captured the BI
determinant information from entity activations. In this work, we provide a
novel view of the Binding ID mechanism by localizing the prototype of BI
information. Specifically, we discover that there exists a low-rank subspace in
the hidden state (or activation) of LMs, that primarily encodes the order of
entity and attribute and which is used as the prototype of BI to causally
determine the binding. To identify this subspace, we choose principle component
analysis as our first attempt and it is empirically proven to be effective.
Moreover, we also discover that when editing representations along directions
in the subspace, LMs tend to bind a given entity to other attributes
accordingly. For example, by patching activations along the BI encoding
direction we can make the LM to infer ``Box Z contains the stone'' and ``Box Z
contains the map''.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assessing SPARQL capabilities of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05925v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05925v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lars-Peter Meyer, Johannes Frey, Felix Brei, Natanael Arndt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>peer reviewed publication at NLP4KGc @ Semantics 2024, see
  https://sites.google.com/view/3rdnlp4kgc</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ STLM Engineering Report: Dropout 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dylan Hillier, Leon Guertler, Bobby Cheng, Cheston Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work we explore the relevance of dropout for modern language models,
particularly in the context of models on the scale of <100M parameters. We
explore it's relevance firstly in the regime of improving the sample efficiency
of models given small, high quality datasets, and secondly in the regime of
improving the quality of its fit on larger datasets where models may underfit.
We find that concordant with conventional wisdom, dropout remains effective in
the overfitting scenario, and that furthermore it may have some relevance for
improving the fit of models even in the case of excess data, as suggested by
previous research. In the process we find that the existing explanation for the
mechanism behind this performance gain is not applicable in the case of
language modelling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, For code base see
  https://github.com/LeonGuertler/SuperTinyLanguageModels</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NLLB-E5: A Scalable Multilingual Retrieval Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arkadeep Acharya, Rudra Murthy, Vishwajeet Kumar, Jaydeep Sen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant progress in multilingual information retrieval, the lack
of models capable of effectively supporting multiple languages, particularly
low-resource like Indic languages, remains a critical challenge. This paper
presents NLLB-E5: A Scalable Multilingual Retrieval Model. NLLB-E5 leverages
the in-built multilingual capabilities in the NLLB encoder for translation
tasks. It proposes a distillation approach from multilingual retriever E5 to
provide a zero-shot retrieval approach handling multiple languages, including
all major Indic languages, without requiring multilingual training data. We
evaluate the model on a comprehensive suite of existing benchmarks, including
Hindi-BEIR, highlighting its robust performance across diverse languages and
tasks. Our findings uncover task and domain-specific challenges, providing
valuable insights into the retrieval performance, especially for low-resource
languages. NLLB-E5 addresses the urgent need for an inclusive, scalable, and
language-agnostic text retrieval model, advancing the field of multilingual
information access and promoting digital inclusivity for millions of users
globally.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Application Specific Compression of Deep Learning Models <span class="chip">KDD</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05368v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05368v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Raj Rai, Angana Borah, Amit Awekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Deep Learning models are compressed and deployed for specific
applications. However, current Deep Learning model compression methods do not
utilize the information about the target application. As a result, the
compressed models are application agnostic. Our goal is to customize the model
compression process to create a compressed model that will perform better for
the target application. Our method, Application Specific Compression (ASC),
identifies and prunes components of the large Deep Learning model that are
redundant specifically for the given target application. The intuition of our
work is to prune the parts of the network that do not contribute significantly
to updating the data representation for the given application. We have
experimented with the BERT family of models for three applications: Extractive
QA, Natural Language Inference, and Paraphrase Identification. We observe that
customized compressed models created using ASC method perform better than
existing model compression methods and off-the-shelf compressed models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in the Proceedings of the 8th Joint International Conference
  on Data Science & Management of Data (12th ACM IKDD CODS and 30th COMAD) for
  the Short Research Paper track, 5 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diagnostic Reasoning in Natural Language: Computational Model and
  Application 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05367v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05367v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nils Dycke, Matej Zečević, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diagnostic reasoning is a key component of expert work in many domains. It is
a hard, time-consuming activity that requires expertise, and AI research has
investigated the ways automated systems can support this process. Yet, due to
the complexity of natural language, the applications of AI for diagnostic
reasoning to language-related tasks are lacking. To close this gap, we
investigate diagnostic abductive reasoning (DAR) in the context of
language-grounded tasks (NL-DAR). We propose a novel modeling framework for
NL-DAR based on Pearl's structural causal models and instantiate it in a
comprehensive study of scientific paper assessment in the biomedical domain. We
use the resulting dataset to investigate the human decision-making process in
NL-DAR and determine the potential of LLMs to support structured
decision-making over text. Our framework, open resources and tools lay the
groundwork for the empirical study of collaborative diagnostic reasoning in the
age of LLMs, in the scholarly domain and beyond.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech
  Corpus for Scaling Indian TTS 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05356v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05356v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashwin Sankar, Srija Anand, Praveen Srinivasa Varadhan, Sherry Thomas, Mehak Singal, Shridhar Kumar, Deovrat Mehendale, Aditi Krishana, Giri Raju, Mitesh Khapra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-speech (TTS) synthesis show that large-scale
models trained with extensive web data produce highly natural-sounding output.
However, such data is scarce for Indian languages due to the lack of
high-quality, manually subtitled data on platforms like LibriVox or YouTube. To
address this gap, we enhance existing large-scale ASR datasets containing
natural conversations collected in low-quality environments to generate
high-quality TTS training data. Our pipeline leverages the cross-lingual
generalization of denoising and speech enhancement models trained on English
and applied to Indian languages. This results in IndicVoices-R (IV-R), the
largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704
hours of high-quality speech from 10,496 speakers across 22 Indian languages.
IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS,
and IndicTTS. We also introduce the IV-R Benchmark, the first to assess
zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS
models on Indian voices, ensuring diversity in age, gender, and style. We
demonstrate that fine-tuning an English pre-trained model on a combined dataset
of high-quality IndicTTS and our IV-R dataset results in better zero-shot
speaker generalization compared to fine-tuning on the IndicTTS dataset alone.
Further, our evaluation reveals limited zero-shot generalization for Indian
voices in TTS models trained on prior datasets, which we improve by fine-tuning
the model on our data containing diverse set of speakers across language
families. We open-source all data and code, releasing the first TTS model for
all 22 official Indian languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mpox Narrative on Instagram: A Labeled Multilingual <span class="highlight-title">Dataset</span> of Instagram
  Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05292v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05292v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirmalya Thakur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The world is currently experiencing an outbreak of mpox, which has been
declared a Public Health Emergency of International Concern by WHO. No prior
work related to social media mining has focused on the development of a dataset
of Instagram posts about the mpox outbreak. The work presented in this paper
aims to address this research gap and makes two scientific contributions to
this field. First, it presents a multilingual dataset of 60,127 Instagram posts
about mpox, published between July 23, 2022, and September 5, 2024. The
dataset, available at https://dx.doi.org/10.21227/7fvc-y093, contains Instagram
posts about mpox in 52 languages. For each of these posts, the Post ID, Post
Description, Date of publication, language, and translated version of the post
(translation to English was performed using the Google Translate API) are
presented as separate attributes in the dataset. After developing this dataset,
sentiment analysis, hate speech detection, and anxiety or stress detection were
performed. This process included classifying each post into (i) one of the
sentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or
neutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no
anxiety/stress detected. These results are presented as separate attributes in
the dataset. Second, this paper presents the results of performing sentiment
analysis, hate speech analysis, and anxiety or stress analysis. The variation
of the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and
neutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and
50.64%, respectively. In terms of hate speech detection, 95.75% of the posts
did not contain hate and the remaining 4.25% of the posts contained hate.
Finally, 72.05% of the posts did not indicate any anxiety/stress, and the
remaining 27.95% of the posts represented some form of anxiety/stress.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seek and Solve Reasoning for Table Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05286v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05286v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruya Jiang, Chun Wang, Weihong Deng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Table-based Question Answering (TQA) involves answering questions based on
tabular data. The complexity of table structures and question logic makes this
task difficult even for Large Language Models (LLMs). This paper improves TQA
performance by leveraging LLMs' reasoning capabilities. Inspired by how humans
solve TQA tasks, we propose a Seek-and-Solve pipeline that instructs the LLM to
first seek relevant information and then answer questions. The two stages are
integrated at the reasoning level, and their Chain of Thought (CoT) paths are
integrated into a coherent Seek-and-Solve CoT (SS-CoT). Furthermore, we present
a compact single-stage TQA-solving prompt distilled from the pipeline.
Experiments demonstrate that under In-Context Learning settings, using samples
with SS-CoT paths as demonstrations, the TQA-solving prompt can effectively
guide the LLM to solve complex TQA tasks, resulting in improved performance and
reliability. Our results highlight the importance of properly eliciting LLMs'
reasoning capabilities in solving complex TQA tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Relationship between Truth and Political Bias in Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05283v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05283v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Suyash Fulay, William Brannon, Shrestha Mohanty, Cassandra Overney, Elinor Poole-Dayan, Deb Roy, Jad Kabbara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model alignment research often attempts to ensure that models are
not only helpful and harmless, but also truthful and unbiased. However,
optimizing these objectives simultaneously can obscure how improving one aspect
might impact the others. In this work, we focus on analyzing the relationship
between two concepts essential in both language model alignment and political
science: \textit{truthfulness} and \textit{political bias}. We train reward
models on various popular truthfulness datasets and subsequently evaluate their
political bias. Our findings reveal that optimizing reward models for
truthfulness on these datasets tends to result in a left-leaning political
bias. We also find that existing open-source reward models (i.e. those trained
on standard human preference datasets) already show a similar bias and that the
bias is larger for larger models. These results raise important questions about
both the datasets used to represent truthfulness and what language models
capture about the relationship between truth and politics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RexUniNLU: Recursive Method with Explicit Schema Instructor for
  Universal NLU 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05275v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05275v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengyuan Liu, Shihang Wang, Fubang Zhao, Kun Kuang, Yangyang Kang, Weiming Lu, Changlong Sun, Fei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information Extraction (IE) and Text Classification (CLS) serve as the
fundamental pillars of NLU, with both disciplines relying on analyzing input
sequences to categorize outputs into pre-established schemas. However, there is
no existing encoder-based model that can unify IE and CLS tasks from this
perspective. To fully explore the foundation shared within NLU tasks, we have
proposed a Recursive Method with Explicit Schema Instructor for Universal NLU.
Specifically, we firstly redefine the true universal information extraction
(UIE) with a formal formulation that covers almost all extraction schemas,
including quadruples and quintuples which remain unsolved for previous UIE
models. Then, we expands the formulation to all CLS and multi-modal NLU tasks.
Based on that, we introduce RexUniNLU, an universal NLU solution that employs
explicit schema constraints for IE and CLS, which encompasses all IE and CLS
tasks and prevent incorrect connections between schema and input sequence. To
avoid interference between different schemas, we reset the position ids and
attention mask matrices. Extensive experiments are conducted on IE, CLS in both
English and Chinese, and multi-modality, revealing the effectiveness and
superiority. Our codes are publicly released.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2304.14770</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UPCS: Unbiased Persona Construction for Dialogue Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuiyun Chen, Yanbin Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Narrative systems, such as dialogue and storytelling systems, often utilize
persona profiles to enhance personalized interactions. Existing persona
profiles frequently exhibit biases, posing risks to system integrity and
fairness. To address this, we introduce the UPCS framework, which categorizes
character descriptions into eight dimensions, including bias mitigation
strategies. Experimental results demonstrate UPCS's superiority in accuracy,
diversity, bias elimination, and user satisfaction, marking a significant
advancement in persona construction for reliable narrative systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Benefits of a Concise Chain of Thought on Problem-Solving in Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05618v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05618v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthew Renze, Erhan Guven
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce Concise Chain-of-Thought (CCoT) prompting. We
compared standard CoT and CCoT prompts to see how conciseness impacts response
length and correct-answer accuracy. We evaluated this using GPT-3.5 and GPT-4
with a multiple-choice question-and-answer (MCQA) benchmark. CCoT reduced
average response length by 48.70% for both GPT-3.5 and GPT-4 while having a
negligible impact on problem-solving performance. However, on math problems,
GPT-3.5 with CCoT incurs a performance penalty of 27.69%. Overall, CCoT leads
to an average per-token cost reduction of 22.67%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>All code, data, and supplemental materials are available on GitHub at
  https://github.com/matthewrenze/jhu-concise-cot</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">transformer</span>-based spelling error correction framework for Bangla and
  resource scarce Indic languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.03730v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.03730v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehedi Hasan Bijoy, Nahid Hossain, Salekul Islam, Swakkhar Shatabda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spelling error correction is the task of identifying and rectifying
misspelled words in texts. It is a potential and active research topic in
Natural Language Processing because of numerous applications in human language
understanding. The phonetically or visually similar yet semantically distinct
characters make it an arduous task in any language. Earlier efforts on spelling
error correction in Bangla and resource-scarce Indic languages focused on
rule-based, statistical, and machine learning-based methods which we found
rather inefficient. In particular, machine learning-based approaches, which
exhibit superior performance to rule-based and statistical methods, are
ineffective as they correct each character regardless of its appropriateness.
In this paper, we propose a novel detector-purificator-corrector framework,
DPCSpell based on denoising transformers by addressing previous issues. In
addition to that, we present a method for large-scale corpus creation from
scratch which in turn resolves the resource limitation problem of any
left-to-right scripted language. The empirical outcomes demonstrate the
effectiveness of our approach, which outperforms previous state-of-the-art
methods by attaining an exact match (EM) score of 94.78%, a precision score of
0.9487, a recall score of 0.9478, an f1 score of 0.948, an f0.5 score of
0.9483, and a modified accuracy (MA) score of 95.16% for Bangla spelling error
correction. The models and corpus are publicly available at
https://tinyurl.com/DPCSpell.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 4 figures, and 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ro<span class="highlight-title">BERT</span>a and Attention-based BiLSTM for Interpretable Sentiment Analysis
  of Tweets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00297v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00297v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Abrar Jahin, Md Sakib Hossain Shovon, M. F. Mridha, Md Rashedul Islam, Yutaka Watanobe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sentiment analysis is crucial for understanding public opinion and consumer
behavior. Existing models face challenges with linguistic diversity,
generalizability, and explainability. We propose TRABSA, a hybrid framework
integrating transformer-based architectures, attention mechanisms, and BiLSTM
networks to address this. Leveraging RoBERTa-trained on 124M tweets, we bridge
gaps in sentiment analysis benchmarks, ensuring state-of-the-art accuracy.
Augmenting datasets with tweets from 32 countries and US states, we compare six
word-embedding techniques and three lexicon-based labeling techniques,
selecting the best for optimal sentiment analysis. TRABSA outperforms
traditional ML and deep learning models with 94% accuracy and significant
precision, recall, and F1-score gains. Evaluation across diverse datasets
demonstrates consistent superiority and generalizability. SHAP and LIME
analyses enhance interpretability, improving confidence in predictions. Our
study facilitates pandemic resource management, aiding resource planning,
policy formation, and vaccination tactics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ User-LLM: Efficient LLM Contextualization with User Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13598v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13598v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin Ning, Luyang Liu, Jiaxing Wu, Neo Wu, Devora Berlowitz, Sushant Prakash, Bradley Green, Shawn O'Banion, Jun Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have achieved remarkable success across various
domains, but effectively incorporating complex and potentially noisy user
timeline data into LLMs remains a challenge. Current approaches often involve
translating user timelines into text descriptions before feeding them to LLMs,
which can be inefficient and may not fully capture the nuances of user
behavior. Inspired by how LLMs are effectively integrated with images through
direct embeddings, we propose User-LLM, a novel framework that leverages user
embeddings to directly contextualize LLMs with user history interactions. These
embeddings, generated by a user encoder pretrained using self-supervised
learning on diverse user interactions, capture latent user behaviors and
interests as well as their evolution over time. We integrate these user
embeddings with LLMs through cross-attention, enabling LLMs to dynamically
adapt their responses based on the context of a user's past actions and
preferences.
  Our approach achieves significant efficiency gains by representing user
timelines directly as embeddings, leading to substantial inference speedups of
up to 78.1X. Comprehensive experiments on MovieLens, Amazon Review, and Google
Local Review datasets demonstrate that User-LLM outperforms text-prompt-based
contextualization on tasks requiring deep user understanding, with improvements
of up to 16.33%, particularly excelling on long sequences that capture subtle
shifts in user behavior. Furthermore, the incorporation of Perceiver layers
streamlines the integration between user encoders and LLMs, yielding additional
computational savings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Using Natural Language Explanations to Rescale Human Judgments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14770v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14770v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manya Wadhwa, Jifan Chen, Junyi Jessy Li, Greg Durrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of large language models (LLMs) has brought a critical need for
high-quality human-labeled data, particularly for processes like human feedback
and evaluation. A common practice is to label data via consensus annotation
over human judgments. However, annotators' judgments for subjective tasks can
differ in many ways: they may reflect different qualitative judgments about an
example, and they may be mapped to a labeling scheme in different ways. We show
that these nuances can be captured by natural language explanations, and
propose a method to rescale ordinal annotations and explanations using LLMs.
Specifically, we feed annotators' Likert ratings and corresponding explanations
into an LLM and prompt it to produce a numeric score anchored in a scoring
rubric. These scores should reflect the annotators' underlying assessments of
the example. The rubric can be designed or modified after annotation, and
include distinctions that may not have been known when the original error
taxonomy was devised. We explore our technique in the context of rating system
outputs for a document-grounded question answering task, where LLMs achieve
near-human performance. Our method rescales the raw judgments without impacting
agreement and brings the scores closer to human judgments grounded in the same
scoring rubric.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Data available at
  https://github.com/ManyaWadhwa/explanation_based_rescaling</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bi-Directional <span class="highlight-title">Transformer</span>s vs. word2vec: Discovering Vulnerabilities in
  Lifted Compiled Code 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20611v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20611v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gary A. McCully, John D. Hastings, Shengjie Xu, Adam Fortier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting vulnerabilities within compiled binaries is challenging due to lost
high-level code structures and other factors such as architectural
dependencies, compilers, and optimization options. To address these obstacles,
this research explores vulnerability detection using natural language
processing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learn
semantics from intermediate representation (LLVM IR) code. Long short-term
memory (LSTM) neural networks were trained on embeddings from encoders created
using approximately 48k LLVM functions from the Juliet dataset. This study is
pioneering in its comparison of word2vec models with multiple bidirectional
transformer (BERT, RoBERTa) embeddings built using LLVM code to train neural
networks to detect vulnerabilities in compiled binaries. word2vec Skip-Gram
models achieved 92% validation accuracy in detecting vulnerabilities,
outperforming word2vec Continuous Bag of Words (CBOW), BERT, and RoBERTa. This
suggests that complex contextual embeddings may not provide advantages over
simpler word2vec models for this task when a limited number (e.g. 48K) of data
samples are used to train the bidirectional transformer-based models. The
comparative results provide novel insights into selecting optimal embeddings
for learning compiler-independent semantic code representations to advance
machine learning detection of vulnerabilities in compiled binaries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated with improvements"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simran Kaur, Simon Park, Anirudh Goyal, Sanjeev Arora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Instruct-SkillMix, an automated approach for creating diverse,
high quality SFT data. The Instruct-SkillMix pipeline involves two stages, each
leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to
extract core "skills" for instruction-following, either from existing datasets,
or by directly prompting the model; (2) Data generation: uses the powerful LLM
to generate (instruction, response) data that exhibit a randomly chosen pair of
these skills. Here, the use of random skill combinations promotes diversity and
difficulty.
  Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from
Instruct-SkillMix leads to strong gains on instruction following benchmarks
such as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples,
LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.
To our knowledge, this achieves state-of-the-art performance among all models
that have only undergone SFT (no RL methods) and competes with proprietary
models such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.
  Ablation studies also suggest plausible reasons for why creating open
instruction-tuning datasets via naive crowd-sourcing has proved difficult.
Introducing low quality answers ("shirkers") in $20\%$ of Instruct-SkillMix
examples causes performance to plummet, sometimes catastrophically.
  The Instruct-SkillMix pipeline is flexible and is adaptable to other
settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Balancing Rigor and Utility: Mitigating Cognitive Biases in Large
  Language Models for Multiple-Choice Questions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10999v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10999v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liman Wang, Hanyang Zhong, Wenting Cao, Zeyuan Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper examines the role of cognitive biases in the decision-making
processes of large language models (LLMs), challenging the conventional goal of
eliminating all biases. We show that certain cognitive biases when properly
balanced, can enhance decision-making efficiency through rational deviations
and heuristic shortcuts. By introducing heuristic moderation and an abstention
option, which allows LLMs to withhold responses when uncertain, we reduce error
rates, improve decision accuracy, and optimize decision rates. Using the
Balance Rigor and Utility (BRU) dataset, developed through expert
collaboration, our findings demonstrate that targeted inspection of cognitive
biases aligns LLM decisions more closely with human reasoning, enhancing
reliability and suggesting strategies for future improvements. This approach
offers a novel way to leverage cognitive biases to improve the practical
utility of LLMs across various applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This article is currently under review. All data will be open on
  GitHub once the review is complete.
  https://github.com/limanwang/Balancing-Rigor-and-Utility</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ X-InstructBLIP: A Framework for aligning X-Modal instruction-aware
  representations to LLMs and Emergent Cross-modal Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.18799v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.18799v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artemis Panagopoulou, Le Xue, Ning Yu, Junnan Li, Dongxu Li, Shafiq Joty, Ran Xu, Silvio Savarese, Caiming Xiong, Juan Carlos Niebles
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent research has achieved significant advancements in visual reasoning
tasks through learning image-to-language projections and leveraging the
impressive reasoning abilities of Large Language Models (LLMs). This paper
introduces an efficient and effective framework that integrates multiple
modalities (images, 3D, audio and video) to a frozen LLM and demonstrates an
emergent ability for cross-modal reasoning (2+ modality inputs). Our approach
explores two distinct projection mechanisms: Q-Formers and Linear Projections
(LPs). Through extensive experimentation across all four modalities on 16
benchmarks, we explore both methods and assess their adaptability in integrated
and separate cross-modal reasoning. The Q-Former projection demonstrates
superior performance in single modality scenarios and adaptability in joint
versus discriminative reasoning involving two or more modalities. However, it
exhibits lower generalization capabilities than linear projection in contexts
where task-modality data are limited. To enable this framework, we devise a
scalable pipeline that automatically generates high-quality, instruction-tuning
datasets from readily available captioning data across different modalities,
and contribute 24K QA data for audio and 250K QA data for 3D. To facilitate
further research in cross-modal reasoning, we introduce the DisCRn
(Discriminative Cross-modal Reasoning) benchmark comprising 9K audio-video QA
samples and 28K image-3D QA samples that require the model to reason
discriminatively across disparate input modalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal
  Conversational Aspect-based Sentiment Analysis <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09481v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09481v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Luo, Hao Fei, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While existing Aspect-based Sentiment Analysis (ABSA) has received extensive
effort and advancement, there are still gaps in defining a more holistic
research target seamlessly integrating multimodality, conversation context,
fine-granularity, and also covering the changing sentiment dynamics as well as
cognitive causal rationales. This paper bridges the gaps by introducing a
multimodal conversational ABSA, where two novel subtasks are proposed: 1)
Panoptic Sentiment Sextuple Extraction, panoramically recognizing holder,
target, aspect, opinion, sentiment, rationale from multi-turn multi-party
multimodal dialogue. 2) Sentiment Flipping Analysis, detecting the dynamic
sentiment transformation throughout the conversation with the causal reasons.
To benchmark the tasks, we construct PanoSent, a dataset annotated both
manually and automatically, featuring high quality, large scale, multimodality,
multilingualism, multi-scenarios, and covering both implicit and explicit
sentiment elements. To effectively address the tasks, we devise a novel
Chain-of-Sentiment reasoning framework, together with a novel multimodal large
language model (namely Sentica) and a paraphrase-based verification mechanism.
Extensive evaluations demonstrate the superiority of our methods over strong
baselines, validating the efficacy of all our proposed methods. The work is
expected to open up a new era for the ABSA community, and thus all our codes
and data are open at https://PanoSent.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM MM 2024 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LoQT: Low-Rank Adapters for Quantized <span class="highlight-title">Pre-Train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16528v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16528v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Loeschcke, Mads Toftrup, Michael J. Kastoryano, Serge Belongie, Vésteinn Snæbjarnarson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training of large neural networks requires significant computational
resources. Despite advances using low-rank adapters and quantization,
pretraining of models such as LLMs on consumer hardware has not been possible
without model sharding, offloading during training, or per-layer gradient
updates. To address these limitations, we propose LoQT, a method for
efficiently training quantized models. LoQT uses gradient-based tensor
factorization to initialize low-rank trainable weight matrices that are
periodically merged into quantized full-rank weight matrices. Our approach is
suitable for both pretraining and fine-tuning of models, which we demonstrate
experimentally for language modeling and downstream task adaptation. We find
that LoQT enables efficient training of models up to 7B parameters on a
consumer-grade 24GB GPU. We also demonstrate the feasibility of training a 13B
parameter model using per-layer gradient updates on the same hardware.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Empirical Study on Information Extraction using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00369v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00369v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ridong Han, Chaohao Yang, Tao Peng, Prayag Tiwari, Xiang Wan, Lu Liu, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human-like large language models (LLMs), especially the most powerful and
popular ones in OpenAI's GPT family, have proven to be very helpful for many
natural language processing (NLP) related tasks. Therefore, various attempts
have been made to apply LLMs to information extraction (IE), which is a
fundamental NLP task that involves extracting information from unstructured
plain text. To demonstrate the latest representative progress in LLMs'
information extraction ability, we assess the information extraction ability of
GPT-4 (the latest version of GPT at the time of writing this paper) from four
perspectives: Performance, Evaluation Criteria, Robustness, and Error Types.
Our results suggest a visible performance gap between GPT-4 and
state-of-the-art (SOTA) IE methods. To alleviate this problem, considering the
LLMs' human-like characteristics, we propose and analyze the effects of a
series of simple prompt-based methods, which can be generalized to other LLMs
and NLP tasks. Rich experiments show our methods' effectiveness and some of
their remaining issues in improving GPT-4's information extraction ability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This submission was intended instead as the replacement of
  arXiv:2305.14450 , where it now appears as arXiv:2305.14450v2</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Factuality in Large Language Models via Decoding-Time
  Hallucinatory and Truthful Comparators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.12325v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.12325v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dingkang Yang, Dongling Xiao, Jinjie Wei, Mingcheng Li, Zhaoyu Chen, Ke Li, Lihua Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their remarkable capabilities, Large Language Models (LLMs) are prone
to generate responses that contradict verifiable facts, i.e., unfaithful
hallucination content. Existing efforts generally focus on optimizing model
parameters or editing semantic representations, which compromise the internal
factual knowledge of target LLMs. In addition, hallucinations typically exhibit
multifaceted patterns in downstream tasks, limiting the model's holistic
performance across tasks. In this paper, we propose a Comparator-driven
Decoding-Time (CDT) framework to alleviate the response hallucination. Firstly,
we construct hallucinatory and truthful comparators with multi-task fine-tuning
samples. In this case, we present an instruction prototype-guided mixture of
experts strategy to enhance the ability of the corresponding comparators to
capture different hallucination or truthfulness patterns in distinct task
instructions. CDT constrains next-token predictions to factuality-robust
distributions by contrasting the logit differences between the target LLMs and
these comparators. Systematic experiments on multiple downstream tasks show
that our framework can significantly improve the model performance and response
factuality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Hallucination Mitigation in LLMs</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.11944v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.11944v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ge Zhang, Xinrun Du, Bei Chen, Yiming Liang, Tongxu Luo, Tianyu Zheng, Kang Zhu, Yuyang Cheng, Chunpu Xu, Shuyue Guo, Haoran Zhang, Xingwei Qu, Junjie Wang, Ruibin Yuan, Yizhi Li, Zekun Wang, Yudong Liu, Yu-Hsuan Tsai, Fengji Zhang, Chenghua Lin, Wenhao Huang, Jie Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the capabilities of large multimodal models (LMMs) continue to advance,
evaluating the performance of LMMs emerges as an increasing need. Additionally,
there is an even larger gap in evaluating the advanced knowledge and reasoning
abilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,
a new Chinese Massive Multi-discipline Multimodal Understanding benchmark
designed to evaluate LMMs on tasks demanding college-level subject knowledge
and deliberate reasoning in a Chinese context. CMMMU is inspired by and
strictly follows the annotation and analysis pattern of MMMU. CMMMU includes
12k manually collected multimodal questions from college exams, quizzes, and
textbooks, covering six core disciplines: Art & Design, Business, Science,
Health & Medicine, Humanities & Social Science, and Tech & Engineering, like
its companion, MMMU. These questions span 30 subjects and comprise 39 highly
heterogeneous image types, such as charts, diagrams, maps, tables, music
sheets, and chemical structures. CMMMU focuses on complex perception and
reasoning with domain-specific knowledge in the Chinese context. We evaluate 11
open-source LLMs and one proprietary GPT-4V(ision). Even GPT-4V only achieves
accuracies of 42%, indicating a large space for improvement. CMMMU will boost
the community to build the next-generation LMMs towards expert artificial
intelligence and promote the democratization of LMMs by providing diverse
language contexts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AnyMatch -- Efficient Zero-Shot Entity Matching with a Small Language
  Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04073v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04073v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyu Zhang, Paul Groth, Iacer Calixto, Sebastian Schelter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity matching (EM) is the problem of determining whether two records refer
to same real-world entity, which is crucial in data integration, e.g., for
product catalogs or address databases. A major drawback of many EM approaches
is their dependence on labelled examples. We thus focus on the challenging
setting of zero-shot entity matching where no labelled examples are available
for an unseen target dataset. Recently, large language models (LLMs) have shown
promising results for zero-shot EM, but their low throughput and high
deployment cost limit their applicability and scalability.
  We revisit the zero-shot EM problem with AnyMatch, a small language model
fine-tuned in a transfer learning setup. We propose several novel data
selection techniques to generate fine-tuning data for our model, e.g., by
selecting difficult pairs to match via an AutoML filter, by generating
additional attribute-level examples, and by controlling label imbalance in the
data.
  We conduct an extensive evaluation of the prediction quality and deployment
cost of our model, in a comparison to thirteen baselines on nine benchmark
datasets. We find that AnyMatch provides competitive prediction quality despite
its small parameter size: it achieves the second-highest F1 score overall, and
outperforms several other approaches that employ models with hundreds of
billions of parameters. Furthermore, our approach exhibits major cost benefits:
the average prediction quality of AnyMatch is within 4.4% of the
state-of-the-art method MatchGPT with the proprietary trillion-parameter model
GPT-4, yet AnyMatch requires four orders of magnitude less parameters and
incurs a 3,899 times lower inference cost (in dollars per 1,000 tokens).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages excluding references, 3 figures, and 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RAGLAB: A Modular and Research-Oriented Unified Framework for
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11381v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11381v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanwang Zhang, Yunze Song, Yidong Wang, Shuyun Tang, Xinfeng Li, Zhengran Zeng, Zhen Wu, Wei Ye, Wenyuan Xu, Yue Zhang, Xinyu Dai, Shikun Zhang, Qingsong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) demonstrate human-level capabilities in
dialogue, reasoning, and knowledge retention. However, even the most advanced
LLMs face challenges such as hallucinations and real-time updating of their
knowledge. Current research addresses this bottleneck by equipping LLMs with
external knowledge, a technique known as Retrieval Augmented Generation (RAG).
However, two key issues constrained the development of RAG. First, there is a
growing lack of comprehensive and fair comparisons between novel RAG
algorithms. Second, open-source tools such as LlamaIndex and LangChain employ
high-level abstractions, which results in a lack of transparency and limits the
ability to develop novel algorithms and evaluation metrics. To close this gap,
we introduce RAGLAB, a modular and research-oriented open-source library.
RAGLAB reproduces 6 existing algorithms and provides a comprehensive ecosystem
for investigating RAG algorithms. Leveraging RAGLAB, we conduct a fair
comparison of 6 RAG algorithms across 10 benchmarks. With RAGLAB, researchers
can efficiently compare the performance of various algorithms and develop novel
algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03753v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03753v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuntian Deng, Wenting Zhao, Jack Hessel, Xiang Ren, Claire Cardie, Yejin Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing availability of real-world conversation data offers exciting
opportunities for researchers to study user-chatbot interactions. However, the
sheer volume of this data makes manually examining individual conversations
impractical. To overcome this challenge, we introduce WildVis, an interactive
tool that enables fast, versatile, and large-scale conversation analysis.
WildVis provides search and visualization capabilities in the text and
embedding spaces based on a list of criteria. To manage million-scale datasets,
we implemented optimizations including search index construction, embedding
precomputation and compression, and caching to ensure responsive user
interactions within seconds. We demonstrate WildVis' utility through three case
studies: facilitating chatbot misuse research, visualizing and comparing topic
distributions across datasets, and characterizing user-specific conversation
patterns. WildVis is open-source and designed to be extendable, supporting
additional datasets and customized search and visualization functionalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards a Unified View of Preference Learning for Large Language Models:
  A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02795v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02795v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bofei Gao, Feifan Song, Yibo Miao, Zefan Cai, Zhe Yang, Liang Chen, Helan Hu, Runxin Xu, Qingxiu Dong, Ce Zheng, Wen Xiao, Ge Zhang, Daoguang Zan, Keming Lu, Bowen Yu, Dayiheng Liu, Zeyu Cui, Jian Yang, Lei Sha, Houfeng Wang, Zhifang Sui, Peiyi Wang, Tianyu Liu, Baobao Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of
the crucial factors to achieve success is aligning the LLM's output with human
preferences. This alignment process often requires only a small amount of data
to efficiently enhance the LLM's performance. While effective, research in this
area spans multiple domains, and the methods involved are relatively complex to
understand. The relationships between different methods have been
under-explored, limiting the development of the preference alignment. In light
of this, we break down the existing popular alignment strategies into different
components and provide a unified framework to study the current alignment
strategies, thereby establishing connections among them. In this survey, we
decompose all the strategies in preference learning into four components:
model, data, feedback, and algorithm. This unified view offers an in-depth
understanding of existing alignment algorithms and also opens up possibilities
to synergize the strengths of different strategies. Furthermore, we present
detailed working examples of prevalent existing algorithms to facilitate a
comprehensive understanding for the readers. Finally, based on our unified
perspective, we explore the challenges and future research directions for
aligning large language models with human preferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15297v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15297v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanru Zhou, Anshul Kashyap, Steve Li, Ayati Sharma, Brittany Morin, David Baquirin, Jet Vonk, Zoe Ezzes, Zachary Miller, Maria Luisa Gorno Tempini, Jiachen Lian, Gopala Krishna Anumanchipalli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dysfluent speech detection is the bottleneck for disordered speech analysis
and spoken language learning. Current state-of-the-art models are governed by
rule-based systems which lack efficiency and robustness, and are sensitive to
template design. In this paper, we propose YOLO-Stutter: a first end-to-end
method that detects dysfluencies in a time-accurate manner. YOLO-Stutter takes
imperfect speech-text alignment as input, followed by a spatial feature
aggregator, and a temporal dependency extractor to perform region-wise boundary
and class predictions. We also introduce two dysfluency corpus, VCTK-Stutter
and VCTK-TTS, that simulate natural spoken dysfluencies including repetition,
block, missing, replacement, and prolongation. Our end-to-end method achieves
state-of-the-art performance with a minimum number of trainable parameters for
on both simulated data and real aphasia speech. Code and datasets are
open-sourced at https://github.com/rorizzz/YOLO-Stutter
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Interspeech 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Natural Language Processing RELIES on Linguistics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.05966v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.05966v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juri Opitz, Shira Wein, Nathan Schneider
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have become capable of generating highly fluent
text in certain languages, without modules specially designed to capture
grammar or semantic coherence. What does this mean for the future of linguistic
expertise in NLP? We highlight several aspects in which NLP (still) relies on
linguistics, or where linguistic thinking can illuminate new directions. We
argue our case around the acronym RELIES that encapsulates six major facets
where linguistics contributes to NLP: Resources, Evaluation, Low-resource
settings, Interpretability, Explanation, and the Study of language. This list
is not exhaustive, nor is linguistics the main point of reference for every
effort under these themes; but at a macro level, these facets highlight the
enduring importance of studying machine systems vis-\`a-vis systems of human
language.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CL4KGE: A Curriculum Learning Method for Knowledge Graph Embedding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14840v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14840v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Liu, Chuan Zhou, Peng Zhang, Yanan Cao, Yongchao Liu, Zhao Li, Hongyang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge graph embedding (KGE) constitutes a foundational task, directed
towards learning representations for entities and relations within knowledge
graphs (KGs), with the objective of crafting representations comprehensive
enough to approximate the logical and symbolic interconnections among entities.
In this paper, we define a metric Z-counts to measure the difficulty of
training each triple ($<$head entity, relation, tail entity$>$) in KGs with
theoretical analysis. Based on this metric, we propose \textbf{CL4KGE}, an
efficient \textbf{C}urriculum \textbf{L}earning based training strategy for
\textbf{KGE}. This method includes a difficulty measurer and a training
scheduler that aids in the training of KGE models. Our approach possesses the
flexibility to act as a plugin within a wide range of KGE models, with the
added advantage of adaptability to the majority of KGs in existence. The
proposed method has been evaluated on popular KGE models, and the results
demonstrate that it enhances the state-of-the-art methods. The use of Z-counts
as a metric has enabled the identification of challenging triples in KGs, which
helps in devising effective training strategies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14482v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14482v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Xu, Wei Ping, Xianchao Wu, Chejian Xu, Zihan Liu, Mohammad Shoeybi, Bryan Catanzaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K
context window, designed to bridge the gap between open-source LLMs and leading
proprietary models (e.g., GPT-4-Turbo) in long-context understanding and
retrieval-augmented generation (RAG) capabilities. These two capabilities are
essential for LLMs to process large volumes of information that cannot fit into
a single prompt and are complementary to each other, depending on the
downstream tasks and computational budgets. We present a detailed continued
training recipe to extend the context window of Llama3-70B-base from 8K to 128K
tokens, along with a three-stage instruction tuning process to enhance the
model's instruction-following, RAG performance, and long-context understanding
capabilities. Our results demonstrate that the Llama3-ChatQA-2-70B model
outperforms most existing state-of-the-art models, including
GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and Llama3.1-70B-Instruct, on
ultra-long tasks beyond 100K tokens, as well as on the RAG benchmark using only
a 4K context window, showing the strong long context capability across varying
sequence lengths. We further provide extensive comparisons between direct
long-context and RAG solutions using the same state-of-the-art long-context
LLMs. Interestingly, we find that the performance of strong long-context LLMs
using RAG improves when retrieving a larger number of chunks. With a large set
of top-k chunks, RAG consistently outperforms direct long-context solution
using the same state-of-the-art long-context models (e.g., Llama3-ChatQA-2-70B
and Qwen2-72B-Instruct) on both 32K benchmarks and real-world 128K tasks. To
advance research in this field, we open-sourced the model weights, training
data, and the evaluation setup for the for the community:
https://chatqa2-project.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: major update with significantly improved results</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A <span class="highlight-title">Survey</span> on Employing Large Language Models for Text-to-SQL Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15186v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15186v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Shi, Zhengju Tang, Nan Zhang, Xiaotong Zhang, Zhi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing volume of data stored in relational databases has led to the
need for efficient querying and utilization of this data in various sectors.
However, writing SQL queries requires specialized knowledge, which poses a
challenge for non-professional users trying to access and query databases.
Text-to-SQL parsing solves this issue by converting natural language queries
into SQL queries, thus making database access more accessible for non-expert
users. To take advantage of the recent developments in Large Language Models
(LLMs), a range of new methods have emerged, with a primary focus on prompt
engineering and fine-tuning. This survey provides a comprehensive overview of
LLMs in text-to-SQL tasks, discussing benchmark datasets, prompt engineering,
fine-tuning methods, and future research directions. We hope this review will
enable readers to gain a broader understanding of the recent advances in this
field and offer some insights into its future trajectory.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Aspect-Based Sentiment Analysis through Deep Learning Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03259v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03259v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Li, Huidong Tang, Jinli Zhang, Xiujing Guo, Debo Cheng, Yasuhiko Morimoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aspect-based sentiment analysis predicts sentiment polarity with fine
granularity. While graph convolutional networks (GCNs) are widely utilized for
sentimental feature extraction, their naive application for syntactic feature
extraction can compromise information preservation. This study introduces an
innovative edge-enhanced GCN, named SentiSys, to navigate the syntactic graph
while preserving intact feature information, leading to enhanced performance.
Specifically,we first integrate a bidirectional long short-term memory
(Bi-LSTM) network and a self-attention-based transformer. This combination
facilitates effective text encoding, preventing the loss of information and
predicting long dependency text. A bidirectional GCN (Bi-GCN) with message
passing is then employed to encode relationships between entities.
Additionally, unnecessary information is filtered out using an aspect-specific
masking technique. To validate the effectiveness of our proposed model, we
conduct extensive evaluation experiments on four benchmark datasets. The
experimental results demonstrate enhanced performance in aspect-based sentiment
analysis with the use of SentiSys.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has already been accepted by the 20th International
  Conference on Advanced Data Mining and Applications (ADMA2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Disentangling Length from Quality in Direct Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19159v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19159v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan Park, Rafael Rafailov, Stefano Ermon, Chelsea Finn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning from Human Feedback (RLHF) has been a crucial
component in the recent success of Large Language Models. However, RLHF is know
to exploit biases in human preferences, such as verbosity. A well-formatted and
eloquent answer is often more highly rated by users, even when it is less
helpful and objective. A number of approaches have been developed to control
those biases in the classical RLHF literature, but the problem remains
relatively under-explored for Direct Alignment Algorithms such as Direct
Preference Optimization (DPO). Unlike classical RLHF, DPO does not train a
separate reward model or use reinforcement learning directly, so previous
approaches developed to control verbosity cannot be directly applied to this
setting. Our work makes several contributions. For the first time, we study the
length problem in the DPO setting, showing significant exploitation in DPO and
linking it to out-of-distribution bootstrapping. We then develop a principled
but simple regularization strategy that prevents length exploitation, while
still maintaining improvements in model quality. We demonstrate these effects
across datasets on summarization and dialogue, where we achieve up to 20\%
improvement in win rates when controlling for length, despite the GPT4 judge's
well-known verbosity bias.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop
  Questions <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.14795v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.14795v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zexuan Zhong, Zhengxuan Wu, Christopher D. Manning, Christopher Potts, Danqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The information stored in large language models (LLMs) falls out of date
quickly, and retraining from scratch is often not an option. This has recently
given rise to a range of techniques for injecting new facts through updating
model weights. Current evaluation paradigms are extremely limited, mainly
validating the recall of edited facts, but changing one fact should cause
rippling changes to the model's related beliefs. If we edit the UK Prime
Minister to now be Rishi Sunak, then we should get a different answer to Who is
married to the British Prime Minister? In this work, we present a benchmark,
MQuAKE (Multi-hop Question Answering for Knowledge Editing), comprising
multi-hop questions that assess whether edited models correctly answer
questions where the answer should change as an entailed consequence of edited
facts. While we find that current knowledge-editing approaches can recall
edited facts accurately, they fail catastrophically on the constructed
multi-hop questions. We thus propose a simple memory-based approach, MeLLo,
which stores all edited facts externally while prompting the language model
iteratively to generate answers that are consistent with the edited facts.
While MQuAKE remains challenging, we show that MeLLo scales well with LLMs
(e.g., OpenAI GPT-3.5-turbo) and outperforms previous model editors by a large
margin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2023. Our code and datasets are available at
  https://github.com/princeton-nlp/MQuAKE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shared Latent Space by Both Languages in Non-Autoregressive Neural
  Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.03511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.03511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        DongNyeong Heo, Heeyoul Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Non-autoregressive neural machine translation (NAT) offers substantial
translation speed up compared to autoregressive neural machine translation (AT)
at the cost of translation quality. Latent variable modeling has emerged as a
promising approach to bridge this quality gap, particularly for addressing the
chronic multimodality problem in NAT. In the previous works that used latent
variable modeling, they added an auxiliary model to estimate the posterior
distribution of the latent variable conditioned on the source and target
sentences. However, it causes several disadvantages, such as redundant
information extraction in the latent variable, increasing the number of
parameters, and a tendency to ignore some information from the inputs. In this
paper, we propose a novel latent variable modeling that integrates a dual
reconstruction perspective and an advanced hierarchical latent modeling with a
shared intermediate latent space across languages. This latent variable
modeling hypothetically alleviates or prevents the above disadvantages. In our
experiment results, we present comprehensive demonstrations that our proposed
approach infers superior latent variables which lead better translation
quality. Finally, in the benchmark translation tasks, such as WMT, we
demonstrate that our proposed method significantly improves translation quality
compared to previous NAT baselines including the state-of-the-art NAT model.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">16</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for
  Safe Navigation Under Perception Uncertainty 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06111v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06111v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Pohland, Claire Tomlin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Perception-based navigation systems are useful for unmanned ground vehicle
(UGV) navigation in complex terrains, where traditional depth-based navigation
schemes are insufficient. However, these data-driven methods are highly
dependent on their training data and can fail in surprising and dramatic ways
with little warning. To ensure the safety of the vehicle and the surrounding
environment, it is imperative that the navigation system is able to recognize
the predictive uncertainty of the perception model and respond safely and
effectively in the face of uncertainty. In an effort to enable safe navigation
under perception uncertainty, we develop a probabilistic and
reconstruction-based competency estimation (PaRCE) method to estimate the
model's level of familiarity with an input image as a whole and with specific
regions in the image. We find that the overall competency score can correctly
predict correctly classified, misclassified, and out-of-distribution (OOD)
samples. We also confirm that the regional competency maps can accurately
distinguish between familiar and unfamiliar regions across images. We then use
this competency information to develop a planning and control scheme that
enables effective navigation while maintaining a low probability of error. We
find that the competency-aware scheme greatly reduces the number of collisions
with unfamiliar obstacles, compared to a baseline controller with no competency
awareness. Furthermore, the regional competency information is very valuable in
enabling efficient navigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SGC-VQGAN: Towards Complex Scene Representation via Semantic Guided
  Clustering Codebook 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06105v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06105v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenjing Ding, Chiyu Wang, Boshi Liu, Xi Guo, Weixuan Tang, Wei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vector quantization (VQ) is a method for deterministically learning features
through discrete codebook representations. Recent works have utilized visual
tokenizers to discretize visual regions for self-supervised representation
learning. However, a notable limitation of these tokenizers is lack of
semantics, as they are derived solely from the pretext task of reconstructing
raw image pixels in an auto-encoder paradigm. Additionally, issues like
imbalanced codebook distribution and codebook collapse can adversely impact
performance due to inefficient codebook utilization. To address these
challenges, We introduce SGC-VQGAN through Semantic Online Clustering method to
enhance token semantics through Consistent Semantic Learning. Utilizing
inference results from segmentation model , our approach constructs a
temporospatially consistent semantic codebook, addressing issues of codebook
collapse and imbalanced token semantics. Our proposed Pyramid Feature Learning
pipeline integrates multi-level features to capture both image details and
semantics simultaneously. As a result, SGC-VQGAN achieves SOTA performance in
both reconstruction quality and various downstream tasks. Its simplicity,
requiring no additional parameter learning, enables its direct application in
downstream tasks, presenting significant potential.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LSE-NeRF: Learning Sensor Modeling Errors for Deblured Neural Radiance
  Fields with RGB-Event Stereo 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06104v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06104v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Zhi Tang, Daniel Rebain, Kostantinos G. Derpanis, Kwang Moo Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a method for reconstructing a clear Neural Radiance Field (NeRF)
even with fast camera motions. To address blur artifacts, we leverage both
(blurry) RGB images and event camera data captured in a binocular
configuration. Importantly, when reconstructing our clear NeRF, we consider the
camera modeling imperfections that arise from the simple pinhole camera model
as learned embeddings for each camera measurement, and further learn a mapper
that connects event camera measurements with RGB data. As no previous dataset
exists for our binocular setting, we introduce an event camera dataset with
captures from a 3D-printed stereo configuration between RGB and event cameras.
Empirically, we evaluate our introduced dataset and EVIMOv2 and show that our
method leads to improved reconstructions. Our code and dataset are available at
https://github.com/ubc-vision/LSENeRF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SVS-GAN: Leveraging GANs for Semantic Video Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06074v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06074v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khaled M. Seyam, Julian Wiederer, Markus Braun, Bin Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, there has been a growing interest in Semantic Image
Synthesis (SIS) through the use of Generative Adversarial Networks (GANs) and
diffusion models. This field has seen innovations such as the implementation of
specialized loss functions tailored for this task, diverging from the more
general approaches in Image-to-Image (I2I) translation. While the concept of
Semantic Video Synthesis (SVS)$\unicode{x2013}$the generation of temporally
coherent, realistic sequences of images from semantic maps$\unicode{x2013}$is
newly formalized in this paper, some existing methods have already explored
aspects of this field. Most of these approaches rely on generic loss functions
designed for video-to-video translation or require additional data to achieve
temporal coherence. In this paper, we introduce the SVS-GAN, a framework
specifically designed for SVS, featuring a custom architecture and loss
functions. Our approach includes a triple-pyramid generator that utilizes SPADE
blocks. Additionally, we employ a U-Net-based network for the image
discriminator, which performs semantic segmentation for the OASIS loss. Through
this combination of tailored architecture and objective engineering, our
framework aims to bridge the existing gap between SIS and SVS, outperforming
current state-of-the-art models on datasets like Cityscapes and KITTI-360.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffusionPen: Towards Controlling the Style of Handwritten Text
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantina Nikolaidou, George Retsinas, Giorgos Sfikas, Marcus Liwicki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Handwritten Text Generation (HTG) conditioned on text and style is a
challenging task due to the variability of inter-user characteristics and the
unlimited combinations of characters that form new words unseen during
training. Diffusion Models have recently shown promising results in HTG but
still remain under-explored. We present DiffusionPen (DiffPen), a 5-shot style
handwritten text generation approach based on Latent Diffusion Models. By
utilizing a hybrid style extractor that combines metric learning and
classification, our approach manages to capture both textual and stylistic
characteristics of seen and unseen words and styles, generating realistic
handwritten samples. Moreover, we explore several variation strategies of the
data with multi-style mixtures and noisy embeddings, enhancing the robustness
and diversity of the generated data. Extensive experiments using IAM offline
handwriting database show that our method outperforms existing methods
qualitatively and quantitatively, and its additional generated data can improve
the performance of Handwriting Text Recognition (HTR) systems. The code is
available at: https://github.com/koninik/DiffusionPen.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Online 3D reconstruction and dense tracking in endoscopic videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michel Hayoz, Christopher Hahne, Thomas Kurmann, Max Allan, Guido Beldi, Daniel Candinas, ablo Márquez-Neila, Raphael Sznitman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  3D scene reconstruction from stereo endoscopic video data is crucial for
advancing surgical interventions. In this work, we present an online framework
for online, dense 3D scene reconstruction and tracking, aimed at enhancing
surgical scene understanding and assisting interventions. Our method
dynamically extends a canonical scene representation using Gaussian splatting,
while modeling tissue deformations through a sparse set of control points. We
introduce an efficient online fitting algorithm that optimizes the scene
parameters, enabling consistent tracking and accurate reconstruction. Through
experiments on the StereoMIS dataset, we demonstrate the effectiveness of our
approach, outperforming state-of-the-art tracking methods and achieving
comparable performance to offline reconstruction techniques. Our work enables
various downstream applications thus contributing to advancing the capabilities
of surgical assistance systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analyzing Tumors by Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06035v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06035v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Chen, Yuxiang Lai, Xiaoxi Chen, Qixin Hu, Alan Yuille, Zongwei Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computer-aided tumor detection has shown great potential in enhancing the
interpretation of over 80 million CT scans performed annually in the United
States. However, challenges arise due to the rarity of CT scans with tumors,
especially early-stage tumors. Developing AI with real tumor data faces issues
of scarcity, annotation difficulty, and low prevalence. Tumor synthesis
addresses these challenges by generating numerous tumor examples in medical
images, aiding AI training for tumor detection and segmentation. Successful
synthesis requires realistic and generalizable synthetic tumors across various
organs. This chapter reviews AI development on real and synthetic data and
summarizes two key trends in synthetic data for cancer imaging research:
modeling-based and learning-based approaches. Modeling-based methods, like
Pixel2Cancer, simulate tumor development over time using generic rules, while
learning-based methods, like DiffTumor, learn from a few annotated examples in
one organ to generate synthetic tumors in others. Reader studies with expert
radiologists show that synthetic tumors can be convincingly realistic. We also
present case studies in the liver, pancreas, and kidneys reveal that AI trained
on synthetic tumors can achieve performance comparable to, or better than, AI
only trained on real data. Tumor synthesis holds significant promise for
expanding datasets, enhancing AI reliability, improving tumor detection
performance, and preserving patient privacy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a chapter in the Springer Book: "Generative Machine
  Learning Models in Medical Image Computing."</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NESI: Shape Representation via Neural Explicit Surface Intersection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06030v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06030v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Congyi Zhang, Jinfan Yang, Eric Hedlin, Suzuran Takikawa, Nicholas Vining, Kwang Moo Yi, Wenping Wang, Alla Sheffer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compressed representations of 3D shapes that are compact, accurate, and can
be processed efficiently directly in compressed form, are extremely useful for
digital media applications. Recent approaches in this space focus on learned
implicit or parametric representations. While implicits are well suited for
tasks such as in-out queries, they lack natural 2D parameterization,
complicating tasks such as texture or normal mapping. Conversely, parametric
representations support the latter tasks but are ill-suited for occupancy
queries. We propose a novel learned alternative to these approaches, based on
intersections of localized explicit, or height-field, surfaces. Since explicits
can be trivially expressed both implicitly and parametrically, NESI directly
supports a wider range of processing operations than implicit alternatives,
including occupancy queries and parametric access. We represent input shapes
using a collection of differently oriented height-field bounded half-spaces
combined using volumetric Boolean intersections. We first tightly bound each
input using a pair of oppositely oriented height-fields, forming a Double
Height-Field (DHF) Hull. We refine this hull by intersecting it with additional
localized height-fields (HFs) that capture surface regions in its interior. We
minimize the number of HFs necessary to accurately capture each input and
compactly encode both the DHF hull and the local HFs as neural functions
defined over subdomains of R^2. This reduced dimensionality encoding delivers
high-quality compact approximations. Given similar parameter count, or storage
capacity, NESI significantly reduces approximation error compared to the state
of the art, especially at lower parameter counts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pioneering Precision in Lumbar Spine MRI Segmentation with Advanced Deep
  Learning and Data Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Istiak Ahmed, Md. Tanzim Hossain, Md. Zahirul Islam Nahid, Kazi Shahriar Sanjid, Md. Shakib Shahariar Junayed, M. Monir Uddin, Mohammad Monirujjaman Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents an advanced approach to lumbar spine segmentation using
deep learning techniques, focusing on addressing key challenges such as class
imbalance and data preprocessing. Magnetic resonance imaging (MRI) scans of
patients with low back pain are meticulously preprocessed to accurately
represent three critical classes: vertebrae, spinal canal, and intervertebral
discs (IVDs). By rectifying class inconsistencies in the data preprocessing
stage, the fidelity of the training data is ensured. The modified U-Net model
incorporates innovative architectural enhancements, including an upsample block
with leaky Rectified Linear Units (ReLU) and Glorot uniform initializer, to
mitigate common issues such as the dying ReLU problem and improve stability
during training. Introducing a custom combined loss function effectively
tackles class imbalance, significantly improving segmentation accuracy.
Evaluation using a comprehensive suite of metrics showcases the superior
performance of this approach, outperforming existing methods and advancing the
current techniques in lumbar spine segmentation. These findings hold
significant advancements for enhanced lumbar spine MRI and segmentation
diagnostic accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improved Visually <span class="highlight-title">Prompt</span>ed Keyword Localisation in Real Low-Resource
  Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leanne Nortje, Dan Oneata, Herman Kamper
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given an image query, visually prompted keyword localisation (VPKL) aims to
find occurrences of the depicted word in a speech collection. This can be
useful when transcriptions are not available for a low-resource language (e.g.
if it is unwritten). Previous work showed that VPKL can be performed with a
visually grounded speech model trained on paired images and unlabelled speech.
But all experiments were done on English. Moreover, transcriptions were used to
get positive and negative pairs for the contrastive loss. This paper introduces
a few-shot learning scheme to mine pairs automatically without transcriptions.
On English, this results in only a small drop in performance. We also - for the
first time - consider VPKL on a real low-resource language, Yoruba. While
scores are reasonable, here we see a bigger drop in performance compared to
using ground truth pairs because the mining is less accurate in Yoruba.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Feedback-guided Data Synthesis for Imbalanced Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.00158v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.00158v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Reyhane Askari Hemmat, Mohammad Pezeshki, Florian Bordes, Michal Drozdzal, Adriana Romero-Soriano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current status quo in machine learning is to use static datasets of real
images for training, which often come from long-tailed distributions. With the
recent advances in generative models, researchers have started augmenting these
static datasets with synthetic data, reporting moderate performance
improvements on classification tasks. We hypothesize that these performance
gains are limited by the lack of feedback from the classifier to the generative
model, which would promote the usefulness of the generated samples to improve
the classifier's performance. In this work, we introduce a framework for
augmenting static datasets with useful synthetic samples, which leverages
one-shot feedback from the classifier to drive the sampling of the generative
model. In order for the framework to be effective, we find that the samples
must be close to the support of the real data of the task at hand, and be
sufficiently diverse. We validate three feedback criteria on a long-tailed
dataset (ImageNet-LT) as well as a group-imbalanced dataset (NICO++). On
ImageNet-LT, we achieve state-of-the-art results, with over 4 percent
improvement on underrepresented classes while being twice efficient in terms of
the number of generated synthetic samples. NICO++ also enjoys marked boosts of
over 5 percent in worst group accuracy. With these results, our framework paves
the path towards effectively leveraging state-of-the-art text-to-image models
as data sources that can be queried to improve downstream applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Out-of-Distribution Detection with Disentangled Foreground and
  Background Features <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.08727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.08727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Choubo Ding, Guansong Pang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting out-of-distribution (OOD) inputs is a principal task for ensuring
the safety of deploying deep-neural-network classifiers in open-set scenarios.
OOD samples can be drawn from arbitrary distributions and exhibit deviations
from in-distribution (ID) data in various dimensions, such as foreground
features (e.g., objects in CIFAR100 images vs. those in CIFAR10 images) and
background features (e.g., textural images vs. objects in CIFAR10). Existing
methods can confound foreground and background features in training, failing to
utilize the background features for OOD detection. This paper considers the
importance of feature disentanglement in out-of-distribution detection and
proposes the simultaneous exploitation of both foreground and background
features to support the detection of OOD inputs in in out-of-distribution
detection. To this end, we propose a novel framework that first disentangles
foreground and background features from ID training samples via a dense
prediction approach, and then learns a new classifier that can evaluate the OOD
scores of test images from both foreground and background features. It is a
generic framework that allows for a seamless combination with various existing
OOD detection methods. Extensive experiments show that our approach 1) can
substantially enhance the performance of four different state-of-the-art (SotA)
OOD detection methods on multiple widely-used OOD datasets with diverse
background features, and 2) achieves new SotA performance on these benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM MM 2024, 9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VideoMambaPro: A Leap Forward for Mamba in Video Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19006v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19006v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Lu, Albert Ali Salah, Ronald Poppe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video understanding requires the extraction of rich spatio-temporal
representations, which transformer models achieve through self-attention.
Unfortunately, self-attention poses a computational burden. In NLP, Mamba has
surfaced as an efficient alternative for transformers. However, Mamba's
successes do not trivially extend to computer vision tasks, including those in
video analysis. In this paper, we theoretically analyze the differences between
self-attention and Mamba. We identify two limitations in Mamba's token
processing: historical decay and element contradiction. We propose
VideoMambaPro (VMP) that solves the identified limitations by adding masked
backward computation and elemental residual connections to a VideoMamba
backbone. VideoMambaPro shows state-of-the-art video action recognition
performance compared to transformer models, and surpasses VideoMamba by clear
margins: 7.9% and 8.1% top-1 on Kinetics-400 and Something-Something V2,
respectively. Our VideoMambaPro-M model achieves 91.9% top-1 on Kinetics-400,
only 0.2% below InternVideo2-6B but with only 1.2% of its parameters. The
combination of high performance and efficiency makes VideoMambaPro an
interesting alternative for transformer models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Model weights are lost due to management error, will re-calculate and
  update the results</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ARTIST: Improving the Generation of Text-rich Images with Disentangled
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12044v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12044v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianyi Zhang, Yufan Zhou, Jiuxiang Gu, Curtis Wigington, Tong Yu, Yiran Chen, Tong Sun, Ruiyi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have demonstrated exceptional capabilities in generating a
broad spectrum of visual content, yet their proficiency in rendering text is
still limited: they often generate inaccurate characters or words that fail to
blend well with the underlying image. To address these shortcomings, we
introduce a new framework named ARTIST. This framework incorporates a dedicated
textual diffusion model to specifically focus on the learning of text
structures. Initially, we pretrain this textual model to capture the
intricacies of text representation. Subsequently, we finetune a visual
diffusion model, enabling it to assimilate textual structure information from
the pretrained textual model. This disentangled architecture design and the
training strategy significantly enhance the text rendering ability of the
diffusion models for text-rich image generation. Additionally, we leverage the
capabilities of pretrained large language models to better interpret user
intentions, contributing to improved generation quality. Empirical results on
the MARIO-Eval benchmark underscore the effectiveness of the proposed method,
showing an improvement of up to 15\% in various metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ XCAT-3.0: A Comprehensive Library of Personalized Digital Twins Derived
  from CT Scans 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.11133v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.11133v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lavsen Dahal, Mobina Ghojoghnejad, Dhrubajyoti Ghosh, Yubraj Bhandari, David Kim, Fong Chi Ho, Fakrul Islam Tushar, Sheng Luoa, Kyle J. Lafata, Ehsan Abadi, Ehsan Samei, Joseph Y. Lo, W. Paul Segars
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Virtual Imaging Trials (VIT) offer a cost-effective and scalable approach for
evaluating medical imaging technologies. Computational phantoms, which mimic
real patient anatomy and physiology, play a central role in VITs. However, the
current libraries of computational phantoms face limitations, particularly in
terms of sample size and diversity. Insufficient representation of the
population hampers accurate assessment of imaging technologies across different
patient groups. Traditionally, the more realistic computational phantoms were
created by manual segmentation, which is a laborious and time-consuming task,
impeding the expansion of phantom libraries. This study presents a framework
for creating realistic computational phantoms using a suite of automatic
segmentation models and performing three forms of automated quality control on
the segmented organ masks. The result is the release of over 2500 new
computational phantoms, so-named XCAT3.0 after the ubiquitous XCAT
computational construct. This new formation embodies 140 structures and
represents a comprehensive approach to detailed anatomical modeling. The
developed computational phantoms are formatted in both voxelized and surface
mesh formats. The framework is combined with an in-house CT scanner simulator
to produce realistic CT images. The framework has the potential to advance
virtual imaging trials, facilitating comprehensive and reliable evaluations of
medical imaging technologies. Phantoms may be requested at
https://cvit.duke.edu/resources/. Code, model weights, and sample CT images are
available at https://xcat-3.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What's Wrong with the Absolute Trajectory Error? <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.05376v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.05376v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seong Hun Lee, Javier Civera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the limitations of the commonly used Absolute Trajectory Error (ATE)
is that it is highly sensitive to outliers. As a result, in the presence of
just a few outliers, it often fails to reflect the varying accuracy as the
inlier trajectory error or the number of outliers varies. In this work, we
propose an alternative error metric for evaluating the accuracy of the
reconstructed camera trajectory. Our metric, named Discernible Trajectory Error
(DTE), is computed in five steps: (1) Shift the ground-truth and estimated
trajectories such that both of their geometric medians are located at the
origin. (2) Rotate the estimated trajectory such that it minimizes the sum of
geodesic distances between the corresponding camera orientations. (3) Scale the
estimated trajectory such that the median distance of the cameras to their
geometric median is the same as that of the ground truth. (4) Compute,
winsorize and normalize the distances between the corresponding cameras. (5)
Obtain the DTE by taking the average of the mean and the root-mean-square (RMS)
of the resulting distances. This metric is an attractive alternative to the
ATE, in that it is capable of discerning the varying trajectory accuracy as the
inlier trajectory error or the number of outliers varies. Using the similar
idea, we also propose a novel rotation error metric, named Discernible Rotation
Error (DRE), which has similar advantages to the DTE. Furthermore, we propose a
simple yet effective method for calibrating the camera-to-marker rotation,
which is needed for the computation of our metrics. Our methods are verified
through extensive simulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The main part of this manuscript (except the part on DRE) has been
  accepted to ECCV 2024 Workshop HALF-CENTURY OF STRUCTURE-FROM-MOTION (50SFM)</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">18</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06096v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06096v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michele Mancusi, Yurii Halychansky, Kin Wai Cheuk, Chieh-Hsin Lai, Stefan Uhlich, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Giorgio Fabbro, Yuhki Mitsufuji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music timbre transfer is a challenging task that involves modifying the
timbral characteristics of an audio signal while preserving its melodic
structure. In this paper, we propose a novel method based on dual diffusion
bridges, trained using the CocoChorales Dataset, which consists of unpaired
monophonic single-instrument audio data. Each diffusion model is trained on a
specific instrument with a Gaussian prior. During inference, a model is
designated as the source model to map the input audio to its corresponding
Gaussian prior, and another model is designated as the target model to
reconstruct the target audio from this Gaussian prior, thereby facilitating
timbre transfer. We compare our approach against existing unsupervised timbre
transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental
results demonstrate that our method achieves both better Fr\'echet Audio
Distance (FAD) and melody preservation, as reflected by lower pitch distances
(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise
level from the Gaussian prior, $\sigma$, can be adjusted to control the degree
of melody preservation and amount of timbre transferred.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking Chinese Knowledge Rectification in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05806v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05806v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While Large Language Models (LLMs) exhibit remarkable generative
capabilities, they are not without flaws, particularly in the form of
hallucinations. This issue is even more pronounced when LLMs are applied to
specific languages and domains. For example, LLMs may generate nonsense
information when handling Chinese ancient poetry, proverbs, or idioms, owing to
the lack of specific knowledge. To this end, this paper introduces a benchmark
for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,
we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of
knowledge from various sources, including classical texts, idioms, and content
from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,
antithesis, and logical constructs inherent in the Chinese language. Through
the analysis of this dataset, we uncover the challenges faced by current LLMs
in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge
editing techniques on this dataset unveil the substantial scope for advancement
in the rectification of Chinese knowledge. Code and dataset are available at
https://github.com/zjunlp/EasyEdit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing work; code and dataset are available at
  https://github.com/zjunlp/EasyEdit</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extracting the U.S. building types from OpenStreetMap data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Henrique F. de Arruda, Sandro M. Reia, Shiyang Ruan, Kuldip S. Atwal, Hamdi Kavak, Taylor Anderson, Dieter Pfoser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building type information is crucial for population estimation, traffic
planning, urban planning, and emergency response applications. Although
essential, such data is often not readily available. To alleviate this problem,
this work creates a comprehensive dataset by providing
residential/non-residential building classification covering the entire United
States. We propose and utilize an unsupervised machine learning method to
classify building types based on building footprints and available
OpenStreetMap information. The classification result is validated using
authoritative ground truth data for select counties in the U.S. The validation
shows a high precision for non-residential building classification and a high
recall for residential buildings. We identified various approaches to improving
the quality of the classification, such as removing sheds and garages from the
dataset. Furthermore, analyzing the misclassifications revealed that they are
mainly due to missing and scarce metadata in OSM. A major result of this work
is the resulting dataset of classifying 67,705,475 buildings. We hope that this
data is of value to the scientific community, including urban and
transportation planners.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RegNLP in Action: Facilitating Compliance Through Automated Information
  Retrieval and Answer Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuba Gokhan, Kexin Wang, Iryna Gurevych, Ted Briscoe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Regulatory documents, issued by governmental regulatory bodies, establish
rules, guidelines, and standards that organizations must adhere to for legal
compliance. These documents, characterized by their length, complexity and
frequent updates, are challenging to interpret, requiring significant
allocation of time and expertise on the part of organizations to ensure ongoing
compliance.Regulatory Natural Language Processing (RegNLP) is a
multidisciplinary subfield aimed at simplifying access to and interpretation of
regulatory rules and obligations. We define an Automated Question-Passage
Generation task for RegNLP, create the ObliQA dataset containing 27,869
questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation
document collection, design a baseline Regulatory Information Retrieval and
Answer Generation system, and evaluate it with RePASs, a novel evaluation
metric that tests whether generated answers accurately capture all relevant
obligations and avoid contradictions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Graph Contrastive Learning with Reliable and Informative
  Augmentation for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Zheng, Junjie Zhang, Hongyu Lu, Yu Chen, Ming Chen, Wayne Xin Zhao, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph neural network (GNN) has been a powerful approach in collaborative
filtering (CF) due to its ability to model high-order user-item relationships.
Recently, to alleviate the data sparsity and enhance representation learning,
many efforts have been conducted to integrate contrastive learning (CL) with
GNNs. Despite the promising improvements, the contrastive view generation based
on structure and representation perturbations in existing methods potentially
disrupts the collaborative information in contrastive views, resulting in
limited effectiveness of positive alignment. To overcome this issue, we propose
CoGCL, a novel framework that aims to enhance graph contrastive learning by
constructing contrastive views with stronger collaborative information via
discrete codes. The core idea is to map users and items into discrete codes
rich in collaborative information for reliable and informative contrastive view
generation. To this end, we initially introduce a multi-level vector quantizer
in an end-to-end manner to quantize user and item representations into discrete
codes. Based on these discrete codes, we enhance the collaborative information
of contrastive views by considering neighborhood structure and semantic
relevance respectively. For neighborhood structure, we propose virtual neighbor
augmentation by treating discrete codes as virtual neighbors, which expands an
observed user-item interaction into multiple edges involving discrete codes.
Regarding semantic relevance, we identify similar users/items based on shared
discrete codes and interaction targets to generate the semantically relevant
view. Through these strategies, we construct contrastive views with stronger
collaborative information and develop a triple-view graph contrastive learning
approach. Extensive experiments on four public datasets demonstrate the
effectiveness of our proposed approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rs4rs: Semantically Find Recent Publications from Top Recommendation
  System-Related Venues 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05570v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05570v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tri Kurniawan Wijaya, Edoardo D'Amico, Gabor Fodor, Manuel V. Loureiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rs4rs is a web application designed to perform semantic search on recent
papers from top conferences and journals related to Recommender Systems.
Current scholarly search engine tools like Google Scholar, Semantic Scholar,
and ResearchGate often yield broad results that fail to target the most
relevant high-quality publications. Moreover, manually visiting individual
conference and journal websites is a time-consuming process that primarily
supports only syntactic searches. Rs4rs addresses these issues by providing a
user-friendly platform where researchers can input their topic of interest and
receive a list of recent, relevant papers from top Recommender Systems venues.
Utilizing semantic search techniques, Rs4rs ensures that the search results are
not only precise and relevant but also comprehensive, capturing papers
regardless of variations in wording. This tool significantly enhances research
efficiency and accuracy, thereby benefitting the research community and public
by facilitating access to high-quality, pertinent academic resources in the
field of Recommender Systems. Rs4rs is available at https://rs4rs.com.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ End-to-End Learnable Item Tokenization for Generative Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05546v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05546v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enze Liu, Bowen Zheng, Cheng Ling, Lantao Hu, Han Li, Wayne Xin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, generative recommendation has emerged as a promising new paradigm
that directly generates item identifiers for recommendation. However, a key
challenge lies in how to effectively construct item identifiers that are
suitable for recommender systems. Existing methods typically decouple item
tokenization from subsequent generative recommendation training, likely
resulting in suboptimal performance. To address this limitation, we propose
ETEGRec, a novel End-To-End Generative Recommender by seamlessly integrating
item tokenization and generative recommendation. Our framework is developed
based on the dual encoder-decoder architecture, which consists of an item
tokenizer and a generative recommender. In order to achieve mutual enhancement
between the two components, we propose a recommendation-oriented alignment
approach by devising two specific optimization objectives: sequence-item
alignment and preference-semantic alignment. These two alignment objectives can
effectively couple the learning of item tokenizer and generative recommender,
thereby fostering the mutual enhancement between the two components. Finally,
we further devise an alternating optimization method, to facilitate stable and
effective end-to-end learning of the entire framework. Extensive experiments
demonstrate the effectiveness of our proposed framework compared to a series of
traditional sequential recommendation models and generative recommendation
baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DatAasee -- A Metadata-Lake as Metadata Catalog for a Virtual Data-Lake 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05512v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05512v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christian Himpe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Metadata management for distributed data sources is a long-standing but
ever-growing problem. To counter this challenge in a research-data and
library-oriented setting, this work constructs a data architecture, derived
from the data-lake: the metadata-lake. A proof-of-concept implementation of
this proposed metadata system is presented and evaluated as well.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Federated Transfer Learning Based Cooperative Wideband Spectrum Sensing
  with Model Pruning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05462v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05462v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jibin Jia, Peihao Dong, Fuhui Zhou, Qihui Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For ultra-wideband and high-rate wireless communication systems, wideband
spectrum sensing (WSS) is critical, since it empowers secondary users (SUs) to
capture the spectrum holes for opportunistic transmission. However, WSS
encounters challenges such as excessive costs of hardware and computation due
to the high sampling rate, as well as robustness issues arising from scenario
mismatch. In this paper, a WSS neural network (WSSNet) is proposed by
exploiting multicoset preprocessing to enable the sub-Nyquist sampling, with
the two dimensional convolution design specifically tailored to work with the
preprocessed samples. A federated transfer learning (FTL) based framework
mobilizing multiple SUs is further developed to achieve a robust model
adaptable to various scenarios, which is paved by the selective weight pruning
for the fast model adaptation and inference. Simulation results demonstrate
that the proposed FTL-WSSNet achieves the fairly good performance in different
target scenarios even without local adaptation samples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recommender Systems Algorithm Selection for Ranking Prediction on
  Implicit Feedback <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05461v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05461v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Wegmeth, Tobias Vente, Joeran Beel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recommender systems algorithm selection problem for ranking prediction on
implicit feedback datasets is under-explored. Traditional approaches in
recommender systems algorithm selection focus predominantly on rating
prediction on explicit feedback datasets, leaving a research gap for ranking
prediction on implicit feedback datasets. Algorithm selection is a critical
challenge for nearly every practitioner in recommender systems. In this work,
we take the first steps toward addressing this research gap. We evaluate the
NDCG@10 of 24 recommender systems algorithms, each with two hyperparameter
configurations, on 72 recommender systems datasets. We train four optimized
machine-learning meta-models and one automated machine-learning meta-model with
three different settings on the resulting meta-dataset. Our results show that
the predictions of all tested meta-models exhibit a median Spearman correlation
ranging from 0.857 to 0.918 with the ground truth. We show that the median
Spearman correlation between meta-model predictions and the ground truth
increases by an average of 0.124 when the meta-model is optimized to predict
the ranking of algorithms instead of their performance. Furthermore, in terms
of predicting the best algorithm for an unknown dataset, we demonstrate that
the best optimized traditional meta-model, e.g., XGBoost, achieves a recall of
48.6%, outperforming the best tested automated machine learning meta-model,
e.g., AutoGluon, which achieves a recall of 47.2%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at the 18th ACM Conference on Recommender
  Systems in the Late-Breaking Results Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assessing SPARQL capabilities of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05925v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05925v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lars-Peter Meyer, Johannes Frey, Felix Brei, Natanael Arndt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>peer reviewed publication at NLP4KGc @ Semantics 2024, see
  https://sites.google.com/view/3rdnlp4kgc</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Replicability Measures for Longitudinal Information Retrieval Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jüri Keller, Timo Breuer, Philipp Schaer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information Retrieval (IR) systems are exposed to constant changes in most
components. Documents are created, updated, or deleted, the information needs
are changing, and even relevance might not be static. While it is generally
expected that the IR systems retain a consistent utility for the users, test
collection evaluations rely on a fixed experimental setup. Based on the
LongEval shared task and test collection, this work explores how the
effectiveness measured in evolving experiments can be assessed. Specifically,
the persistency of effectiveness is investigated as a replicability task. It is
observed how the effectiveness progressively deteriorates over time compared to
the initial measurement. Employing adapted replicability measures provides
further insight into the persistence of effectiveness. The ranking of systems
varies across retrieval measures and time. In conclusion, it was found that the
most effective systems are not necessarily the ones with the most persistent
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Experimental IR Meets Multilinguality, Multimodality, and Interaction
  - 15th International Conference of the CLEF Association, CLEF 2024, Grenoble,
  France, September 9-12, 2024, Proceedings. arXiv admin note: text overlap
  with arXiv:2308.10549</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of Multimodal Composite Editing and Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Suyan Li, Fuxiang Huang, Lei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the real world, where information is abundant and diverse across different
modalities, understanding and utilizing various data types to improve retrieval
systems is a key focus of research. Multimodal composite retrieval integrates
diverse modalities such as text, image and audio, etc. to provide more
accurate, personalized, and contextually relevant results. To facilitate a
deeper understanding of this promising direction, this survey explores
multimodal composite editing and retrieval in depth, covering image-text
composite editing, image-text composite retrieval, and other multimodal
composite retrieval. In this survey, we systematically organize the application
scenarios, methods, benchmarks, experiments, and future directions. Multimodal
learning is a hot topic in large model era, and have also witnessed some
surveys in multimodal learning and vision-language models with transformers
published in the PAMI journal. To the best of our knowledge, this survey is the
first comprehensive review of the literature on multimodal composite retrieval,
which is a timely complement of multimodal fusion to existing reviews. To help
readers' quickly track this field, we build the project page for this survey,
which can be found at
https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 3 figures, and 11 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NLLB-E5: A Scalable Multilingual Retrieval Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arkadeep Acharya, Rudra Murthy, Vishwajeet Kumar, Jaydeep Sen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite significant progress in multilingual information retrieval, the lack
of models capable of effectively supporting multiple languages, particularly
low-resource like Indic languages, remains a critical challenge. This paper
presents NLLB-E5: A Scalable Multilingual Retrieval Model. NLLB-E5 leverages
the in-built multilingual capabilities in the NLLB encoder for translation
tasks. It proposes a distillation approach from multilingual retriever E5 to
provide a zero-shot retrieval approach handling multiple languages, including
all major Indic languages, without requiring multilingual training data. We
evaluate the model on a comprehensive suite of existing benchmarks, including
Hindi-BEIR, highlighting its robust performance across diverse languages and
tasks. Our findings uncover task and domain-specific challenges, providing
valuable insights into the retrieval performance, especially for low-resource
languages. NLLB-E5 addresses the urgent need for an inclusive, scalable, and
language-agnostic text retrieval model, advancing the field of multilingual
information access and promoting digital inclusivity for millions of users
globally.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PhishLang: A Lightweight, Client-Side Phishing Detection Framework using
  Mobile<span class="highlight-title">BERT</span> for Real-Time, Explainable Threat Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sayak Saha Roy, Shirin Nilizadeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce PhishLang, an open-source, lightweight language
model specifically designed for phishing website detection through contextual
analysis of the website. Unlike traditional heuristic or machine learning
models that rely on static features and struggle to adapt to new threats, and
deep learning models that are computationally intensive, our model leverages
MobileBERT, a fast and memory-efficient variant of the BERT architecture, to
learn granular features characteristic of phishing attacks. PhishLang operates
with minimal data preprocessing and offers performance comparable to leading
deep learning anti-phishing tools, while being significantly faster and less
resource-intensive. Over a 3.5-month testing period, PhishLang successfully
identified 25,796 phishing URLs, many of which were undetected by popular
antiphishing blocklists, thus demonstrating its potential to enhance current
detection measures. Capitalizing on PhishLang's resource efficiency, we release
the first open-source fully client-side Chromium browser extension that
provides inference locally without requiring to consult an online blocklist and
can be run on low-end systems with no impact on inference times. Our
implementation not only outperforms prevalent (server-side) phishing tools, but
is significantly more effective than the limited commercial client-side
measures available. Furthermore, we study how PhishLang can be integrated with
GPT-3.5 Turbo to create explainable blocklisting -- which, upon detection of a
website, provides users with detailed contextual information about the features
that led to a website being marked as phishing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WildVis: Open Source Visualizer for Million-Scale Chat Logs in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03753v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03753v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuntian Deng, Wenting Zhao, Jack Hessel, Xiang Ren, Claire Cardie, Yejin Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing availability of real-world conversation data offers exciting
opportunities for researchers to study user-chatbot interactions. However, the
sheer volume of this data makes manually examining individual conversations
impractical. To overcome this challenge, we introduce WildVis, an interactive
tool that enables fast, versatile, and large-scale conversation analysis.
WildVis provides search and visualization capabilities in the text and
embedding spaces based on a list of criteria. To manage million-scale datasets,
we implemented optimizations including search index construction, embedding
precomputation and compression, and caching to ensure responsive user
interactions within seconds. We demonstrate WildVis' utility through three case
studies: facilitating chatbot misuse research, visualizing and comparing topic
distributions across datasets, and characterizing user-specific conversation
patterns. WildVis is open-source and designed to be extendable, supporting
additional datasets and customized search and visualization functionalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding Fairness in Recommender Systems: A Healthcare Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03893v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03893v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Veronica Kecki, Alan Said
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fairness in AI-driven decision-making systems has become a critical concern,
especially when these systems directly affect human lives. This paper explores
the public's comprehension of fairness in healthcare recommendations. We
conducted a survey where participants selected from four fairness metrics --
Demographic Parity, Equal Accuracy, Equalized Odds, and Positive Predictive
Value -- across different healthcare scenarios to assess their understanding of
these concepts. Our findings reveal that fairness is a complex and often
misunderstood concept, with a generally low level of public understanding
regarding fairness metrics in recommender systems. This study highlights the
need for enhanced information and education on algorithmic fairness to support
informed decision-making in using these systems. Furthermore, the results
suggest that a one-size-fits-all approach to fairness may be insufficient,
pointing to the importance of context-sensitive designs in developing equitable
AI systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 18th ACM Conference on Recommender Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG
  Capabilities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14482v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14482v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Xu, Wei Ping, Xianchao Wu, Chejian Xu, Zihan Liu, Mohammad Shoeybi, Bryan Catanzaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K
context window, designed to bridge the gap between open-source LLMs and leading
proprietary models (e.g., GPT-4-Turbo) in long-context understanding and
retrieval-augmented generation (RAG) capabilities. These two capabilities are
essential for LLMs to process large volumes of information that cannot fit into
a single prompt and are complementary to each other, depending on the
downstream tasks and computational budgets. We present a detailed continued
training recipe to extend the context window of Llama3-70B-base from 8K to 128K
tokens, along with a three-stage instruction tuning process to enhance the
model's instruction-following, RAG performance, and long-context understanding
capabilities. Our results demonstrate that the Llama3-ChatQA-2-70B model
outperforms most existing state-of-the-art models, including
GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and Llama3.1-70B-Instruct, on
ultra-long tasks beyond 100K tokens, as well as on the RAG benchmark using only
a 4K context window, showing the strong long context capability across varying
sequence lengths. We further provide extensive comparisons between direct
long-context and RAG solutions using the same state-of-the-art long-context
LLMs. Interestingly, we find that the performance of strong long-context LLMs
using RAG improves when retrieving a larger number of chunks. With a large set
of top-k chunks, RAG consistently outperforms direct long-context solution
using the same state-of-the-art long-context models (e.g., Llama3-ChatQA-2-70B
and Qwen2-72B-Instruct) on both 32K benchmarks and real-world 128K tasks. To
advance research in this field, we open-sourced the model weights, training
data, and the evaluation setup for the for the community:
https://chatqa2-project.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: major update with significantly improved results</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">16</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable Multitask Learning Using Gradient-based Estimation of Task
  Affinity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06091v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06091v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongyue Li, Aneesh Sharma, Hongyang R. Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a "base" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Differentiable programming across the PDE and Machine Learning barrier 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06085v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06085v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nacime Bouziani, David A. Ham, Ado Farsi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The combination of machine learning and physical laws has shown immense
potential for solving scientific problems driven by partial differential
equations (PDEs) with the promise of fast inference, zero-shot generalisation,
and the ability to discover new physics. Examples include the use of
fundamental physical laws as inductive bias to machine learning algorithms,
also referred to as physics-driven machine learning, and the application of
machine learning to represent features not represented in the differential
equations such as closures for unresolved spatiotemporal scales. However, the
simulation of complex physical systems by coupling advanced numerics for PDEs
with state-of-the-art machine learning demands the composition of specialist
PDE solving frameworks with industry-standard machine learning tools.
Hand-rolling either the PDE solver or the neural net will not cut it. In this
work, we introduce a generic differentiable programming abstraction that
provides scientists and engineers with a highly productive way of specifying
end-to-end differentiable models coupling machine learning and PDE-based
components, while relying on code generation for high performance. Our
interface automates the coupling of arbitrary PDE-based systems and machine
learning models and unlocks new applications that could not hitherto be
tackled, while only requiring trivial changes to existing code. Our framework
has been adopted in the Firedrake finite-element library and supports the
PyTorch and JAX ecosystems, as well as downstream libraries.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Symmetry constrained neural networks for detection and localization of
  damage in metal plates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06084v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06084v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James Amarel, Christopher Rudolf, Athanasios Iliopoulos, John Michopoulos, Leslie N. Smith
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The present paper is concerned with deep learning techniques applied to
detection and localization of damage in a thin aluminum plate. We used data
generated on a tabletop apparatus by mounting to the plate four piezoelectric
transducers, each of which took turn to generate a Lamb wave that then
traversed the region of interest before being received by the remaining three
sensors. On training a neural network to analyze time-series data of the
material response, which displayed damage-reflective features whenever the
plate guided waves interacted with a contact load, we achieved a model that
detected with greater than 99% accuracy in addition to a model that localized
with $3.14 \pm 0.21$ mm mean distance error and captured more than 60% of test
examples within the diffraction limit. For each task, the best-performing model
was designed according to the inductive bias that our transducers were both
similar and arranged in a square pattern on a nearly uniform plate.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Regression with Large Language Models for Materials and Molecular
  Property Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06080v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06080v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan Jacobs, Maciej P. Polak, Lane E. Schultz, Hamed Mahdavi, Vasant Honavar, Dane Morgan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We demonstrate the ability of large language models (LLMs) to perform
material and molecular property regression tasks, a significant deviation from
the conventional LLM use case. We benchmark the Large Language Model Meta AI
(LLaMA) 3 on several molecular properties in the QM9 dataset and 24 materials
properties. Only composition-based input strings are used as the model input
and we fine tune on only the generative loss. We broadly find that LLaMA 3,
when fine-tuned using the SMILES representation of molecules, provides useful
regression results which can rival standard materials property prediction
models like random forest or fully connected neural networks on the QM9
dataset. Not surprisingly, LLaMA 3 errors are 5-10x higher than those of the
state-of-the-art models that were trained using far more granular
representation of molecules (e.g., atom types and their coordinates) for the
same task. Interestingly, LLaMA 3 provides improved predictions compared to
GPT-3.5 and GPT-4o. This work highlights the versatility of LLMs, suggesting
that LLM-like generative models can potentially transcend their traditional
applications to tackle complex physical phenomena, thus paving the way for
future research and applications in chemistry, materials science and other
scientific domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06077v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06077v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Faezeh Faez, Raika Karimi, Yingxue Zhang, Xing Li, Lei Chen, Mingxuan Yuan, Mahdi Biparva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electronic Design Automation (EDA) is essential for IC design and has
recently benefited from AI-based techniques to improve efficiency. Logic
synthesis, a key EDA stage, transforms high-level hardware descriptions into
optimized netlists. Recent research has employed machine learning to predict
Quality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis
recipes. However, the severe scarcity of data due to a very limited number of
available AIGs results in overfitting, significantly hindering performance.
Additionally, the complexity and large number of nodes in AIGs make plain GNNs
less effective for learning expressive graph-level representations. To tackle
these challenges, we propose MTLSO - a Multi-Task Learning approach for Logic
Synthesis Optimization. On one hand, it maximizes the use of limited data by
training the model across different tasks. This includes introducing an
auxiliary task of binary multi-label graph classification alongside the primary
regression task, allowing the model to benefit from diverse supervision
sources. On the other hand, we employ a hierarchical graph representation
learning strategy to improve the model's capacity for learning expressive
graph-level representations of large AIGs, surpassing traditional plain GNNs.
Extensive experiments across multiple datasets and against state-of-the-art
baselines demonstrate the superiority of our method, achieving an average
performance gain of 8.22\% for delay and 5.95\% for area.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DetoxBench: Benchmarking Large Language Models for Multitask Fraud &
  Abuse Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06072v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06072v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joymallya Chakraborty, Wei Xia, Anirban Majumder, Dan Ma, Walid Chaabene, Naveed Janvekar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Privacy-Preserving Data Linkage Across Private and Public <span class="highlight-title">Dataset</span>s for
  Collaborative Agriculture Research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06069v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06069v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Osama Zafar, Rosemarie Santa Gonzalez, Gabriel Wilkins, Alfonso Morales, Erman Ayday
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Digital agriculture leverages technology to enhance crop yield, disease
resilience, and soil health, playing a critical role in agricultural research.
However, it raises privacy concerns such as adverse pricing, price
discrimination, higher insurance costs, and manipulation of resources,
deterring farm operators from sharing data due to potential misuse. This study
introduces a privacy-preserving framework that addresses these risks while
allowing secure data sharing for digital agriculture. Our framework enables
comprehensive data analysis while protecting privacy. It allows stakeholders to
harness research-driven policies that link public and private datasets. The
proposed algorithm achieves this by: (1) identifying similar farmers based on
private datasets, (2) providing aggregate information like time and location,
(3) determining trends in price and product availability, and (4) correlating
trends with public policy data, such as food insecurity statistics. We validate
the framework with real-world Farmer's Market datasets, demonstrating its
efficacy through machine learning models trained on linked privacy-preserved
data. The results support policymakers and researchers in addressing food
insecurity and pricing issues. This work significantly contributes to digital
agriculture by providing a secure method for integrating and analyzing data,
driving advancements in agricultural technology and development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Statistical Mechanics of Min-Max Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06053v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06053v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuma Ichikawa, Koji Hukushima
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Min-max optimization problems, also known as saddle point problems, have
attracted significant attention due to their applications in various fields,
such as fair beamforming, generative adversarial networks (GANs), and
adversarial learning. However, understanding the properties of these min-max
problems has remained a substantial challenge. This study introduces a
statistical mechanical formalism for analyzing the equilibrium values of
min-max problems in the high-dimensional limit, while appropriately addressing
the order of operations for min and max. As a first step, we apply this
formalism to bilinear min-max games and simple GANs, deriving the relationship
between the amount of training data and generalization error and indicating the
optimal ratio of fake to real data for effective learning. This formalism
provides a groundwork for a deeper theoretical analysis of the equilibrium
properties in various machine learning methods based on min-max problems and
encourages the development of new algorithms and architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 1 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PhishLang: A Lightweight, Client-Side Phishing Detection Framework using
  Mobile<span class="highlight-title">BERT</span> for Real-Time, Explainable Threat Mitigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.05667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.05667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sayak Saha Roy, Shirin Nilizadeh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce PhishLang, an open-source, lightweight language
model specifically designed for phishing website detection through contextual
analysis of the website. Unlike traditional heuristic or machine learning
models that rely on static features and struggle to adapt to new threats, and
deep learning models that are computationally intensive, our model leverages
MobileBERT, a fast and memory-efficient variant of the BERT architecture, to
learn granular features characteristic of phishing attacks. PhishLang operates
with minimal data preprocessing and offers performance comparable to leading
deep learning anti-phishing tools, while being significantly faster and less
resource-intensive. Over a 3.5-month testing period, PhishLang successfully
identified 25,796 phishing URLs, many of which were undetected by popular
antiphishing blocklists, thus demonstrating its potential to enhance current
detection measures. Capitalizing on PhishLang's resource efficiency, we release
the first open-source fully client-side Chromium browser extension that
provides inference locally without requiring to consult an online blocklist and
can be run on low-end systems with no impact on inference times. Our
implementation not only outperforms prevalent (server-side) phishing tools, but
is significantly more effective than the limited commercial client-side
measures available. Furthermore, we study how PhishLang can be integrated with
GPT-3.5 Turbo to create explainable blocklisting -- which, upon detection of a
website, provides users with detailed contextual information about the features
that led to a website being marked as phishing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Concealing Backdoor Model Updates in Federated Learning by
  Trigger-Optimized Data Poisoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06206v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06206v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujie Zhang, Neil Gong, Michael K. Reiter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Learning (FL) is a decentralized machine learning method that
enables participants to collaboratively train a model without sharing their
private data. Despite its privacy and scalability benefits, FL is susceptible
to backdoor attacks, where adversaries poison the local training data of a
subset of clients using a backdoor trigger, aiming to make the aggregated model
produce malicious results when the same backdoor condition is met by an
inference-time input. Existing backdoor attacks in FL suffer from common
deficiencies: fixed trigger patterns and reliance on the assistance of model
poisoning. State-of-the-art defenses based on analyzing clients' model updates
exhibit a good defense performance on these attacks because of the significant
divergence between malicious and benign client model updates. To effectively
conceal malicious model updates among benign ones, we propose DPOT, a backdoor
attack strategy in FL that dynamically constructs backdoor objectives by
optimizing a backdoor trigger, making backdoor data have minimal effect on
model updates. We provide theoretical justifications for DPOT's attacking
principle and display experimental results showing that DPOT, via only a
data-poisoning attack, effectively undermines state-of-the-art defenses and
outperforms existing backdoor attack techniques on various datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Feedback-guided Data Synthesis for Imbalanced Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.00158v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.00158v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Reyhane Askari Hemmat, Mohammad Pezeshki, Florian Bordes, Michal Drozdzal, Adriana Romero-Soriano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current status quo in machine learning is to use static datasets of real
images for training, which often come from long-tailed distributions. With the
recent advances in generative models, researchers have started augmenting these
static datasets with synthetic data, reporting moderate performance
improvements on classification tasks. We hypothesize that these performance
gains are limited by the lack of feedback from the classifier to the generative
model, which would promote the usefulness of the generated samples to improve
the classifier's performance. In this work, we introduce a framework for
augmenting static datasets with useful synthetic samples, which leverages
one-shot feedback from the classifier to drive the sampling of the generative
model. In order for the framework to be effective, we find that the samples
must be close to the support of the real data of the task at hand, and be
sufficiently diverse. We validate three feedback criteria on a long-tailed
dataset (ImageNet-LT) as well as a group-imbalanced dataset (NICO++). On
ImageNet-LT, we achieve state-of-the-art results, with over 4 percent
improvement on underrepresented classes while being twice efficient in terms of
the number of generated synthetic samples. NICO++ also enjoys marked boosts of
over 5 percent in worst group accuracy. With these results, our framework paves
the path towards effectively leveraging state-of-the-art text-to-image models
as data sources that can be queried to improve downstream applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Differentially Private Model Training with Public Data <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2306.15056v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2306.15056v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Lowy, Zeman Li, Tianjian Huang, Meisam Razaviyayn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differential privacy (DP) ensures that training a machine learning model does
not leak private data. In practice, we may have access to auxiliary public data
that is free of privacy concerns. In this work, we assume access to a given
amount of public data and settle the following fundamental open questions: 1.
What is the optimal (worst-case) error of a DP model trained over a private
data set while having access to side public data? 2. How can we harness public
data to improve DP model training in practice? We consider these questions in
both the local and central models of pure and approximate DP. To answer the
first question, we prove tight (up to log factors) lower and upper bounds that
characterize the optimal error rates of three fundamental problems: mean
estimation, empirical risk minimization, and stochastic convex optimization. We
show that the optimal error rates can be attained (up to log factors) by either
discarding private data and training a public model, or treating public data
like it is private and using an optimal DP algorithm. To address the second
question, we develop novel algorithms that are "even more optimal" (i.e. better
constants) than the asymptotically optimal approaches described above. For
local DP mean estimation, our algorithm is optimal including constants.
Empirically, our algorithms show benefits over the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Epistemic Uncertainty Faithfully Represented by Evidential Deep
  Learning Methods? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09056v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09056v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mira Jürgens, Nis Meinert, Viktor Bengs, Eyke Hüllermeier, Willem Waegeman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Trustworthy ML systems should not only return accurate predictions, but also
a reliable representation of their uncertainty. Bayesian methods are commonly
used to quantify both aleatoric and epistemic uncertainty, but alternative
approaches, such as evidential deep learning methods, have become popular in
recent years. The latter group of methods in essence extends empirical risk
minimization (ERM) for predicting second-order probability distributions over
outcomes, from which measures of epistemic (and aleatoric) uncertainty can be
extracted. This paper presents novel theoretical insights of evidential deep
learning, highlighting the difficulties in optimizing second-order loss
functions and interpreting the resulting epistemic uncertainty measures. With a
systematic setup that covers a wide range of approaches for classification,
regression and counts, it provides novel insights into issues of
identifiability and convergence in second-order loss minimization, and the
relative (rather than absolute) nature of epistemic uncertainty measures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifiable Exchangeable Mechanisms for Causal Structure and
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14302v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14302v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrik Reizinger, Siyuan Guo, Ferenc Huszár, Bernhard Schölkopf, Wieland Brendel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Identifying latent representations or causal structures is important for good
generalization and downstream task performance. However, both fields have been
developed rather independently. We observe that several methods in both
representation and causal structure learning rely on the same data-generating
process (DGP), namely, exchangeable but not i.i.d. (independent and identically
distributed) data. We provide a unified framework, termed Identifiable
Exchangeable Mechanisms (IEM), for representation and structure learning under
the lens of exchangeability. IEM provides new insights that let us relax the
necessary conditions for causal structure identification in exchangeable
non--i.i.d. data. We also demonstrate the existence of a duality condition in
identifiable representation learning, leading to new identifiability results.
We hope this work will pave the way for further research in causal
representation learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Recoverability of Causal Relations from Temporally Aggregated
  I.I.D. Data <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02191v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02191v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shunxing Fan, Mingming Gong, Kun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the effect of temporal aggregation on instantaneous
(non-temporal) causal discovery in general setting. This is motivated by the
observation that the true causal time lag is often considerably shorter than
the observational interval. This discrepancy leads to high aggregation, causing
time-delay causality to vanish and instantaneous dependence to manifest.
Although we expect such instantaneous dependence has consistency with the true
causal relation in certain sense to make the discovery results meaningful, it
remains unclear what type of consistency we need and when will such consistency
be satisfied. We proposed functional consistency and conditional independence
consistency in formal way correspond functional causal model-based methods and
conditional independence-based methods respectively and provide the conditions
under which these consistencies will hold. We show theoretically and
experimentally that causal discovery results may be seriously distorted by
aggregation especially in complete nonlinear case and we also find causal
relationship still recoverable from aggregated data if we have partial
linearity or appropriate prior. Our findings suggest community should take a
cautious and meticulous approach when interpreting causal discovery results
from such data and show why and when aggregation will distort the performance
of causal discovery methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ro<span class="highlight-title">BERT</span>a and Attention-based BiLSTM for Interpretable Sentiment Analysis
  of Tweets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00297v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00297v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Abrar Jahin, Md Sakib Hossain Shovon, M. F. Mridha, Md Rashedul Islam, Yutaka Watanobe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sentiment analysis is crucial for understanding public opinion and consumer
behavior. Existing models face challenges with linguistic diversity,
generalizability, and explainability. We propose TRABSA, a hybrid framework
integrating transformer-based architectures, attention mechanisms, and BiLSTM
networks to address this. Leveraging RoBERTa-trained on 124M tweets, we bridge
gaps in sentiment analysis benchmarks, ensuring state-of-the-art accuracy.
Augmenting datasets with tweets from 32 countries and US states, we compare six
word-embedding techniques and three lexicon-based labeling techniques,
selecting the best for optimal sentiment analysis. TRABSA outperforms
traditional ML and deep learning models with 94% accuracy and significant
precision, recall, and F1-score gains. Evaluation across diverse datasets
demonstrates consistent superiority and generalizability. SHAP and LIME
analyses enhance interpretability, improving confidence in predictions. Our
study facilitates pandemic resource management, aiding resource planning,
policy formation, and vaccination tactics.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ REVISION: A Roadmap on Adaptive Video Streaming Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06051v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06051v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Farzad Tashtarian, Christian Timmerer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the soaring popularity of video applications and the consequent rise
in video traffic on the Internet, technologies like HTTP Adaptive Streaming
(HAS) are crucial for delivering high Quality of Experience (QoE) to consumers.
HAS technology enables video players on consumer devices to enhance viewer
engagement by dynamically adapting video content quality based on network
conditions. This is especially relevant for consumer electronics as it ensures
an optimized viewing experience across a variety of devices, from smartphones
to smart TVs. This paper introduces REVISION, an efficient roadmap designed to
enhance adaptive video streaming, a core feature of modern consumer
electronics. The REVISION optimization triangle highlights three essential
aspects for improving streaming: Objective, Input Space, and Action Domain.
Additionally, REVISION proposes a novel layer-based architecture tailored to
refine video streaming systems, comprising Application, Control and Management,
and Resource layers. Each layer is designed to optimize different components of
the streaming process, which is directly linked to the performance and
efficiency of consumer devices. By adopting the principles of the REVISION,
manufacturers and developers can significantly improve the streaming
capabilities of consumer electronics, thereby enriching the consumer's
multimedia experience and accommodating the increasing demand for high-quality,
real-time video content. This approach addresses the complexities of today's
diverse video streaming ecosystem and paves the way for future advancements in
consumer technology.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A CLIP-based siamese approach for meme classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Javier Huertas-Tato, Christos Koutlis, Symeon Papadopoulos, David Camacho, Ioannis Kompatsiaris
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Memes are an increasingly prevalent element of online discourse in social
networks, especially among young audiences. They carry ideas and messages that
range from humorous to hateful, and are widely consumed. Their potentially high
impact requires adequate means of control to moderate their use in large scale.
In this work, we propose SimCLIP a deep learning-based architecture for
cross-modal understanding of memes, leveraging a pre-trained CLIP encoder to
produce context-aware embeddings and a Siamese fusion technique to capture the
interactions between text and image. We perform an extensive experimentation on
seven meme classification tasks across six datasets. We establish a new state
of the art in Memotion7k with a 7.25% relative F1-score improvement, and
achieve super-human performance on Harm-P with 13.73% F1-Score improvement. Our
approach demonstrates the potential for compact meme classification models,
enabling accurate and efficient meme monitoring. We share our code at
https://github.com/jahuerta92/meme-classification-simclip
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Toolkit for Joint Speaker Diarization and Identification with
  Application to Speaker-Attributed ASR 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05750v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05750v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giovanni Morrone, Enrico Zovato, Fabio Brugnara, Enrico Sartori, Leonardo Badino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a modular toolkit to perform joint speaker diarization and speaker
identification. The toolkit can leverage on multiple models and algorithms
which are defined in a configuration file. Such flexibility allows our system
to work properly in various conditions (e.g., multiple registered speakers'
sets, acoustic conditions and languages) and across application domains (e.g.
media monitoring, institutional, speech analytics). In this demonstration we
show a practical use-case in which speaker-related information is used jointly
with automatic speech recognition engines to generate speaker-attributed
transcriptions. To achieve that, we employ a user-friendly web-based interface
to process audio and video inputs with the chosen configuration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Show and Tell paper. Presented at Interspeech 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio-Visual Speaker Diarization: Current Databases, Approaches and
  Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05659v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05659v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Victoria Mingote, Alfonso Ortega, Antonio Miguel, Eduardo Lleida
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nowadays, the large amount of audio-visual content available has fostered the
need to develop new robust automatic speaker diarization systems to analyse and
characterise it. This kind of system helps to reduce the cost of doing this
process manually and allows the use of the speaker information for different
applications, as a huge quantity of information is present, for example, images
of faces, or audio recordings. Therefore, this paper aims to address a critical
area in the field of speaker diarization systems, the integration of
audio-visual content of different domains. This paper seeks to push beyond
current state-of-the-art practices by developing a robust audio-visual speaker
diarization framework adaptable to various data domains, including TV
scenarios, meetings, and daily activities. Unlike most of the existing
audio-visual speaker diarization systems, this framework will also include the
proposal of an approach to lead the precise assignment of specific identities
in TV scenarios where celebrities appear. In addition, in this work, we have
conducted an extensive compilation of the current state-of-the-art approaches
and the existing databases for developing audio-visual speaker diarization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CustomContrast: A Multilevel Contrastive Perspective For Subject-Driven
  Text-to-Image Customization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nan Chen, Mengqi Huang, Zhuowei Chen, Yang Zheng, Lei Zhang, Zhendong Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Subject-driven text-to-image (T2I) customization has drawn significant
interest in academia and industry. This task enables pre-trained models to
generate novel images based on unique subjects. Existing studies adopt a
self-reconstructive perspective, focusing on capturing all details of a single
image, which will misconstrue the specific image's irrelevant attributes (e.g.,
view, pose, and background) as the subject intrinsic attributes. This
misconstruction leads to both overfitting or underfitting of irrelevant and
intrinsic attributes of the subject, i.e., these attributes are
over-represented or under-represented simultaneously, causing a trade-off
between similarity and controllability. In this study, we argue an ideal
subject representation can be achieved by a cross-differential perspective,
i.e., decoupling subject intrinsic attributes from irrelevant attributes via
contrastive learning, which allows the model to focus more on intrinsic
attributes through intra-consistency (features of the same subject are
spatially closer) and inter-distinctiveness (features of different subjects
have distinguished differences). Specifically, we propose CustomContrast, a
novel framework, which includes a Multilevel Contrastive Learning (MCL)
paradigm and a Multimodal Feature Injection (MFI) Encoder. The MCL paradigm is
used to extract intrinsic features of subjects from high-level semantics to
low-level appearance through crossmodal semantic contrastive learning and
multiscale appearance contrastive learning. To facilitate contrastive learning,
we introduce the MFI encoder to capture cross-modal representations. Extensive
experiments show the effectiveness of CustomContrast in subject similarity and
text controllability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Rich Subjective Quality Information for Image Quality
  Assessment in the Wild 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiongkuo Min, Yixuan Gao, Yuqin Cao, Guangtao Zhai, Wenjun Zhang, Huifang Sun, Chang Wen Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional in the wild image quality assessment (IQA) models are generally
trained with the quality labels of mean opinion score (MOS), while missing the
rich subjective quality information contained in the quality ratings, for
example, the standard deviation of opinion scores (SOS) or even distribution of
opinion scores (DOS). In this paper, we propose a novel IQA method named
RichIQA to explore the rich subjective rating information beyond MOS to predict
image quality in the wild. RichIQA is characterized by two key novel designs:
(1) a three-stage image quality prediction network which exploits the powerful
feature representation capability of the Convolutional vision Transformer (CvT)
and mimics the short-term and long-term memory mechanisms of human brain; (2) a
multi-label training strategy in which rich subjective quality information like
MOS, SOS and DOS are concurrently used to train the quality prediction network.
Powered by these two novel designs, RichIQA is able to predict the image
quality in terms of a distribution, from which the mean image quality can be
subsequently obtained. Extensive experimental results verify that the
three-stage network is tailored to predict rich quality information, while the
multi-label training strategy can fully exploit the potentials within
subjective quality rating and enhance the prediction performance and
generalizability of the network. RichIQA outperforms state-of-the-art
competitors on multiple large-scale in the wild IQA databases with rich
subjective rating labels. The code of RichIQA will be made publicly available
on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Educational Virtual Field Trips based on Social VR and 360° Spaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Surya Kalvakolu, Heinrich Söbke, Jannicke Baalsrud Hauge, Eckhard Kraft
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Virtual field trips (VFTs) have proven to be valuable learning tools. Such
applications are mostly based on 360{\deg} technology and are to be
characterized as single-user applications in technological terms. In contrast,
Social VR applications are characterized by multi-user capability and
user-specific avatars. From a learning perspective, the concepts of
collaborative learning and embodiment have long been proposed as conducive to
learning. Both concepts might be supported using Social VR. However, little is
currently known about the use of Social VR for VFTs. Accordingly, the research
questions are to what extent VFTs can be implemented in Social VR environments
and how these Social VR-based VFTs are perceived by learners. This article
presents an evaluation study on the development and evaluation of a VFT
environment using the Social VR platform Mozilla Hubs. It describes the design
decisions to create the environment and evaluation results from a mixed-method
study (N=16) using a questionnaire and focus group discussions. The study
highlighted the opportunities offered by Social VR-based VFTs but also revealed
several challenges that need to be addressed to embrace the potential of Social
VR-based VFTs to be utilized regularly in education.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 7 figures, 1 table, submitted to Games and Learning Alliance
  Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of Multimodal Composite Editing and Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05405v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05405v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Suyan Li, Fuxiang Huang, Lei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the real world, where information is abundant and diverse across different
modalities, understanding and utilizing various data types to improve retrieval
systems is a key focus of research. Multimodal composite retrieval integrates
diverse modalities such as text, image and audio, etc. to provide more
accurate, personalized, and contextually relevant results. To facilitate a
deeper understanding of this promising direction, this survey explores
multimodal composite editing and retrieval in depth, covering image-text
composite editing, image-text composite retrieval, and other multimodal
composite retrieval. In this survey, we systematically organize the application
scenarios, methods, benchmarks, experiments, and future directions. Multimodal
learning is a hot topic in large model era, and have also witnessed some
surveys in multimodal learning and vision-language models with transformers
published in the PAMI journal. To the best of our knowledge, this survey is the
first comprehensive review of the literature on multimodal composite retrieval,
which is a timely complement of multimodal fusion to existing reviews. To help
readers' quickly track this field, we build the project page for this survey,
which can be found at
https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 3 figures, and 11 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Look One and More: Distilling Hybrid Order Relational Knowledge for
  Cross-Resolution Image Recognition <span class="chip">AAAI 2020</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05384v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05384v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shiming Ge, Kangkai Zhang, Haolin Liu, Yingying Hua, Shengwei Zhao, Xin Jin, Hao Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In spite of great success in many image recognition tasks achieved by recent
deep models, directly applying them to recognize low-resolution images may
suffer from low accuracy due to the missing of informative details during
resolution degradation. However, these images are still recognizable for
subjects who are familiar with the corresponding high-resolution ones. Inspired
by that, we propose a teacher-student learning approach to facilitate
low-resolution image recognition via hybrid order relational knowledge
distillation. The approach refers to three streams: the teacher stream is
pretrained to recognize high-resolution images in high accuracy, the student
stream is learned to identify low-resolution images by mimicking the teacher's
behaviors, and the extra assistant stream is introduced as bridge to help
knowledge transfer across the teacher to the student. To extract sufficient
knowledge for reducing the loss in accuracy, the learning of student is
supervised with multiple losses, which preserves the similarities in various
order relational structures. In this way, the capability of recovering missing
details of familiar low-resolution images can be effectively enhanced, leading
to a better knowledge transfer. Extensive experiments on metric learning,
low-resolution image classification and low-resolution face recognition tasks
show the effectiveness of our approach, while taking reduced models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2020</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KAN-Based Fusion of Dual-Domain for Audio-Driven Facial Landmarks
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05330v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05330v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hoang-Son Vo-Thanh, Quang-Vinh Nguyen, Soo-Hyung Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio-driven talking face generation is a widely researched topic due to its
high applicability. Reconstructing a talking face using audio significantly
contributes to fields such as education, healthcare, online conversations,
virtual assistants, and virtual reality. Early studies often focused solely on
changing the mouth movements, which resulted in outcomes with limited practical
applications. Recently, researchers have proposed a new approach of
constructing the entire face, including face pose, neck, and shoulders. To
achieve this, they need to generate through landmarks. However, creating stable
landmarks that align well with the audio is a challenge. In this paper, we
propose the KFusion of Dual-Domain model, a robust model that generates
landmarks from audio. We separate the audio into two distinct domains to learn
emotional information and facial context, then use a fusion mechanism based on
the KAN model. Our model demonstrates high efficiency compared to recent
models. This will lay the groundwork for the development of the audio-driven
talking face generation problem in the future.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Offloading and Enhancement for Low-Light Video Analytics on
  Mobile Devices 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanyi He, Peng Yang, Tian Qin, Jiawei Hou, Ning Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we explore adaptive offloading and enhancement strategies for
video analytics tasks on computing-constrained mobile devices in low-light
conditions. We observe that the accuracy of low-light video analytics varies
from different enhancement algorithms. The root cause could be the disparities
in the effectiveness of enhancement algorithms for feature extraction in
analytic models. Specifically, the difference in class activation maps (CAMs)
between enhanced and low-light frames demonstrates a positive correlation with
video analytics accuracy. Motivated by such observations, a novel enhancement
quality assessment method is proposed on CAMs to evaluate the effectiveness of
different enhancement algorithms for low-light videos. Then, we design a
multi-edge system, which adaptively offloads and enhances low-light video
analytics tasks from mobile devices. To achieve the trade-off between the
enhancement quality and the latency for all system-served mobile devices, we
propose a genetic-based scheduling algorithm, which can find a near-optimal
solution in a reasonable time to meet the latency requirement. Thereby, the
offloading strategies and the enhancement algorithms are properly selected
under the condition of limited end-edge bandwidth and edge computation
resources. Simulation experiments demonstrate the superiority of the proposed
system, improving accuracy up to 20.83\% compared to existing benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HiSC4D: Human-centered interaction and 4D Scene Capture in Large-scale
  Space Using Wearable IMUs and LiDAR 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04398v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04398v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yudi Dai, Zhiyong Wang, Xiping Lin, Chenglu Wen, Lan Xu, Siqi Shen, Yuexin Ma, Cheng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce HiSC4D, a novel Human-centered interaction and 4D Scene Capture
method, aimed at accurately and efficiently creating a dynamic digital world,
containing large-scale indoor-outdoor scenes, diverse human motions, rich
human-human interactions, and human-environment interactions. By utilizing
body-mounted IMUs and a head-mounted LiDAR, HiSC4D can capture egocentric human
motions in unconstrained space without the need for external devices and
pre-built maps. This affords great flexibility and accessibility for
human-centered interaction and 4D scene capturing in various environments.
Taking into account that IMUs can capture human spatially unrestricted poses
but are prone to drifting for long-period using, and while LiDAR is stable for
global localization but rough for local positions and orientations, HiSC4D
employs a joint optimization method, harmonizing all sensors and utilizing
environment cues, yielding promising results for long-term capture in large
scenes. To promote research of egocentric human interaction in large scenes and
facilitate downstream tasks, we also present a dataset, containing 8 sequences
in 4 large scenes (200 to 5,000 $m^2$), providing 36k frames of accurate 4D
human motions with SMPL annotations and dynamic scenes, 31k frames of cropped
human point clouds, and scene mesh of the environment. A variety of scenarios,
such as the basketball gym and commercial street, alongside challenging human
motions, such as daily greeting, one-on-one basketball playing, and tour
guiding, demonstrate the effectiveness and the generalization ability of
HiSC4D. The dataset and code will be publicated on
www.lidarhumanmotion.net/hisc4d available for research purposes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 10 figures, Jornal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Auto-ACD: A Large-scale <span class="highlight-title">Dataset</span> for Audio-Language Representation
  Learning <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.11500v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.11500v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luoyi Sun, Xuenan Xu, Mengyue Wu, Weidi Xie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, the AI community has made significant strides in developing
powerful foundation models, driven by large-scale multimodal datasets. However,
for audio representation learning, existing datasets suffer from limitations in
the following aspects: insufficient volume, simplistic content, and arduous
collection procedures. To establish an audio dataset with high-quality
captions, we propose an innovative, automatic approach leveraging multimodal
inputs, such as video frames, audio streams. Specifically, we construct a
large-scale, high-quality, audio-language dataset, named as Auto-ACD,
comprising over 1.5M audio-text pairs. We exploit a series of pre-trained
models or APIs, to determine audio-visual synchronisation, generate image
captions, object detection, or audio tags for specific videos. Subsequently, we
employ LLM to paraphrase a congruent caption for each audio, guided by the
extracted multi-modality clues. To demonstrate the effectiveness of the
proposed dataset, we train widely used models on our dataset and show
performance improvement on various downstream tasks, for example,
audio-language retrieval, audio captioning, zero-shot classification. In
addition, we establish a novel benchmark with environmental information and
provide a benchmark for audio-text tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM MM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Concept Conductor: Orchestrating Multiple Personalized Concepts in
  Text-to-Image Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03632v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03632v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zebin Yao, Fangxiang Feng, Ruifan Li, Xiaojie Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The customization of text-to-image models has seen significant advancements,
yet generating multiple personalized concepts remains a challenging task.
Current methods struggle with attribute leakage and layout confusion when
handling multiple concepts, leading to reduced concept fidelity and semantic
consistency. In this work, we introduce a novel training-free framework,
Concept Conductor, designed to ensure visual fidelity and correct layout in
multi-concept customization. Concept Conductor isolates the sampling processes
of multiple custom models to prevent attribute leakage between different
concepts and corrects erroneous layouts through self-attention-based spatial
guidance. Additionally, we present a concept injection technique that employs
shape-aware masks to specify the generation area for each concept. This
technique injects the structure and appearance of personalized concepts through
feature fusion in the attention layers, ensuring harmony in the final image.
Extensive qualitative and quantitative experiments demonstrate that Concept
Conductor can consistently generate composite images with accurate layouts
while preserving the visual details of each concept. Compared to existing
baselines, Concept Conductor shows significant performance improvements. Our
method supports the combination of any number of concepts and maintains high
fidelity even when dealing with visually similar concepts. The code and models
are available at https://github.com/Nihukat/Concept-Conductor.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github Page: https://github.com/Nihukat/Concept-Conductor</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 360VFI: A <span class="highlight-title">Dataset</span> and Benchmark for Omnidirectional Video Frame
  Interpolation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14066v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14066v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenxuan Lu, Mengshun Hu, Yansheng Qiu, Liang Liao, Zheng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Head-mounted 360{\deg} displays and portable 360{\deg} cameras have
significantly progressed, providing viewers a realistic and immersive
experience. However, many omnidirectional videos have low frame rates that can
lead to visual fatigue, and the prevailing plane frame interpolation
methodologies are unsuitable for omnidirectional video interpolation because
they are designed solely for traditional videos. This paper introduces the
benchmark dataset, 360VFI, for Omnidirectional Video Frame Interpolation. We
present a practical implementation that introduces a distortion prior from
omnidirectional video into the network to modulate distortions. Specifically,
we propose a pyramid distortion-sensitive feature extractor that uses the
unique characteristics of equirectangular projection (ERP) format as prior
information. Moreover, we devise a decoder that uses an affine transformation
to further facilitate the synthesis of intermediate frames. 360VFI is the first
dataset and benchmark that explores the challenge of Omnidirectional Video
Frame Interpolation. Through our benchmark analysis, we present four different
distortion condition scenes in the proposed 360VFI dataset to evaluate the
challenges triggered by distortion during interpolation. Besides, experimental
results demonstrate that Omnidirectional Video Interpolation can be effectively
improved by modeling for omnidirectional distortion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a preprint version</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-08T00:00:00Z">2024-09-08</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">22</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Socially Responsible Data for Large Multilingual Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05247v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05247v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Smart, Ben Hutchinson, Lameck Mbangula Amugongo, Suzanne Dikker, Alex Zito, Amber Ebinama, Zara Wudiri, Ding Wang, Erin van Liemt, João Sedoc, Seyi Olojo, Stanley Uwakwe, Edem Wornyo, Sonja Schmer-Galunder, Jamila Smith-Loud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have rapidly increased in size and apparent
capabilities in the last three years, but their training data is largely
English text. There is growing interest in multilingual LLMs, and various
efforts are striving for models to accommodate languages of communities outside
of the Global North, which include many languages that have been historically
underrepresented in digital realms. These languages have been coined as "low
resource languages" or "long-tail languages", and LLMs performance on these
languages is generally poor. While expanding the use of LLMs to more languages
may bring many potential benefits, such as assisting cross-community
communication and language preservation, great care must be taken to ensure
that data collection on these languages is not extractive and that it does not
reproduce exploitative practices of the past. Collecting data from languages
spoken by previously colonized people, indigenous people, and non-Western
languages raises many complex sociopolitical and ethical questions, e.g.,
around consent, cultural safety, and data sovereignty. Furthermore, linguistic
complexity and cultural nuances are often lost in LLMs. This position paper
builds on recent scholarship, and our own work, and outlines several relevant
social, cultural, and ethical considerations and potential ways to mitigate
them through qualitative research, community partnerships, and participatory
design approaches. We provide twelve recommendations for consideration when
collecting language data on underrepresented language communities outside of
the Global North.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Intrinsic Language-specific Subspaces in Fine-tuning
  Multilingual Neural Machine Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05224v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05224v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhe Cao, Zhi Qu, Hidetaka Kamigaito, Taro Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilingual neural machine translation models support fine-tuning hundreds
of languages simultaneously. However, fine-tuning on full parameters solely is
inefficient potentially leading to negative interactions among languages. In
this work, we demonstrate that the fine-tuning for a language occurs in its
intrinsic language-specific subspace with a tiny fraction of entire parameters.
Thus, we propose language-specific LoRA to isolate intrinsic language-specific
subspaces. Furthermore, we propose architecture learning techniques and
introduce a gradual pruning schedule during fine-tuning to exhaustively explore
the optimal setting and the minimal intrinsic subspaces for each language,
resulting in a lightweight yet effective fine-tuning procedure. The
experimental results on a 12-language subset and a 30-language subset of
FLORES-101 show that our methods not only outperform full-parameter fine-tuning
up to 2.25 spBLEU scores but also reduce trainable parameters to $0.4\%$ for
high and medium-resource languages and $1.6\%$ for low-resource ones.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interactive Machine Teaching by Labeling Rules and Instances <span class="chip">ACL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05199v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05199v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giannis Karamanolakis, Daniel Hsu, Luis Gravano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Weakly supervised learning aims to reduce the cost of labeling data by using
expert-designed labeling rules. However, existing methods require experts to
design effective rules in a single shot, which is difficult in the absence of
proper guidance and tooling. Therefore, it is still an open question whether
experts should spend their limited time writing rules or instead providing
instance labels via active learning. In this paper, we investigate how to
exploit an expert's limited time to create effective supervision. First, to
develop practical guidelines for rule creation, we conduct an exploratory
analysis of diverse collections of existing expert-designed rules and find that
rule precision is more important than coverage across datasets. Second, we
compare rule creation to individual instance labeling via active learning and
demonstrate the importance of both across 6 datasets. Third, we propose an
interactive learning framework, INTERVAL, that achieves efficiency by
automatically extracting candidate rules based on rich patterns (e.g., by
prompting a language model), and effectiveness by soliciting expert feedback on
both candidate rules and individual instances. Across 6 datasets, INTERVAL
outperforms state-of-the-art weakly supervised approaches by 7% in F1.
Furthermore, it requires as few as 10 queries for expert feedback to reach F1
values that existing active learning methods cannot match even with 100
queries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to TACL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large
  Language Models Attentive Readers? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05197v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05197v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neeladri Bhuiya, Viktor Schlegel, Stefan Winkler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art Large Language Models (LLMs) are accredited with an
increasing number of different capabilities, ranging from reading
comprehension, over advanced mathematical and reasoning skills to possessing
scientific knowledge. In this paper we focus on their multi-hop reasoning
capability: the ability to identify and integrate information from multiple
textual sources.
  Given the concerns with the presence of simplifying cues in existing
multi-hop reasoning benchmarks, which allow models to circumvent the reasoning
requirement, we set out to investigate, whether LLMs are prone to exploiting
such simplifying cues. We find evidence that they indeed circumvent the
requirement to perform multi-hop reasoning, but they do so in more subtle ways
than what was reported about their fine-tuned pre-trained language model (PLM)
predecessors. Motivated by this finding, we propose a challenging multi-hop
reasoning benchmark, by generating seemingly plausible multi-hop reasoning
chains, which ultimately lead to incorrect answers. We evaluate multiple open
and proprietary state-of-the-art LLMs, and find that their performance to
perform multi-hop reasoning is affected, as indicated by up to 45% relative
decrease in F1 score when presented with such seemingly plausible alternatives.
We conduct a deeper analysis and find evidence that while LLMs tend to ignore
misleading lexical cues, misleading reasoning paths indeed present a
significant challenge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05152v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05152v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang, Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the recent advancements in Large Language Models (LLMs), which have
significantly enhanced the generative capabilities for various NLP tasks, LLMs
still face limitations in directly handling retrieval tasks. However, many
practical applications demand the seamless integration of both retrieval and
generation. This paper introduces a novel and efficient One-pass Generation and
retrieval framework (OneGen), designed to improve LLMs' performance on tasks
that require both generation and retrieval. The proposed framework bridges the
traditionally separate training approaches for generation and retrieval by
incorporating retrieval tokens generated autoregressively. This enables a
single LLM to handle both tasks simultaneously in a unified forward pass. We
conduct experiments on two distinct types of composite tasks, RAG and Entity
Linking, to validate the pluggability, effectiveness, and efficiency of OneGen
in training and inference. Furthermore, our results show that integrating
generation and retrieval within the same context preserves the generative
capabilities of LLMs while improving retrieval performance. To the best of our
knowledge, OneGen is the first to enable LLMs to conduct vector retrieval
during the generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress; code is available at
  https://github.com/zjunlp/OneGen</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Better Spanish Emotion Recognition In-the-wild: Bringing Attention to
  Deep Spectrum Voice Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elena Ortega-Beltrán, Josep Cabacas-Maso, Ismael Benito-Altamirano, Carles Ventura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Within the context of creating new Socially Assistive Robots, emotion
recognition has become a key development factor, as it allows the robot to
adapt to the user's emotional state in the wild. In this work, we focused on
the analysis of two voice recording Spanish datasets: ELRA-S0329 and
EmoMatchSpanishDB. Specifically, we centered our work in the paralanguage,
e.~g. the vocal characteristics that go along with the message and clarifies
the meaning. We proposed the use of the DeepSpectrum method, which consists of
extracting a visual representation of the audio tracks and feeding them to a
pretrained CNN model. For the classification task, DeepSpectrum is often paired
with a Support Vector Classifier --DS-SVC--, or a Fully-Connected deep-learning
classifier --DS-FC--. We compared the results of the DS-SVC and DS-FC
architectures with the state-of-the-art (SOTA) for ELRA-S0329 and
EmoMatchSpanishDB. Moreover, we proposed our own classifier based upon
Attention Mechanisms, namely DS-AM. We trained all models against both
datasets, and we found that our DS-AM model outperforms the SOTA models for the
datasets and the SOTA DeepSpectrum architectures. Finally, we trained our DS-AM
model in one dataset and tested it in the other, to simulate real-world
conditions on how biased is the model to the dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ READoc: A Unified Benchmark for Realistic Document Structured Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05137v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05137v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zichao Li, Aizier Abulaiti, Yaojie Lu, Xuanang Chen, Jia Zheng, Hongyu Lin, Xianpei Han, Le Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document Structured Extraction (DSE) aims to extract structured content from
raw documents. Despite the emergence of numerous DSE systems, their unified
evaluation remains inadequate, significantly hindering the field's advancement.
This problem is largely attributed to existing benchmark paradigms, which
exhibit fragmented and localized characteristics. To address these limitations
and offer a thorough evaluation of DSE systems, we introduce a novel benchmark
named READoc, which defines DSE as a realistic task of converting unstructured
PDFs into semantically rich Markdown. The READoc dataset is derived from 2,233
diverse and real-world documents from arXiv and GitHub. In addition, we develop
a DSE Evaluation S$^3$uite comprising Standardization, Segmentation and Scoring
modules, to conduct a unified evaluation of state-of-the-art DSE approaches. By
evaluating a range of pipeline tools, expert visual models, and general VLMs,
we identify the gap between current work and the unified, realistic DSE
objective for the first time. We aspire that READoc will catalyze future
research in DSE, fostering more comprehensive and practical solutions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MHS-STMA: Multimodal Hate Speech Detection via Scalable
  <span class="highlight-title">Transformer</span>-Based Multilevel Attention Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05136v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05136v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anusha Chhabra, Dinesh Kumar Vishwakarma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media has a significant impact on people's lives. Hate speech on
social media has emerged as one of society's most serious issues recently. Text
and pictures are two forms of multimodal data distributed within articles.
Unimodal analysis has been the primary emphasis of earlier approaches.
Additionally, when doing multimodal analysis, researchers neglect to preserve
the distinctive qualities associated with each modality. The present article
suggests a scalable architecture for multimodal hate content detection called
transformer-based multilevel attention (STMA) to address these shortcomings.
This architecture consists of three main parts: a combined attention-based deep
learning mechanism, a vision attention mechanism encoder, and a caption
attention-mechanism encoder. To identify hate content, each component uses
various attention processes and uniquely handles multimodal data. Several
studies employing multiple assessment criteria on three hate speech datasets:
Hateful memes, MultiOff, and MMHS150K, validate the suggested architecture's
efficacy. The outcomes demonstrate that on all three datasets, the suggested
strategy performs better than the baseline approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hate Content Detection via Novel Pre-Processing Sequencing and Ensemble
  Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05134v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05134v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anusha Chhabra, Dinesh Kumar Vishwakarma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social media, particularly Twitter, has seen a significant increase in
incidents like trolling and hate speech. Thus, identifying hate speech is the
need of the hour. This paper introduces a computational framework to curb the
hate content on the web. Specifically, this study presents an exhaustive study
of pre-processing approaches by studying the impact of changing the sequence of
text pre-processing operations for the identification of hate content. The
best-performing pre-processing sequence, when implemented with popular
classification approaches like Support Vector Machine, Random Forest, Decision
Tree, Logistic Regression and K-Neighbor provides a considerable boost in
performance. Additionally, the best pre-processing sequence is used in
conjunction with different ensemble methods, such as bagging, boosting and
stacking to improve the performance further. Three publicly available benchmark
datasets (WZ-LS, DT, and FOUNTA), were used to evaluate the proposed approach
for hate speech identification. The proposed approach achieves a maximum
accuracy of 95.14% highlighting the effectiveness of the unique pre-processing
approach along with an ensemble classifier.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Knowledge-Aware Conversation Derailment Forecasting Using Graph
  Convolutional Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13440v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13440v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Enas Altarawneh, Ameeta Agrawal, Michael Jenkin, Manos Papagelis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online conversations are particularly susceptible to derailment, which can
manifest itself in the form of toxic communication patterns including
disrespectful comments and abuse. Forecasting conversation derailment predicts
signs of derailment in advance enabling proactive moderation of conversations.
State-of-the-art approaches to conversation derailment forecasting sequentially
encode conversations and use graph neural networks to model dialogue user
dynamics. However, existing graph models are not able to capture complex
conversational characteristics such as context propagation and emotional
shifts. The use of common sense knowledge enables a model to capture such
characteristics, thus improving performance. Following this approach, here we
derive commonsense statements from a knowledge base of dialogue contextual
information to enrich a graph neural network classification architecture. We
fuse the multi-source information on utterance into capsules, which are used by
a transformer-based forecaster to predict conversation derailment. Our model
captures conversation dynamics and context propagation, outperforming the
state-of-the-art models on the CGA and CMV benchmark datasets
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2306.12982;
  text overlap with arXiv:2106.01071 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-Reflection in LLM Agents: Effects on Problem-Solving Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06682v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06682v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthew Renze, Erhan Guven
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we investigated the effects of self-reflection in large
language models (LLMs) on problem-solving performance. We instructed nine
popular LLMs to answer a series of multiple-choice questions to provide a
performance baseline. For each incorrectly answered question, we instructed
eight types of self-reflecting LLM agents to reflect on their mistakes and
provide themselves with guidance to improve problem-solving. Then, using this
guidance, each self-reflecting agent attempted to re-answer the same questions.
Our results indicate that LLM agents are able to significantly improve their
problem-solving performance through self-reflection ($p < 0.001$). In addition,
we compared the various types of self-reflection to determine their individual
contribution to performance. All code and data are available on GitHub at
https://github.com/matthewrenze/self-reflection
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ProGRes: <span class="highlight-title">Prompt</span>ed Generative Rescoring on ASR n-Best 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00217v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00217v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ada Defne Tur, Adel Moumen, Mirco Ravanelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown their ability to improve the
performance of speech recognizers by effectively rescoring the n-best
hypotheses generated during the beam search process. However, the best way to
exploit recent generative instruction-tuned LLMs for hypothesis rescoring is
still unclear. This paper proposes a novel method that uses instruction-tuned
LLMs to dynamically expand the n-best speech recognition hypotheses with new
hypotheses generated through appropriately-prompted LLMs. Specifically, we
introduce a new zero-shot method for ASR n-best rescoring, which combines
confidence scores, LLM sequence scoring, and prompt-based hypothesis
generation. We compare Llama-3-Instruct, GPT-3.5 Turbo, and GPT-4 Turbo as
prompt-based generators with Llama-3 as sequence scorer LLM. We evaluated our
approach using different speech recognizers and observed significant relative
improvement in the word error rate (WER) ranging from 5% to 25%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE Spoken Language Technology Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Using LLMs to Establish Implicit User Sentiment of Software Desirability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01527v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01527v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sherri Weitl-Harms, John D. Hastings, Jonah Lum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores the use of LLMs for providing quantitative zero-shot
sentiment analysis of implicit software desirability, addressing a critical
challenge in product evaluation where traditional review scores, though
convenient, fail to capture the richness of qualitative user feedback.
Innovations include establishing a method that 1) works with qualitative user
experience data without the need for explicit review scores, 2) focuses on
implicit user satisfaction, and 3) provides scaled numerical sentiment
analysis, offering a more nuanced understanding of user sentiment, instead of
simply classifying sentiment as positive, neutral, or negative.
  Data is collected using the Microsoft Product Desirability Toolkit (PDT), a
well-known qualitative user experience analysis tool. For initial exploration,
the PDT metric was given to users of two software systems. PDT data was fed
through several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a
leading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader,
a leading sentiment analysis tool. Each system was asked to evaluate the data
in two ways, by looking at the sentiment expressed in the PDT word/explanation
pairs; and by looking at the sentiment expressed by the users in their grouped
selection of five words and explanations, as a whole. Each LLM provided a
sentiment score, its confidence (low, medium, high) in the score, and an
explanation of the score.
  All LLMs tested were able to statistically detect user sentiment from the
users' grouped data, whereas TRBS and Vader were not. The confidence and
explanation of confidence provided by the LLMs assisted in understanding user
sentiment. This study adds deeper understanding of evaluating user experiences,
toward the goal of creating a universal tool that quantifies implicit
sentiment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures, 2 tables, updated to incorporate feedback</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fact-and-Reflection (FaR) Improves Confidence Calibration of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17124v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17124v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinran Zhao, Hongming Zhang, Xiaoman Pan, Wenlin Yao, Dong Yu, Tongshuang Wu, Jianshu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For a LLM to be trustworthy, its confidence level should be well-calibrated
with its actual performance. While it is now common sense that LLM performances
are greatly impacted by prompts, the confidence calibration in prompting LLMs
has yet to be thoroughly explored. In this paper, we explore how different
prompting strategies influence LLM confidence calibration and how it could be
improved. We conduct extensive experiments on six prompting methods in the
question-answering context and we observe that, while these methods help
improve the expected LLM calibration, they also trigger LLMs to be
over-confident when responding to some instances. Inspired by human cognition,
we propose Fact-and-Reflection (FaR) prompting, which improves the LLM
calibration in two steps. First, FaR elicits the known "facts" that are
relevant to the input prompt from the LLM. And then it asks the model to
"reflect" over them to generate the final answer. Experiments show that FaR
prompting achieves significantly better calibration; it lowers the Expected
Calibration Error by 23.5% on our multi-purpose QA tasks. Notably, FaR
prompting even elicits the capability of verbally expressing concerns in less
confident scenarios, which helps trigger retrieval augmentation for solving
these harder instances.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SS-GEN: A Social Story Generation Framework with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15695v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15695v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Feng, Mingyang Song, Jiaqi Wang, Zhuang Chen, Guanqun Bi, Minlie Huang, Liping Jing, Jian Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Children with Autism Spectrum Disorder (ASD) often misunderstand social
situations and struggle to participate in daily routines. Social Stories are
traditionally crafted by psychology experts under strict constraints to address
these challenges but are costly and limited in diversity. As Large Language
Models (LLMs) advance, there's an opportunity to develop more automated,
affordable, and accessible methods to generate Social Stories in real-time with
broad coverage. However, adapting LLMs to meet the unique and strict
constraints of Social Stories is a challenging issue. To this end, we propose
\textbf{SS-GEN}, a \textbf{S}ocial \textbf{S}tory \textbf{GEN}eration framework
with LLMs. Firstly, we develop a constraint-driven sophisticated strategy named
\textbf{\textsc{StarSow}} to hierarchically prompt LLMs to generate Social
Stories at scale, followed by rigorous human filtering to build a high-quality
dataset. Additionally, we introduce \textbf{quality assessment criteria} to
evaluate the effectiveness of these generated stories. Considering that
powerful closed-source large models require very complex instructions and
expensive API fees, we finally fine-tune smaller language models with our
curated high-quality dataset, achieving comparable results at lower costs and
with simpler instruction and deployment. This work marks a significant step in
leveraging AI to personalize Social Stories cost-effectively for autistic
children at scale, which we hope can encourage future research. The prompt,
code and data will release in the \texttt{Technical Appendix} and \texttt{Code
\& Data Appendix} at \url{https://github.com/MIMIFY/SS-GEN}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Predictability maximization and the origins of word order harmony 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16570v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16570v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ramon Ferrer-i-Cancho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the linguistic problem of the sequential arrangement of a head and
its dependents from an information theoretic perspective. In particular, we
consider the optimal placement of a head that maximizes the predictability of
the sequence. We assume that dependents are statistically independent given a
head, in line with the open-choice principle and the core assumptions of
dependency grammar. We demonstrate the optimality of harmonic order, i.e.,
placing the head last maximizes the predictability of the head whereas placing
the head first maximizes the predictability of dependents. We also show that
postponing the head is the optimal strategy to maximize its predictability
while bringing it forward is the optimal strategy to maximize the
predictability of dependents. We unravel the advantages of the strategy of
maximizing the predictability of the head over maximizing the predictability of
dependents. Our findings shed light on the placements of the head adopted by
real languages or emerging in different kinds of experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Local reorganization of the text; many typos corrected</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data Alignment for Zero-Shot Concept Generation in Dermatology AI <span class="chip">ICLR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13043v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13043v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soham Gadgil, Mahtab Bigverdi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  AI in dermatology is evolving at a rapid pace but the major limitation to
training trustworthy classifiers is the scarcity of data with ground-truth
concept level labels, which are meta-labels semantically meaningful to humans.
Foundation models like CLIP providing zero-shot capabilities can help alleviate
this challenge by leveraging vast amounts of image-caption pairs available on
the internet. CLIP can be fine-tuned using domain specific image-caption pairs
to improve classification performance. However, CLIP's pre-training data is not
well-aligned with the medical jargon that clinicians use to perform diagnoses.
The development of large language models (LLMs) in recent years has led to the
possibility of leveraging the expressive nature of these models to generate
rich text. Our goal is to use these models to generate caption text that aligns
well with both the clinical lexicon and with the natural human language used in
CLIP's pre-training data. Starting with captions used for images in PubMed
articles, we extend them by passing the raw captions through an LLM fine-tuned
on the field's several textbooks. We find that using captions generated by an
expressive fine-tuned LLM like GPT-3.5 improves downstream zero-shot concept
classification performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a workshop paper to ICLR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distributed Speculative Inference of Large Language Models is Provably
  Faster 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14105v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14105v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Moshe Wasserblat, Tomer Galanti, Michal Gordon, David Harel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accelerating the inference of large language models (LLMs) is an important
challenge in artificial intelligence. This paper introduces Distributed
Speculative Inference (DSI), a novel distributed inference algorithm that is
provably faster than speculative inference (SI)
[leviathan2023fast,chen2023accelerating,miao2023specinfer] and traditional
autoregressive inference (non-SI). Like other SI algorithms, DSI works on
frozen LLMs, requiring no training or architectural modifications, and it
preserves the target distribution. Prior studies on SI have demonstrated
empirical speedups (compared to non-SI) but require fast and accurate drafters,
which are often unavailable in practice. We identify a gap where SI can be
slower than non-SI given slower or less accurate drafters. We close this gap by
proving that DSI is faster than both SI and non-SI--given any drafters. DSI
introduces a novel type of task parallelism called Speculation Parallelism
(SP), which orchestrates target and drafter instances to overlap in time,
creating a new foundational tradeoff between computational resources and
latency. DSI is not only faster than SI but also supports LLMs that cannot be
accelerated with SI. Our simulations show speedups of off-the-shelf LLMs in
realistic single-node settings where DSI is 1.29-1.92x faster than SI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GEGA: Graph Convolutional Networks and Evidence Retrieval Guided
  Attention for Enhanced Document-level Relation Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.21384v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.21384v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanxu Mao, Xiaohui Chen, Peipei Liu, Tiehan Cui, Zuhui Yue, Zheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document-level relation extraction (DocRE) aims to extract relations between
entities from unstructured document text. Compared to sentence-level relation
extraction, it requires more complex semantic understanding from a broader text
context. Currently, some studies are utilizing logical rules within evidence
sentences to enhance the performance of DocRE. However, in the data without
provided evidence sentences, researchers often obtain a list of evidence
sentences for the entire document through evidence retrieval (ER). Therefore,
DocRE suffers from two challenges: firstly, the relevance between evidence and
entity pairs is weak; secondly, there is insufficient extraction of complex
cross-relations between long-distance multi-entities. To overcome these
challenges, we propose GEGA, a novel model for DocRE. The model leverages graph
neural networks to construct multiple weight matrices, guiding attention
allocation to evidence sentences. It also employs multi-scale representation
aggregation to enhance ER. Subsequently, we integrate the most efficient
evidence information to implement both fully supervised and weakly supervised
training processes for the model. We evaluate the GEGA model on three widely
used benchmark datasets: DocRED, Re-DocRED, and Revisit-DocRED. The
experimental results indicate that our model has achieved comprehensive
improvements compared to the existing SOTA model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05965v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05965v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yibo Miao, Yifan Zhu, Yinpeng Dong, Lijia Yu, Jun Zhu, Xiao-Shan Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent development of Sora leads to a new era in text-to-video (T2V)
generation. Along with this comes the rising concern about its security risks.
The generated videos may contain illegal or unethical content, and there is a
lack of comprehensive quantitative understanding of their safety, posing a
challenge to their reliability and practical deployment. Previous evaluations
primarily focus on the quality of video generation. While some evaluations of
text-to-image models have considered safety, they cover fewer aspects and do
not address the unique temporal risk inherent in video generation. To bridge
this research gap, we introduce T2VSafetyBench, a new benchmark designed for
conducting safety-critical assessments of text-to-video models. We define 12
critical aspects of video generation safety and construct a malicious prompt
dataset including real-world prompts, LLM-generated prompts and jailbreak
attack-based prompts. Based on our evaluation results, we draw several
important findings, including: 1) no single model excels in all aspects, with
different models showing various strengths; 2) the correlation between GPT-4
assessments and manual reviews is generally high; 3) there is a trade-off
between the usability and safety of text-to-video generative models. This
indicates that as the field of video generation rapidly advances, safety risks
are set to surge, highlighting the urgency of prioritizing video safety. We
hope that T2VSafetyBench can provide insights for better understanding the
safety of video generation in the era of generative AI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ No Train but Gain: Language Arithmetic for training-free Language
  Adapters enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15737v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15737v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mateusz Klimaszewski, Piotr Andruszkiewicz, Alexandra Birch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modular deep learning is the state-of-the-art solution for lifting the curse
of multilinguality, preventing the impact of negative interference and enabling
cross-lingual performance in Multilingual Pre-trained Language Models. However,
a trade-off of this approach is the reduction in positive transfer learning
from closely related languages. In response, we introduce a novel method called
language arithmetic, which enables training-free post-processing to address
this limitation. Extending the task arithmetic framework, we apply learning via
addition to the language adapters, transitioning the framework from a
multi-task to a multilingual setup. The effectiveness of the proposed solution
is demonstrated on three downstream tasks in a MAD-X-based set of cross-lingual
schemes, acting as a post-processing procedure. Language arithmetic
consistently improves the baselines with significant gains, especially in the
most challenging case of zero-shot application. Our code and models are
available at https://github.com/mklimasz/language-arithmetic .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DSLR: Document Refinement with Sentence-Level Re-ranking and
  Reconstruction to Enhance Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03627v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03627v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taeho Hwang, Soyeong Jeong, Sukmin Cho, SeungYoon Han, Jong C. Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have significantly
improved their performance across various Natural Language Processing (NLP)
tasks. However, LLMs still struggle with generating non-factual responses due
to limitations in their parametric memory. Retrieval-Augmented Generation (RAG)
systems address this issue by incorporating external knowledge with a retrieval
module. Despite their successes, however, current RAG systems face challenges
with retrieval failures and the limited ability of LLMs to filter out
irrelevant information. Therefore, in this work, we propose DSLR (Document
Refinement with Sentence-Level Re-ranking and Reconstruction), an unsupervised
framework that decomposes retrieved documents into sentences, filters out
irrelevant sentences, and reconstructs them again into coherent passages. We
experimentally validate DSLR on multiple open-domain QA datasets and the
results demonstrate that DSLR significantly enhances the RAG performance over
conventional fixed-size passage. Furthermore, our DSLR enhances performance in
specific, yet realistic scenarios without the need for additional training,
providing an effective and efficient solution for refining retrieved documents
in RAG systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05152v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05152v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang, Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the recent advancements in Large Language Models (LLMs), which have
significantly enhanced the generative capabilities for various NLP tasks, LLMs
still face limitations in directly handling retrieval tasks. However, many
practical applications demand the seamless integration of both retrieval and
generation. This paper introduces a novel and efficient One-pass Generation and
retrieval framework (OneGen), designed to improve LLMs' performance on tasks
that require both generation and retrieval. The proposed framework bridges the
traditionally separate training approaches for generation and retrieval by
incorporating retrieval tokens generated autoregressively. This enables a
single LLM to handle both tasks simultaneously in a unified forward pass. We
conduct experiments on two distinct types of composite tasks, RAG and Entity
Linking, to validate the pluggability, effectiveness, and efficiency of OneGen
in training and inference. Furthermore, our results show that integrating
generation and retrieval within the same context preserves the generative
capabilities of LLMs while improving retrieval performance. To the best of our
knowledge, OneGen is the first to enable LLMs to conduct vector retrieval
during the generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress; code is available at
  https://github.com/zjunlp/OneGen</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Diffusion Models for Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05033v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05033v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianghao Lin, Jiaqi Liu, Jiachen Zhu, Yunjia Xi, Chengkai Liu, Yangtian Zhang, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While traditional recommendation techniques have made significant strides in
the past decades, they still suffer from limited generalization performance
caused by factors like inadequate collaborative signals, weak latent
representations, and noisy data. In response, diffusion models (DMs) have
emerged as promising solutions for recommender systems due to their robust
generative capabilities, solid theoretical foundations, and improved training
stability. To this end, in this paper, we present the first comprehensive
survey on diffusion models for recommendation, and draw a bird's-eye view from
the perspective of the whole pipeline in real-world recommender systems. We
systematically categorize existing research works into three primary domains:
(1) diffusion for data engineering & encoding, focusing on data augmentation
and representation enhancement; (2) diffusion as recommender models, employing
diffusion models to directly estimate user preferences and rank items; and (3)
diffusion for content presentation, utilizing diffusion models to generate
personalized content such as fashion and advertisement creatives. Our taxonomy
highlights the unique strengths of diffusion models in capturing complex data
distributions and generating high-quality, diverse samples that closely align
with user preferences. We also summarize the core characteristics of the
adapting diffusion models for recommendation, and further identify key areas
for future exploration, which helps establish a roadmap for researchers and
practitioners seeking to advance recommender systems through the innovative
application of diffusion models. To further facilitate the research community
of recommender systems based on diffusion models, we actively maintain a GitHub
repository for papers and other related resources in this rising direction
https://github.com/CHIANGEL/Awesome-Diffusion-for-RecSys.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sequential Recommendation via Adaptive Robust Attention with
  Multi-dimensional Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05022v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05022v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linsey Pang, Amir Hossein Raffiee, Wei Liu, Keld Lundgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation models have achieved state-of-the-art performance
using self-attention mechanism. It has since been found that moving beyond only
using item ID and positional embeddings leads to a significant accuracy boost
when predicting the next item. In recent literature, it was reported that a
multi-dimensional kernel embedding with temporal contextual kernels to capture
users' diverse behavioral patterns results in a substantial performance
improvement. In this study, we further improve the sequential recommender
model's robustness and generalization by introducing a mix-attention mechanism
with a layer-wise noise injection (LNI) regularization. We refer to our
proposed model as adaptive robust sequential recommendation framework (ADRRec),
and demonstrate through extensive experiments that our model outperforms
existing self-attention architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Keyword-driven Retrieval-Augmented Large Language Models for Cold-start
  User Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19612v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19612v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hai-Dang Kieu, Minh Duc Nguyen, Thanh-Son Nguyen, Dung D. Le
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have shown significant
potential in enhancing recommender systems. However, addressing the cold-start
recommendation problem, where users lack historical data, remains a
considerable challenge. In this paper, we introduce KALM4Rec (Keyword-driven
Retrieval-Augmented Large Language Models for Cold-start User Recommendations),
a novel framework specifically designed to tackle this problem by requiring
only a few input keywords from users in a practical scenario of cold-start user
restaurant recommendations. KALM4Rec operates in two main stages: candidates
retrieval and LLM-based candidates re-ranking. In the first stage,
keyword-driven retrieval models are used to identify potential candidates,
addressing LLMs' limitations in processing extensive tokens and reducing the
risk of generating misleading information. In the second stage, we employ LLMs
with various prompting strategies, including zero-shot and few-shot techniques,
to re-rank these candidates by integrating multiple examples directly into the
LLM prompts. Our evaluation, using a Yelp restaurant dataset with user reviews
from three English-speaking cities, shows that our proposed framework
significantly improves recommendation quality. Specifically, the integration of
in-context instructions with LLMs for re-ranking markedly enhances the
performance of the cold-start user recommender system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 10 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DREAM: A Dual Representation Learning Model for Multimodal
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangning Zhang, Yingjie Qin, Jiarui Jin, Yifan Liu, Ruilong Su, Weinan Zhang, Yong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal recommendation focuses primarily on effectively exploiting both
behavioral and multimodal information for the recommendation task. However,
most existing models suffer from the following issues when fusing information
from two different domains: (1) Previous works do not pay attention to the
sufficient utilization of modal information by only using direct concatenation,
addition, or simple linear layers for modal information extraction. (2)
Previous works treat modal features as learnable embeddings, which causes the
modal embeddings to gradually deviate from the original modal features during
learning. We refer to this issue as Modal Information Forgetting. (3) Previous
approaches fail to account for the significant differences in the distribution
between behavior and modality, leading to the issue of representation
misalignment. To address these challenges, this paper proposes a novel Dual
REpresentAtion learning model for Multimodal Recommendation called DREAM. For
sufficient information extraction, we introduce separate dual lines, including
Behavior Line and Modal Line, in which the Modal-specific Encoder is applied to
empower modal representations. To address the issue of Modal Information
Forgetting, we introduce the Similarity Supervised Signal to constrain the
modal representations. Additionally, we design a Behavior-Modal Alignment
module to fuse the dual representations through Intra-Alignment and
Inter-Alignment. Extensive experiments on three public datasets demonstrate
that the proposed DREAM method achieves state-of-the-art (SOTA) results. The
source code will be available upon acceptance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Visual Grounding with Multi-modal Conditional Adaptation <span class="chip">ACM MM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04999v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04999v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruilin Yao, Shengwu Xiong, Yichen Zhao, Yi Rong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual grounding is the task of locating objects specified by natural
language expressions. Existing methods extend generic object detection
frameworks to tackle this task. They typically extract visual and textual
features separately using independent visual and textual encoders, then fuse
these features in a multi-modal decoder for final prediction. However, visual
grounding presents unique challenges. It often involves locating objects with
different text descriptions within the same image. Existing methods struggle
with this task because the independent visual encoder produces identical visual
features for the same image, limiting detection performance. Some recently
approaches propose various language-guided visual encoders to address this
issue, but they mostly rely solely on textual information and require
sophisticated designs. In this paper, we introduce Multi-modal Conditional
Adaptation (MMCA), which enables the visual encoder to adaptively update
weights, directing its focus towards text-relevant regions. Specifically, we
first integrate information from different modalities to obtain multi-modal
embeddings. Then we utilize a set of weighting coefficients, which generated
from the multimodal embeddings, to reorganize the weight update matrices and
apply them to the visual encoder of the visual grounding model. Extensive
experiments on four widely used datasets demonstrate that MMCA achieves
significant improvements and state-of-the-art results. Ablation experiments
further demonstrate the lightweight and efficiency of our method. Our source
code is available at: https://github.com/Mr-Bigworth/MMCA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM MM 2024 [Oral]</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes <span class="chip">ICIP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03336v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03336v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junpei Honma, Akisato Kimura, Go Irie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Measuring 3D geometric structures of indoor scenes requires dedicated depth
sensors, which are not always available. Echo-based depth estimation has
recently been studied as a promising alternative solution. All previous studies
have assumed the use of echoes in the audible range. However, one major problem
is that audible echoes cannot be used in quiet spaces or other situations where
producing audible sounds is prohibited. In this paper, we consider echo-based
depth estimation using inaudible ultrasonic echoes. While ultrasonic waves
provide high measurement accuracy in theory, the actual depth estimation
accuracy when ultrasonic echoes are used has remained unclear, due to its
disadvantage of being sensitive to noise and susceptible to attenuation. We
first investigate the depth estimation accuracy when the frequency of the sound
source is restricted to the high-frequency band, and found that the accuracy
decreased when the frequency was limited to ultrasonic ranges. Based on this
observation, we propose a novel deep learning method to improve the accuracy of
ultrasonic echo-based depth estimation by using audible echoes as auxiliary
data only during training. Experimental results with a public dataset
demonstrate that our method improves the estimation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICIP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FakeBench: Probing Explainable Fake Image Detection via Large Multimodal
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13306v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13306v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixuan Li, Xuelin Liu, Xiaoyang Wang, Bu Sung Lee, Shiqi Wang, Anderson Rocha, Weisi Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to distinguish whether an image is generated by artificial
intelligence (AI) is a crucial ingredient in human intelligence, usually
accompanied by a complex and dialectical forensic and reasoning process.
However, current fake image detection models and databases focus on binary
classification without understandable explanations for the general populace.
This weakens the credibility of authenticity judgment and may conceal potential
model biases. Meanwhile, large multimodal models (LMMs) have exhibited immense
visual-text capabilities on various tasks, bringing the potential for
explainable fake image detection. Therefore, we pioneer the probe of LMMs for
explainable fake image detection by presenting a multimodal database
encompassing textual authenticity descriptions, the FakeBench. For
construction, we first introduce a fine-grained taxonomy of generative visual
forgery concerning human perception, based on which we collect forgery
descriptions in human natural language with a human-in-the-loop strategy.
FakeBench examines LMMs with four evaluation criteria: detection, reasoning,
interpretation and fine-grained forgery analysis, to obtain deeper insights
into image authenticity-relevant capabilities. Experiments on various LMMs
confirm their merits and demerits in different aspects of fake image detection
tasks. This research presents a paradigm shift towards transparency for the
fake image detection area and reveals the need for greater emphasis on forensic
elements in visual-language research and AI risk control. FakeBench will be
available at https://github.com/Yixuan423/FakeBench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DREAM: A Dual Representation Learning Model for Multimodal
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangning Zhang, Yingjie Qin, Jiarui Jin, Yifan Liu, Ruilong Su, Weinan Zhang, Yong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal recommendation focuses primarily on effectively exploiting both
behavioral and multimodal information for the recommendation task. However,
most existing models suffer from the following issues when fusing information
from two different domains: (1) Previous works do not pay attention to the
sufficient utilization of modal information by only using direct concatenation,
addition, or simple linear layers for modal information extraction. (2)
Previous works treat modal features as learnable embeddings, which causes the
modal embeddings to gradually deviate from the original modal features during
learning. We refer to this issue as Modal Information Forgetting. (3) Previous
approaches fail to account for the significant differences in the distribution
between behavior and modality, leading to the issue of representation
misalignment. To address these challenges, this paper proposes a novel Dual
REpresentAtion learning model for Multimodal Recommendation called DREAM. For
sufficient information extraction, we introduce separate dual lines, including
Behavior Line and Modal Line, in which the Modal-specific Encoder is applied to
empower modal representations. To address the issue of Modal Information
Forgetting, we introduce the Similarity Supervised Signal to constrain the
modal representations. Additionally, we design a Behavior-Modal Alignment
module to fuse the dual representations through Intra-Alignment and
Inter-Alignment. Extensive experiments on three public datasets demonstrate
that the proposed DREAM method achieves state-of-the-art (SOTA) results. The
source code will be available upon acceptance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-07T00:00:00Z">2024-09-07</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">9</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Incorporate LLMs with Influential Recommender System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04827v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04827v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingze Wang, Shuxian Bi, Wenjie Wang, Chongming Gao, Yangyang Li, Fuli Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems have achieved increasing accuracy over the years.
However, this precision often leads users to narrow their interests, resulting
in issues such as limited diversity and the creation of echo chambers. Current
research addresses these challenges through proactive recommender systems by
recommending a sequence of items (called influence path) to guide user interest
in the target item. However, existing methods struggle to construct a coherent
influence path that builds up with items the user is likely to enjoy. In this
paper, we leverage the Large Language Model's (LLMs) exceptional ability for
path planning and instruction following, introducing a novel approach named
LLM-based Influence Path Planning (LLM-IPP). Our approach maintains coherence
between consecutive recommendations and enhances user acceptability of the
recommended items. To evaluate LLM-IPP, we implement various user simulators
and metrics to measure user acceptability and path coherence. Experimental
results demonstrate that LLM-IPP significantly outperforms traditional
proactive recommender systems. This study pioneers the integration of LLMs into
proactive recommender systems, offering a reliable and user-engaging
methodology for future recommendation technologies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Debias Can be Unreliable: Mitigating Bias Issue in Evaluating Debiasing
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04810v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04810v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengbing Wang, Wentao Shi, Jizhi Zhang, Wenjie Wang, Hang Pan, Fuli Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work has improved recommendation models remarkably by equipping them
with debiasing methods. Due to the unavailability of fully-exposed datasets,
most existing approaches resort to randomly-exposed datasets as a proxy for
evaluating debiased models, employing traditional evaluation scheme to
represent the recommendation performance. However, in this study, we reveal
that traditional evaluation scheme is not suitable for randomly-exposed
datasets, leading to inconsistency between the Recall performance obtained
using randomly-exposed datasets and that obtained using fully-exposed datasets.
Such inconsistency indicates the potential unreliability of experiment
conclusions on previous debiasing techniques and calls for unbiased Recall
evaluation using randomly-exposed datasets. To bridge the gap, we propose the
Unbiased Recall Evaluation (URE) scheme, which adjusts the utilization of
randomly-exposed datasets to unbiasedly estimate the true Recall performance on
fully-exposed datasets. We provide theoretical evidence to demonstrate the
rationality of URE and perform extensive experiments on real-world datasets to
validate its soundness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04701v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04701v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Günther, Isabelle Mohr, Bo Wang, Han Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many use cases require retrieving smaller portions of text, and dense
vector-based retrieval systems often perform better with shorter text segments,
as the semantics are less likely to be "over-compressed" in the embeddings.
Consequently, practitioners often split text documents into smaller chunks and
encode them separately. However, chunk embeddings created in this way can lose
contextual information from surrounding chunks, resulting in suboptimal
representations. In this paper, we introduce a novel method called "late
chunking," which leverages long context embedding models to first embed all
tokens of the long text, with chunking applied after the transformer model and
just before mean pooling. The resulting chunk embeddings capture the full
contextual information, leading to superior results across various retrieval
tasks without the need for additional training. Moreover, our method is generic
enough to be applied to any long-context embedding model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, early draft</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CoST: Contrastive Quantization based Semantic Tokenization for
  Generative Recommendation <span class="chip">RecSys'2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jieming Zhu, Mengqun Jin, Qijiong Liu, Zexuan Qiu, Zhenhua Dong, Xiu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embedding-based retrieval serves as a dominant approach to candidate item
matching for industrial recommender systems. With the success of generative AI,
generative retrieval has recently emerged as a new retrieval paradigm for
recommendation, which casts item retrieval as a generation problem. Its model
consists of two stages: semantic tokenization and autoregressive generation.
The first stage involves item tokenization that constructs discrete semantic
tokens to index items, while the second stage autoregressively generates
semantic tokens of candidate items. Therefore, semantic tokenization serves as
a crucial preliminary step for training generative recommendation models.
Existing research usually employs a vector quantizier with reconstruction loss
(e.g., RQ-VAE) to obtain semantic tokens of items, but this method fails to
capture the essential neighborhood relationships that are vital for effective
item modeling in recommender systems. In this paper, we propose a contrastive
quantization-based semantic tokenization approach, named CoST, which harnesses
both item relationships and semantic information to learn semantic tokens. Our
experimental results highlight the significant impact of semantic tokenization
on generative recommendation performance, with CoST achieving up to a 43%
improvement in Recall@5 and 44% improvement in NDCG@5 on the MIND dataset over
previous baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by RecSys'2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Implementing Streaming algorithm and k-means clusters to RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.21300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.21300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoyu Kang, Yuzhou Zhu, Yukun Zhong, Ke Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has achieved significant success in
information retrieval to assist large language models LLMs because it builds an
external knowledge database. However, it also has many problems, it consumes a
lot of memory because of the enormous database, and it cannot update the
established index database in time when confronted with massive streaming data.
To reduce the memory required for building the database and maintain accuracy
simultaneously, we proposed a new approach integrating a streaming algorithm
with k-means clustering into RAG. Our approach applied a streaming algorithm to
update the index dynamically and reduce memory consumption. Additionally, the
k-means algorithm clusters highly similar documents, and the query time would
be shortened. We conducted comparative experiments on four methods, and the
results indicated that RAG with streaming algorithm and k-means clusters
outperforms traditional RAG in accuracy and memory, particularly when dealing
with large-scale streaming data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video Editing for Video Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02335v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02335v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Zhu, Kevin Flanagan, Adriano Fragomeni, Michael Wray, Dima Damen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Though pre-training vision-language models have demonstrated significant
benefits in boosting video-text retrieval performance from large-scale web
videos, fine-tuning still plays a critical role with manually annotated clips
with start and end times, which requires considerable human effort. To address
this issue, we explore an alternative cheaper source of annotations, single
timestamps, for video-text retrieval. We initialise clips from timestamps in a
heuristic way to warm up a retrieval model. Then a video clip editing method is
proposed to refine the initial rough boundaries to improve retrieval
performance. A student-teacher network is introduced for video clip editing.
The teacher model is employed to edit the clips in the training set whereas the
student model trains on the edited clips. The teacher weights are updated from
the student's after the student's performance increases. Our method is model
agnostic and applicable to any retrieval models. We conduct experiments based
on three state-of-the-art retrieval models, COOT, VideoCLIP and CLIP4Clip.
Experiments conducted on three video retrieval datasets, YouCook2, DiDeMo and
ActivityNet-Captions show that our edited clips consistently improve retrieval
performance over initial clips across all the three retrieval models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reformulating Conversational Recommender Systems as Tri-Phase Offline
  Policy Learning <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06809v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06809v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gangyi Zhang, Chongming Gao, Hang Pan, Runzhe Teng, Ruizhe Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing Conversational Recommender Systems (CRS) predominantly utilize user
simulators for training and evaluating recommendation policies. These
simulators often oversimplify the complexity of user interactions by focusing
solely on static item attributes, neglecting the rich, evolving preferences
that characterize real-world user behavior. This limitation frequently leads to
models that perform well in simulated environments but falter in actual
deployment. Addressing these challenges, this paper introduces the Tri-Phase
Offline Policy Learning-based Conversational Recommender System (TCRS), which
significantly reduces dependency on real-time interactions and mitigates
overfitting issues prevalent in traditional approaches. TCRS integrates a
model-based offline learning strategy with a controllable user simulation that
dynamically aligns with both personalized and evolving user preferences.
Through comprehensive experiments, TCRS demonstrates enhanced robustness,
adaptability, and accuracy in recommendations, outperforming traditional CRS
models in diverse user scenarios. This approach not only provides a more
realistic evaluation environment but also facilitates a deeper understanding of
user behavior dynamics, thereby refining the recommendation process.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Tree-based Retrieval for Efficient Recommendation: Theory and
  Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11345v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11345v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ze Liu, Jin Zhang, Chao Feng, Defu Lian, Jie Wang, Enhong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the development of deep learning techniques, deep recommendation models
also achieve remarkable improvements in terms of recommendation accuracy.
However, due to the large number of candidate items in practice and the high
cost of preference computation, these methods also suffer from low efficiency
of recommendation. The recently proposed tree-based deep recommendation models
alleviate the problem by directly learning tree structure and representations
under the guidance of recommendation objectives. However, such models have
shortcomings. The max-heap assumption in the hierarchical tree, in which the
preference for a parent node should be the maximum between the preferences for
its children, is difficult to satisfy in their binary classification
objectives. To this end, we propose Tree-based Deep Retrieval (TDR for short)
for efficient recommendation. In TDR, all the trees generated during the
training process are retained to form the forest. When learning the node
representation of each tree, we have to satisfy the max-heap assumption as much
as possible and mimic beam search behavior over the tree in the training stage.
This is achieved by TDR to regard the training task as multi-classification
over tree nodes at the same level. However, the number of tree nodes grows
exponentially with levels, making us train the preference model with the
guidance of the sampled-softmax technique. The experiments are conducted on
real-world datasets, validating the effectiveness of the proposed preference
model learning method and tree learning method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ YouTube Videos for Public Health Literacy? A Machine Learning Pipeline
  to Curate Covid-19 Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.09425v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.09425v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yawen Guo, Xiao Liu, Anjana Susarla, Rema Padman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The COVID-19 pandemic has highlighted the dire necessity to improve public
health literacy for societal resilience. YouTube, the largest video-sharing
social media platform, provides a vast repository of user-generated health
information in a multi-media-rich format which may be easier for the public to
understand and use if major concerns about content quality and accuracy are
addressed. This study develops an automated solution to identify, retrieve and
shortlist medically relevant and understandable YouTube videos that domain
experts can subsequently review and recommend for disseminating and educating
the public on the COVID-19 pandemic and similar public health outbreaks. Our
approach leverages domain knowledge from human experts and machine learning and
natural language processing methods to provide a scalable, replicable, and
generalizable approach that can also be applied to enhance the management of
many health conditions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Studies in health technology and informatics(MedInfo) 2023</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ POINTS: Improving Your Vision-language Model with Affordable Strategies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04828v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04828v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Liu, Zhongyin Zhao, Ziyuan Zhuang, Le Tian, Xiao Zhou, Jie Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, vision-language models have made significant strides,
excelling in tasks like optical character recognition and geometric
problem-solving. However, several critical issues remain: 1) Proprietary models
often lack transparency about their architectures, while open-source models
need more detailed ablations of their training strategies. 2) Pre-training data
in open-source works is under-explored, with datasets added empirically, making
the process cumbersome. 3) Fine-tuning often focuses on adding datasets,
leading to diminishing returns. To address these issues, we propose the
following contributions: 1) We trained a robust baseline model using the latest
advancements in vision-language models, introducing effective improvements and
conducting comprehensive ablation and validation for each technique. 2)
Inspired by recent work on large language models, we filtered pre-training data
using perplexity, selecting the lowest perplexity data for training. This
approach allowed us to train on a curated 1M dataset, achieving competitive
performance. 3) During visual instruction tuning, we used model soup on
different datasets when adding more datasets yielded marginal improvements.
These innovations resulted in a 9B parameter model that performs competitively
with state-of-the-art models. Our strategies are efficient and lightweight,
making them easily adoptable by the community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Speech Enhancement Using Burst Propagation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2209.03275v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2209.03275v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohsin Raza, Leandro A. Passos, Ahmed Khubaib, Ahsan Adeel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes the MBURST, a novel multimodal solution for audio-visual
speech enhancements that consider the most recent neurological discoveries
regarding pyramidal cells of the prefrontal cortex and other brain regions. The
so-called burst propagation implements several criteria to address the credit
assignment problem in a more biologically plausible manner: steering the sign
and magnitude of plasticity through feedback, multiplexing the feedback and
feedforward information across layers through different weight connections,
approximating feedback and feedforward connections, and linearizing the
feedback signals. MBURST benefits from such capabilities to learn correlations
between the noisy signal and the visual stimuli, thus attributing meaning to
the speech by amplifying relevant information and suppressing noise.
Experiments conducted over a Grid Corpus and CHiME3-based dataset show that
MBURST can reproduce similar mask reconstructions to the multimodal
backpropagation-based baseline while demonstrating outstanding energy
efficiency management, reducing the neuron firing rates to values up to
\textbf{$70\%$} lower. Such a feature implies more sustainable implementations,
suitable and desirable for hearing aids or any other similar embedded systems.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-06T00:00:00Z">2024-09-06</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">14</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Preserving Individuality while Following the Crowd: Understanding the
  Role of User Taste and Crowd Wisdom in Online Product Rating Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Wang, Shubham Jain, Yingtong Dou, Junpeng Wang, Chin-Chia Michael Yeh, Yujie Fan, Prince Aboagye, Yan Zheng, Xin Dai, Zhongfang Zhuang, Uday Singh Saini, Wei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerous algorithms have been developed for online product rating prediction,
but the specific influence of user and product information in determining the
final prediction score remains largely unexplored. Existing research often
relies on narrowly defined data settings, which overlooks real-world challenges
such as the cold-start problem, cross-category information utilization, and
scalability and deployment issues. To delve deeper into these aspects, and
particularly to uncover the roles of individual user taste and collective
wisdom, we propose a unique and practical approach that emphasizes historical
ratings at both the user and product levels, encapsulated using a continuously
updated dynamic tree representation. This representation effectively captures
the temporal dynamics of users and products, leverages user information across
product categories, and provides a natural solution to the cold-start problem.
Furthermore, we have developed an efficient data processing strategy that makes
this approach highly scalable and easily deployable. Comprehensive experiments
in real industry settings demonstrate the effectiveness of our approach.
Notably, our findings reveal that individual taste dominates over collective
wisdom in online product rating prediction, a perspective that contrasts with
the commonly observed wisdom of the crowd phenomenon in other domains. This
dominance of individual user taste is consistent across various model types,
including the boosting tree model, recurrent neural network (RNN), and
transformer-based architectures. This observation holds true across the overall
population, within individual product categories, and in cold-start scenarios.
Our findings underscore the significance of individual user tastes in the
context of online product rating prediction and the robustness of our approach
across different model architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Unified Framework for Cross-Domain Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiangxia Cao, Shen Wang, Gaode Chen, Rui Huang, Shuang Yang, Zhaojie Liu, Guorui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In addressing the persistent challenges of data-sparsity and cold-start
issues in domain-expert recommender systems, Cross-Domain Recommendation (CDR)
emerges as a promising methodology. CDR aims at enhancing prediction
performance in the target domain by leveraging interaction knowledge from
related source domains, particularly through users or items that span across
multiple domains (e.g., Short-Video and Living-Room). For academic research
purposes, there are a number of distinct aspects to guide CDR method designing,
including the auxiliary domain number, domain-overlapped element, user-item
interaction types, and downstream tasks. With so many different CDR combination
scenario settings, the proposed scenario-expert approaches are tailored to
address a specific vertical CDR scenario, and often lack the capacity to adapt
to multiple horizontal scenarios. In an effect to coherently adapt to various
scenarios, and drawing inspiration from the concept of domain-invariant
transfer learning, we extend the former SOTA model UniCDR in five different
aspects, named as UniCDR+. Our work was successfully deployed on the Kuaishou
Living-Room RecSys.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> on Knowledge Organization Systems of Research Fields: Resources
  and Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angelo Salatino, Tanay Aggarwal, Andrea Mannocci, Francesco Osborne, Enrico Motta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Organization Systems (KOSs), such as term lists, thesauri,
taxonomies, and ontologies, play a fundamental role in categorising, managing,
and retrieving information. In the academic domain, KOSs are often adopted for
representing research areas and their relationships, primarily aiming to
classify research articles, academic courses, patents, books, scientific
venues, domain experts, grants, software, experiment materials, and several
other relevant products and agents. These structured representations of
research areas, widely embraced by many academic fields, have proven effective
in empowering AI-based systems to i) enhance retrievability of relevant
documents, ii) enable advanced analytic solutions to quantify the impact of
academic research, and iii) analyse and forecast research dynamics. This paper
aims to present a comprehensive survey of the current KOS for academic
disciplines. We analysed and compared 45 KOSs according to five main
dimensions: scope, structure, curation, usage, and links to other KOSs. Our
results reveal a very heterogeneous scenario in terms of scope, scale, quality,
and usage, highlighting the need for more integrated solutions for representing
research knowledge across academic fields. We conclude by discussing the main
challenges and the most promising future directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Fair is Your Diffusion Recommender Model? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04339v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04339v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniele Malitesta, Giacomo Medda, Erasmo Purificato, Ludovico Boratto, Fragkiskos D. Malliaros, Mirko Marras, Ernesto William De Luca
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based recommender systems have recently proven to outperform
traditional generative recommendation approaches, such as variational
autoencoders and generative adversarial networks. Nevertheless, the machine
learning literature has raised several concerns regarding the possibility that
diffusion models, while learning the distribution of data samples, may
inadvertently carry information bias and lead to unfair outcomes. In light of
this aspect, and considering the relevance that fairness has held in
recommendations over the last few decades, we conduct one of the first fairness
investigations in the literature on DiffRec, a pioneer approach in
diffusion-based recommendation. First, we propose an experimental setting
involving DiffRec (and its variant L-DiffRec) along with nine state-of-the-art
recommendation models, two popular recommendation datasets from the
fairness-aware literature, and six metrics accounting for accuracy and
consumer/provider fairness. Then, we perform a twofold analysis, one assessing
models' performance under accuracy and recommendation fairness separately, and
the other identifying if and to what extent such metrics can strike a
performance trade-off. Experimental results from both studies confirm the
initial unfairness warnings but pave the way for how to address them in future
research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Sequential Music Recommendation with Personalized Popularity
  Awareness <span class="chip">RecSys'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04329v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04329v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Davide Abbattista, Vito Walter Anelli, Tommaso Di Noia, Craig Macdonald, Aleksandr Vladimirovich Petrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the realm of music recommendation, sequential recommender systems have
shown promise in capturing the dynamic nature of music consumption.
Nevertheless, traditional Transformer-based models, such as SASRec and
BERT4Rec, while effective, encounter challenges due to the unique
characteristics of music listening habits. In fact, existing models struggle to
create a coherent listening experience due to rapidly evolving preferences.
Moreover, music consumption is characterized by a prevalence of repeated
listening, i.e., users frequently return to their favourite tracks, an
important signal that could be framed as individual or personalized popularity.
  This paper addresses these challenges by introducing a novel approach that
incorporates personalized popularity information into sequential
recommendation. By combining user-item popularity scores with model-generated
scores, our method effectively balances the exploration of new music with the
satisfaction of user preferences. Experimental results demonstrate that a
Personalized Most Popular recommender, a method solely based on user-specific
popularity, outperforms existing state-of-the-art models. Furthermore,
augmenting Transformer-based models with personalized popularity awareness
yields superior performance, showing improvements ranging from 25.2% to 69.8%.
The code for this paper is available at
https://github.com/sisinflab/personalized-popularity-awareness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by RecSys'24 as an LBR paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WarpAdam: A new Adam optimizer based on Meta-Learning approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04244v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04244v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengxi Pan, Junshang Chen, Jingrui Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Optimal selection of optimization algorithms is crucial for training deep
learning models. The Adam optimizer has gained significant attention due to its
efficiency and wide applicability. However, to enhance the adaptability of
optimizers across diverse datasets, we propose an innovative optimization
strategy by integrating the 'warped gradient descend'concept from Meta Learning
into the Adam optimizer. In the conventional Adam optimizer, gradients are
utilized to compute estimates of gradient mean and variance, subsequently
updating model parameters. Our approach introduces a learnable distortion
matrix, denoted as P, which is employed for linearly transforming gradients.
This transformation slightly adjusts gradients during each iteration, enabling
the optimizer to better adapt to distinct dataset characteristics. By learning
an appropriate distortion matrix P, our method aims to adaptively adjust
gradient information across different data distributions, thereby enhancing
optimization performance. Our research showcases the potential of this novel
approach through theoretical insights and empirical evaluations. Experimental
results across various tasks and datasets validate the superiority of our
optimizer that integrates the 'warped gradient descend' concept in terms of
adaptability. Furthermore, we explore effective strategies for training the
adaptation matrix P and identify scenarios where this method can yield optimal
results. In summary, this study introduces an innovative approach that merges
the 'warped gradient descend' concept from Meta Learning with the Adam
optimizer. By introducing a learnable distortion matrix P within the optimizer,
we aim to enhance the model's generalization capability across diverse data
distributions, thus opening up new possibilities in the field of deep learning
optimization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Refining Wikidata Taxonomy using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04056v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04056v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiwen Peng, Thomas Bonald, Mehwish Alam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to its collaborative nature, Wikidata is known to have a complex
taxonomy, with recurrent issues like the ambiguity between instances and
classes, the inaccuracy of some taxonomic paths, the presence of cycles, and
the high level of redundancy across classes. Manual efforts to clean up this
taxonomy are time-consuming and prone to errors or subjective decisions. We
present WiKC, a new version of Wikidata taxonomy cleaned automatically using a
combination of Large Language Models (LLMs) and graph mining techniques.
Operations on the taxonomy, such as cutting links or merging classes, are
performed with the help of zero-shot prompting on an open-source LLM. The
quality of the refined taxonomy is evaluated from both intrinsic and extrinsic
perspectives, on a task of entity typing for the latter, showing the practical
interest of WiKC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM International Conference on Information and Knowledge Management,
  Oct 2024, Boise, Idaho, United States</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FiNER-ORD: Financial Named Entity Recognition Open Research <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.11157v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.11157v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Agam Shah, Abhinav Gullapalli, Ruchit Vithani, Michael Galarnyk, Sudheer Chava
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the last two decades, the development of the CoNLL-2003 named entity
recognition (NER) dataset has helped enhance the capabilities of deep learning
and natural language processing (NLP). The finance domain, characterized by its
unique semantic and lexical variations for the same entities, presents specific
challenges to the NER task; thus, a domain-specific customized dataset is
crucial for advancing research in this field. In our work, we develop the first
high-quality English Financial NER Open Research Dataset (FiNER-ORD). We
benchmark multiple pre-trained language models (PLMs) and large-language models
(LLMs) on FiNER-ORD. We believe our proposed FiNER-ORD dataset will open future
opportunities to use FiNER-ORD as a benchmark for financial domain-specific NER
and NLP tasks. Our dataset, models, and code are publicly available on GitHub
and Hugging Face under CC BY-NC 4.0 license.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GraphEx: A Graph-based Extraction Method for Advertiser Keyphrase
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03140v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03140v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashirbad Mishra, Soumik Dey, Marshall Wu, Jinyu Zhao, He Yu, Kaichen Ni, Binbin Li, Kamesh Madduri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online sellers and advertisers are recommended keyphrases for their listed
products, which they bid on to enhance their sales. One popular paradigm that
generates such recommendations is Extreme Multi-Label Classification (XMC),
which involves tagging/mapping keyphrases to items. We outline the limitations
of using traditional item-query based tagging or mapping techniques for
keyphrase recommendations on E-Commerce platforms. We introduce GraphEx, an
innovative graph-based approach that recommends keyphrases to sellers using
extraction of token permutations from item titles. Additionally, we demonstrate
that relying on traditional metrics such as precision/recall can be misleading
in practical applications, thereby necessitating a combination of metrics to
evaluate performance in real-world scenarios. These metrics are designed to
assess the relevance of keyphrases to items and the potential for buyer
outreach. GraphEx outperforms production models at eBay, achieving the
objectives mentioned above. It supports near real-time inferencing in
resource-constrained production environments and scales effectively for
billions of items.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-Shot Topic Classification of Column Headers: Leveraging LLMs for
  Metadata Enrichment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.00884v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.00884v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Margherita Martorana, Tobias Kuhn, Lise Stork, Jacco van Ossenbruggen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional dataset retrieval systems rely on metadata for indexing, rather
than on the underlying data values. However, high-quality metadata creation and
enrichment often require manual annotations, which is a labour-intensive and
challenging process to automate. In this study, we propose a method to support
metadata enrichment using topic annotations generated by three Large Language
Models (LLMs): ChatGPT-3.5, GoogleBard, and GoogleGemini. Our analysis focuses
on classifying column headers based on domain-specific topics from the
Consortium of European Social Science Data Archives (CESSDA), a Linked Data
controlled vocabulary. Our approach operates in a zero-shot setting,
integrating the controlled topic vocabulary directly within the input prompt.
This integration serves as a Large Context Windows approach, with the aim of
improving the results of the topic classification task.
  We evaluated the performance of the LLMs in terms of internal consistency,
inter-machine alignment, and agreement with human classification. Additionally,
we investigate the impact of contextual information (i.e., dataset description)
on the classification outcomes. Our findings suggest that ChatGPT and
GoogleGemini outperform GoogleBard in terms of internal consistency as well as
LLM-human-agreement. Interestingly, we found that contextual information had no
significant impact on LLM performance.
  This work proposes a novel approach that leverages LLMs for topic
classification of column headers using a controlled vocabulary, presenting a
practical application of LLMs and Large Context Windows within the Semantic Web
domain. This approach has the potential to facilitate automated metadata
enrichment, thereby enhancing dataset retrieval and the Findability,
Accessibility, Interoperability, and Reusability (FAIR) of research data on the
Web.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RAG based Question-Answering for Contextual Response Prediction System <span class="chip">CIKM'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03708v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03708v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sriram Veturi, Saurabh Vaichal, Reshma Lal Jagadheesh, Nafis Irtiza Tripto, Nian Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown versatility in various Natural
Language Processing (NLP) tasks, including their potential as effective
question-answering systems. However, to provide precise and relevant
information in response to specific customer queries in industry settings, LLMs
require access to a comprehensive knowledge base to avoid hallucinations.
Retrieval Augmented Generation (RAG) emerges as a promising technique to
address this challenge. Yet, developing an accurate question-answering
framework for real-world applications using RAG entails several challenges: 1)
data availability issues, 2) evaluating the quality of generated content, and
3) the costly nature of human evaluation. In this paper, we introduce an
end-to-end framework that employs LLMs with RAG capabilities for industry use
cases. Given a customer query, the proposed system retrieves relevant knowledge
documents and leverages them, along with previous chat history, to generate
response suggestions for customer service agents in the contact centers of a
major retail company. Through comprehensive automated and human evaluations, we
show that this solution outperforms the current BERT-based algorithms in
accuracy and relevance. Our findings suggest that RAG-based LLMs can be an
excellent support to human customer service representatives by lightening their
workload.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 1st Workshop on GenAI and RAG Systems for Enterprise,
  CIKM'24. 6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hybrid Semantic Search: Unveiling User Intent Beyond Keywords 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09236v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09236v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aman Ahluwalia, Bishwajit Sutradhar, Karishma Ghosh, Indrapal Yadav, Arpan Sheetal, Prashant Patil
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the limitations of traditional keyword-based search in
understanding user intent and introduces a novel hybrid search approach that
leverages the strengths of non-semantic search engines, Large Language Models
(LLMs), and embedding models. The proposed system integrates keyword matching,
semantic vector embeddings, and LLM-generated structured queries to deliver
highly relevant and contextually appropriate search results. By combining these
complementary methods, the hybrid approach effectively captures both explicit
and implicit user intent.The paper further explores techniques to optimize
query execution for faster response times and demonstrates the effectiveness of
this hybrid search model in producing comprehensive and accurate search
outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hi-Gen: Generative Retrieval For Large-Scale Personalized E-commerce
  Search <span class="chip">ICDM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanjing Wu, Yinfu Feng, Jian Wang, Wenji Zhou, Yunan Ye, Rong Xiao, Jun Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging generative retrieval (GR) techniques to enhance search systems is
an emerging methodology that has shown promising results in recent years. In
GR, a text-to-text model maps string queries directly to relevant document
identifiers (docIDs), dramatically simplifying the retrieval process. However,
when applying most GR models in large-scale E-commerce for personalized item
search, we must face two key problems in encoding and decoding. (1) Existing
docID generation methods ignore the encoding of efficiency information, which
is critical in E-commerce. (2) The positional information is important in
decoding docIDs, while prior studies have not adequately discriminated the
significance of positional information or well exploited the inherent
interrelation among these positions. To overcome these problems, we introduce
an efficient Hierarchical encoding-decoding Generative retrieval method
(Hi-Gen) for large-scale personalized E-commerce search systems. Specifically,
we first design a representation learning model using metric learning to learn
discriminative feature representations of items to capture semantic relevance
and efficiency information. Then, we propose a category-guided hierarchical
clustering scheme that makes full use of the semantic and efficiency
information of items to facilitate docID generation. Finally, we design a
position-aware loss to discriminate the importance of positions and mine the
inherent interrelation between different tokens at the same position. This loss
boosts the performance of the language model used in the decoding stage.
Besides, we propose two variants of Hi-Gen (Hi-Gen-I2I and Hi-Gen-Cluster) to
support online real-time large-scale recall in the online serving process.
Hi-Gen gets 3.30% and 4.62% improvements over SOTA for Recall@1 on the public
and industry datasets, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICDM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Med<span class="highlight-title">Prompt</span>Extract (Medical Data Extraction Tool): Anonymization and
  Hi-fidelity Automated data extraction using NLP and <span class="highlight-title">prompt</span> engineering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02664v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02664v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roomani Srivastava, Suraj Prasad, Lipika Bhat, Sarvesh Deshpande, Barnali Das, Kshitij Jadhav
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Introduction: The labour-intensive nature of data extraction from sources
like discharge summaries (DS) poses significant obstacles to the digitisation
of medical records particularly for low- and middle-income countries (LMICs).
In this paper we present a completely automated method MedPromptExtract to
efficiently extract data from DS while maintaining confidentiality. Methods:
The source of data was Discharge Summaries (DS) from Kokilaben Dhirubhai Ambani
Hospital (KDAH) of patients having Acute Kidney Injury (AKI). A pre-existing
tool EIGEN which leverages semi-supervised learning techniques for
high-fidelity information extraction was used to anonymize the DS, Natural
Language Processing (NLP) was used to extract data from regular fields. We used
Prompt Engineering and Large Language Model(LLM) to extract custom clinical
information from free flowing text describing the patients stay in the
hospital. Twelve features associated with occurrence of AKI were extracted. The
LLM responses were validated against clinicians annotations. Results: The
MedPromptExtracttool first subjected DS to the anonymization pipeline which
took three seconds per summary. Successful anonymization was verified by
clinicians, thereafter NLP pipeline extracted structured text from the
anonymized pdfs at the rate of 0.2 seconds per summary with 100%
accuracy.Finally DS were analysed by the LLM pipeline using Gemini Pro for the
twelve features. Accuracy metrics were calculated by comparing model responses
to clinicians annotations with seven features achieving AUCs above 0.9,
indicating high fidelity of the extraction process. Conclusion:
MedPromptExtract serves as an automated adaptable tool for efficient data
extraction from medical records with a dynamic user interface. Keywords:
Digitizing Medical Records, Automated Anonymisation, Information Retrieval,
Large Language Models, Prompt Engineering
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ 3D-GP-LMVIC: Learning-based Multi-View Image Coding with 3D Gaussian
  Geometric Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04013v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04013v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujun Huang, Bin Chen, Niu Lian, Baoyi An, Shu-Tao Xia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-view image compression is vital for 3D-related applications. To
effectively model correlations between views, existing methods typically
predict disparity between two views on a 2D plane, which works well for small
disparities, such as in stereo images, but struggles with larger disparities
caused by significant view changes. To address this, we propose a novel
approach: learning-based multi-view image coding with 3D Gaussian geometric
priors (3D-GP-LMVIC). Our method leverages 3D Gaussian Splatting to derive
geometric priors of the 3D scene, enabling more accurate disparity estimation
across views within the compression model. Additionally, we introduce a depth
map compression model to reduce redundancy in geometric information between
views. A multi-view sequence ordering method is also proposed to enhance
correlations between adjacent views. Experimental results demonstrate that
3D-GP-LMVIC surpasses both traditional and learning-based methods in
performance, while maintaining fast encoding and decoding speed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19pages, 8 figures, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MSLIQA: Enhancing Learning Representations for Image Quality Assessment
  through Multi-Scale Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16879v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16879v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nasim Jamshidi Avanaki, Abhijay Ghildyal, Nabajeet Barman, Saman Zadtootaghaj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  No-Reference Image Quality Assessment (NR-IQA) remains a challenging task due
to the diversity of distortions and the lack of large annotated datasets. Many
studies have attempted to tackle these challenges by developing more accurate
NR-IQA models, often employing complex and computationally expensive networks,
or by bridging the domain gap between various distortions to enhance
performance on test datasets. In our work, we improve the performance of a
generic lightweight NR-IQA model by introducing a novel augmentation strategy
that boosts its performance by almost 28\%. This augmentation strategy enables
the network to better discriminate between different distortions in various
parts of the image by zooming in and out. Additionally, the inclusion of
test-time augmentation further enhances performance, making our lightweight
network's results comparable to the current state-of-the-art models, simply
through the use of augmentations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LAR-IQA: A Lightweight, Accurate, and Robust No-Reference Image Quality
  Assessment Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.17057v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.17057v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nasim Jamshidi Avanaki, Abhijay Ghildyal, Nabajeet Barman, Saman Zadtootaghaj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in the field of No-Reference Image Quality Assessment
(NR-IQA) using deep learning techniques demonstrate high performance across
multiple open-source datasets. However, such models are typically very large
and complex making them not so suitable for real-world deployment, especially
on resource- and battery-constrained mobile devices. To address this
limitation, we propose a compact, lightweight NR-IQA model that achieves
state-of-the-art (SOTA) performance on ECCV AIM UHD-IQA challenge validation
and test datasets while being also nearly 5.7 times faster than the fastest
SOTA model. Our model features a dual-branch architecture, with each branch
separately trained on synthetically and authentically distorted images which
enhances the model's generalizability across different distortion types. To
improve robustness under diverse real-world visual conditions, we additionally
incorporate multiple color spaces during the training process. We also
demonstrate the higher accuracy of recently proposed Kolmogorov-Arnold Networks
(KANs) for final quality regression as compared to the conventional Multi-Layer
Perceptrons (MLPs). Our evaluation considering various open-source datasets
highlights the practical, high-accuracy, and robust performance of our proposed
lightweight model. Code: https://github.com/nasimjamshidi/LAR-IQA.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-05T00:00:00Z">2024-09-05</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RETAIN: Interactive Tool for Regression Testing Guided LLM Migration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03928v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03928v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tanay Dixit, Daniel Lee, Sally Fang, Sai Sree Harsha, Anirudh Sureshan, Akash Maharaj, Yunyao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly integrated into diverse
applications. The rapid evolution of LLMs presents opportunities for developers
to enhance applications continuously. However, this constant adaptation can
also lead to performance regressions during model migrations. While several
interactive tools have been proposed to streamline the complexity of prompt
engineering, few address the specific requirements of regression testing for
LLM Migrations. To bridge this gap, we introduce RETAIN (REgression Testing
guided LLM migrAtIoN), a tool designed explicitly for regression testing in LLM
Migrations. RETAIN comprises two key components: an interactive interface
tailored to regression testing needs during LLM migrations, and an error
discovery module that facilitates understanding of differences in model
behaviors. The error discovery module generates textual descriptions of various
errors or differences between model outputs, providing actionable insights for
prompt refinement. Our automatic evaluation and empirical user studies
demonstrate that RETAIN, when compared to manual evaluation, enabled
participants to identify twice as many errors, facilitated experimentation with
75% more prompts, and achieves 12% higher metric scores in a given time frame.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HGAMN: Heterogeneous Graph Attention Matching Network for Multilingual
  POI Retrieval at Baidu Maps <span class="chip">KDD'21</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03504v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03504v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jizhou Huang, Haifeng Wang, Yibo Sun, Miao Fan, Zhengjie Huang, Chunyuan Yuan, Yawen Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The increasing interest in international travel has raised the demand of
retrieving point of interests in multiple languages. This is even superior to
find local venues such as restaurants and scenic spots in unfamiliar languages
when traveling abroad. Multilingual POI retrieval, enabling users to find
desired POIs in a demanded language using queries in numerous languages, has
become an indispensable feature of today's global map applications such as
Baidu Maps. This task is non-trivial because of two key challenges: (1)
visiting sparsity and (2) multilingual query-POI matching. To this end, we
propose a Heterogeneous Graph Attention Matching Network (HGAMN) to
concurrently address both challenges. Specifically, we construct a
heterogeneous graph that contains two types of nodes: POI node and query node
using the search logs of Baidu Maps. To alleviate challenge \#1, we construct
edges between different POI nodes to link the low-frequency POIs with the
high-frequency ones, which enables the transfer of knowledge from the latter to
the former. To mitigate challenge \#2, we construct edges between POI and query
nodes based on the co-occurrences between queries and POIs, where queries in
different languages and formulations can be aggregated for individual POIs.
Moreover, we develop an attention-based network to jointly learn node
representations of the heterogeneous graph and further design a cross-attention
module to fuse the representations of both types of nodes for query-POI
relevance scoring. Extensive experiments conducted on large-scale real-world
datasets from Baidu Maps demonstrate the superiority and effectiveness of
HGAMN. In addition, HGAMN has already been deployed in production at Baidu
Maps, and it successfully keeps serving hundreds of millions of requests every
day.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD'21</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu's
  Sponsored Search <span class="chip">KDD'19</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03449v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03449v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miao Fan, Jiacheng Guo, Shuai Zhu, Shuo Miao, Mingming Sun, Ping Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Baidu runs the largest commercial web search engine in China, serving
hundreds of millions of online users every day in response to a great variety
of queries. In order to build a high-efficiency sponsored search engine, we
used to adopt a three-layer funnel-shaped structure to screen and sort hundreds
of ads from billions of ad candidates subject to the requirement of low
response latency and the restraints of computing resources. Given a user query,
the top matching layer is responsible for providing semantically relevant ad
candidates to the next layer, while the ranking layer at the bottom concerns
more about business indicators (e.g., CPM, ROI, etc.) of those ads. The clear
separation between the matching and ranking objectives results in a lower
commercial return. The Mobius project has been established to address this
serious issue. It is our first attempt to train the matching layer to consider
CPM as an additional optimization objective besides the query-ad relevance, via
directly predicting CTR (click-through rate) from billions of query-ad pairs.
Specifically, this paper will elaborate on how we adopt active learning to
overcome the insufficiency of click history at the matching layer when training
our neural click networks offline, and how we use the SOTA ANN search technique
for retrieving ads more efficiently (Here ``ANN'' stands for approximate
nearest neighbor search). We contribute the solutions to Mobius-V1 as the first
version of our next generation query-ad matching system.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by KDD'19</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Federated Prototype-based Contrastive Learning for Privacy-Preserving
  Cross-domain Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03294v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03294v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Wang, Quangui Zhang, Lei Sang, Qiang Wu, Min Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-domain recommendation (CDR) aims to improve recommendation accuracy in
sparse domains by transferring knowledge from data-rich domains. However,
existing CDR methods often assume the availability of user-item interaction
data across domains, overlooking user privacy concerns. Furthermore, these
methods suffer from performance degradation in scenarios with sparse
overlapping users, as they typically depend on a large number of fully shared
users for effective knowledge transfer. To address these challenges, we propose
a Federated Prototype-based Contrastive Learning (CL) method for
Privacy-Preserving CDR, named FedPCL-CDR. This approach utilizes
non-overlapping user information and prototypes to improve multi-domain
performance while protecting user privacy. FedPCL-CDR comprises two modules:
local domain (client) learning and global server aggregation. In the local
domain, FedPCL-CDR clusters all user data to learn representative prototypes,
effectively utilizing non-overlapping user information and addressing the
sparse overlapping user issue. It then facilitates knowledge transfer by
employing both local and global prototypes returned from the server in a CL
manner. Simultaneously, the global server aggregates representative prototypes
from local domains to learn both local and global prototypes. The combination
of prototypes and federated learning (FL) ensures that sensitive user data
remains decentralized, with only prototypes being shared across domains,
thereby protecting user privacy. Extensive experiments on four CDR tasks using
two real-world datasets demonstrate that FedPCL-CDR outperforms the
state-of-the-art baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ iText2KG: Incremental Knowledge Graphs Construction Using Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yassir Lairgi, Ludovic Moncla, Rémy Cazabet, Khalid Benabdeslem, Pierre Cléau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most available data is unstructured, making it challenging to access valuable
information. Automatically building Knowledge Graphs (KGs) is crucial for
structuring data and making it accessible, allowing users to search for
information effectively. KGs also facilitate insights, inference, and
reasoning. Traditional NLP methods, such as named entity recognition and
relation extraction, are key in information retrieval but face limitations,
including the use of predefined entity types and the need for supervised
learning. Current research leverages large language models' capabilities, such
as zero- or few-shot learning. However, unresolved and semantically duplicated
entities and relations still pose challenges, leading to inconsistent graphs
and requiring extensive post-processing. Additionally, most approaches are
topic-dependent. In this paper, we propose iText2KG, a method for incremental,
topic-independent KG construction without post-processing. This plug-and-play,
zero-shot method is applicable across a wide range of KG construction scenarios
and comprises four modules: Document Distiller, Incremental Entity Extractor,
Incremental Relation Extractor, and Graph Integrator and Visualization. Our
method demonstrates superior performance compared to baseline methods across
three scenarios: converting scientific papers to graphs, websites to graphs,
and CVs to graphs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at The International Web Information Systems Engineering
  conference (the WISE conference) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Behavior-Dependent Linear Recurrent Units for Efficient Sequential
  Recommendation <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12580v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12580v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengkai Liu, Jianghao Lin, Hanzhou Liu, Jianling Wang, James Caverlee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems aims to predict the users' next interaction
through user behavior modeling with various operators like RNNs and attentions.
However, existing models generally fail to achieve the three golden principles
for sequential recommendation simultaneously, i.e., training efficiency,
low-cost inference, and strong performance. To this end, we propose RecBLR, an
Efficient Sequential Recommendation Model based on Behavior-Dependent Linear
Recurrent Units to accomplish the impossible triangle of the three principles.
By incorporating gating mechanisms and behavior-dependent designs into linear
recurrent units, our model significantly enhances user behavior modeling and
recommendation performance. Furthermore, we unlock the parallelizable training
as well as inference efficiency for our model by designing a hardware-aware
scanning acceleration algorithm with a customized CUDA kernel. Extensive
experiments on real-world datasets with varying lengths of user behavior
sequences demonstrate RecBLR's remarkable effectiveness in simultaneously
achieving all three golden principles - strong recommendation performance,
training efficiency, and low-cost inference, while exhibiting excellent
scalability to datasets with long user interaction histories.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pooling And Attention: What Are Effective Designs For LLM-Based
  Embedding Models? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixuan Tang, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The significant advancements of Large Language Models (LLMs) in generative
tasks have led to a growing body of work exploring LLM-based embedding models.
While these models, employing different pooling and attention strategies, have
achieved state-of-the-art performance on public embedding benchmarks, questions
still arise about what constitutes an effective design for LLM-based embedding
models. However, these models are often trained on different datasets, using
different LLM base models or training settings. Moreover, evaluations on public
embedding benchmarks often fail to report statistical significance, making it
difficult to determine which designs truly contribute to final performance.
This complicates the process for practitioners seeking optimal training recipes
for LLM-based embedding models. In this study, we conduct a large-scale
experiment by training a series of LLM-based embedding models using the same
training data and base model but differing in their pooling and attention
strategies. The results show that there is no one-size-fits-all solution: while
bidirectional attention and an additional trainable pooling layer outperform in
text similarity and information retrieval tasks, they do not significantly
surpass simpler designs like EOS-last token pooling and default causal
attention in clustering and classification tasks. Furthermore, we propose a new
pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs
of all hidden layers, rather than just the last layer, using a cross-attention
network. This method proves to be statistically superior in text similarity and
retrieval tasks compared to existing pooling methods. Overall, this paper sheds
light on effective training strategies for LLM-based embedding models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/yixuantt/PoolingAndAttn</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ WaterMAS: Sharpness-Aware Maximization for Neural Network Watermarking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03902v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03902v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carl De Sousa Trias, Mihai Mitrea, Attilio Fiandrotti, Marco Cagnazzo, Sumanta Chaudhuri, Enzo Tartaglione
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nowadays, deep neural networks are used for solving complex tasks in several
critical applications and protecting both their integrity and intellectual
property rights (IPR) has become of utmost importance. To this end, we advance
WaterMAS, a substitutive, white-box neural network watermarking method that
improves the trade-off among robustness, imperceptibility, and computational
complexity, while making provisions for increased data payload and security.
WasterMAS insertion keeps unchanged the watermarked weights while sharpening
their underlying gradient space. The robustness is thus ensured by limiting the
attack's strength: even small alterations of the watermarked weights would
impact the model's performance. The imperceptibility is ensured by inserting
the watermark during the training process. The relationship among the WaterMAS
data payload, imperceptibility, and robustness properties is discussed. The
secret key is represented by the positions of the weights conveying the
watermark, randomly chosen through multiple layers of the model. The security
is evaluated by investigating the case in which an attacker would intercept the
key. The experimental validations consider 5 models and 2 tasks (VGG16,
ResNet18, MobileNetV3, SwinT for CIFAR10 image classification, and DeepLabV3
for Cityscapes image segmentation) as well as 4 types of attacks (Gaussian
noise addition, pruning, fine-tuning, and quantization). The code will be
released open-source upon acceptance of the article.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MetaBGM: Dynamic Soundtrack Transformation For Continuous Multi-Scene
  Experiences With Ambient Awareness And Personalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03844v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03844v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxuan Liu, Zihao Wang, Haorong Hong, Youwei Feng, Jiaxin Yu, Han Diao, Yunfei Xu, Kejun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces MetaBGM, a groundbreaking framework for generating
background music that adapts to dynamic scenes and real-time user interactions.
We define multi-scene as variations in environmental contexts, such as
transitions in game settings or movie scenes. To tackle the challenge of
converting backend data into music description texts for audio generation
models, MetaBGM employs a novel two-stage generation approach that transforms
continuous scene and user state data into these texts, which are then fed into
an audio generation model for real-time soundtrack creation. Experimental
results demonstrate that MetaBGM effectively generates contextually relevant
and dynamic background music for interactive applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SegTalker: Segmentation-based Talking Face Generation with Mask-guided
  Local Editing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingyu Xiong, Xize Cheng, Jintao Tan, Xianjia Wu, Xiandong Li, Lei Zhu, Fei Ma, Minglei Li, Huang Xu, Zhihu Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio-driven talking face generation aims to synthesize video with lip
movements synchronized to input audio. However, current generative techniques
face challenges in preserving intricate regional textures (skin, teeth). To
address the aforementioned challenges, we propose a novel framework called
SegTalker to decouple lip movements and image textures by introducing
segmentation as intermediate representation. Specifically, given the mask of
image employed by a parsing network, we first leverage the speech to drive the
mask and generate talking segmentation. Then we disentangle semantic regions of
image into style codes using a mask-guided encoder. Ultimately, we inject the
previously generated talking segmentation and style codes into a mask-guided
StyleGAN to synthesize video frame. In this way, most of textures are fully
preserved. Moreover, our approach can inherently achieve background separation
and facilitate mask-guided facial local editing. In particular, by editing the
mask and swapping the region textures from a given reference image (e.g. hair,
lip, eyebrows), our approach enables facial editing seamlessly when generating
talking face video. Experiments demonstrate that our proposed approach can
effectively preserve texture details and generate temporally consistent video
while remaining competitive in lip synchronization. Quantitative and
qualitative results on the HDTF and MEAD datasets illustrate the superior
performance of our method over existing methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Make Graph-based Referring Expression Comprehension Great Again through
  Expression-guided Dynamic Gating and Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03385v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03385v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingcheng Ke, Dele Wang, Jun-Cheng Chen, I-Hong Jhuo, Chia-Wen Lin, Yen-Yu Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One common belief is that with complex models and pre-training on large-scale
datasets, transformer-based methods for referring expression comprehension
(REC) perform much better than existing graph-based methods. We observe that
since most graph-based methods adopt an off-the-shelf detector to locate
candidate objects (i.e., regions detected by the object detector), they face
two challenges that result in subpar performance: (1) the presence of
significant noise caused by numerous irrelevant objects during reasoning, and
(2) inaccurate localization outcomes attributed to the provided detector. To
address these issues, we introduce a plug-and-adapt module guided by
sub-expressions, called dynamic gate constraint (DGC), which can adaptively
disable irrelevant proposals and their connections in graphs during reasoning.
We further introduce an expression-guided regression strategy (EGR) to refine
location prediction. Extensive experimental results on the RefCOCO, RefCOCO+,
RefCOCOg, Flickr30K, RefClef, and Ref-reasoning datasets demonstrate the
effectiveness of the DGC module and the EGR strategy in consistently boosting
the performances of various graph-based REC methods. Without any pretaining,
the proposed graph-based method achieves better performance than the
state-of-the-art (SOTA) transformer-based methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages to appear in IEEE Transactions on Multimedia</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-Shot Character Identification and Speaker Prediction in Comics via
  Iterative Multimodal Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.13993v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.13993v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingxuan Li, Ryota Hinami, Kiyoharu Aizawa, Yusuke Matsui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recognizing characters and predicting speakers of dialogue are critical for
comic processing tasks, such as voice generation or translation. However,
because characters vary by comic title, supervised learning approaches like
training character classifiers which require specific annotations for each
comic title are infeasible. This motivates us to propose a novel zero-shot
approach, allowing machines to identify characters and predict speaker names
based solely on unannotated comic images. In spite of their importance in
real-world applications, these task have largely remained unexplored due to
challenges in story comprehension and multimodal integration. Recent large
language models (LLMs) have shown great capability for text understanding and
reasoning, while their application to multimodal content analysis is still an
open problem. To address this problem, we propose an iterative multimodal
framework, the first to employ multimodal information for both character
identification and speaker prediction tasks. Our experiments demonstrate the
effectiveness of the proposed framework, establishing a robust baseline for
these tasks. Furthermore, since our method requires no training data or
annotations, it can be used as-is on any comic series.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACM Multimedia 2024. Project page:
  https://liyingxuan1012.github.io/zeroshot-speaker-prediction ; Github repo:
  https://github.com/liyingxuan1012/zeroshot-speaker-prediction</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-04T00:00:00Z">2024-09-04</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">20</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bioinformatics Retrieval Augmentation Data (BRAD) Digital Assistant 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02864v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02864v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joshua Pickard, Marc Andrew Choi, Natalie Oliven, Cooper Stansbury, Jillian Cwycyshyn, Nicholas Galioto, Alex Gorodetsky, Alvaro Velasquez, Indika Rajapakse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a prototype for a Bioinformatics Retrieval Augmentation Data
(BRAD) digital assistant. BRAD integrates a suite of tools to handle a wide
range of bioinformatics tasks, from code execution to online search. We
demonstrate BRAD's capabilities through (1) improved question-and-answering
with retrieval augmented generation (RAG), (2) BRAD's ability to run and write
complex software pipelines, and (3) BRAD's ability to organize and distribute
tasks across individual and teams of agents. We use BRAD for automation of
bioinformatics workflows, performing tasks ranging from gene enrichment and
searching the archive to automatic code generation and running biomarker
identification pipelines. BRAD is a step toward the ultimate goal to develop a
digital twin of laboratories driven by self-contained loops for hypothesis
generation and testing of digital biology experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Building a Scalable, Effective, and Steerable Search and Ranking
  Platform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02856v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02856v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marjan Celikik, Jacek Wasilewski, Ana Peleteiro Ramallo, Alexey Kurennoy, Evgeny Labzin, Danilo Ascione, Tural Gurbanov, Géraud Le Falher, Andrii Dzhoha, Ian Harris
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern e-commerce platforms offer vast product selections, making it
difficult for customers to find items that they like and that are relevant to
their current session intent. This is why it is key for e-commerce platforms to
have near real-time scalable and adaptable personalized ranking and search
systems. While numerous methods exist in the scientific literature for building
such systems, many are unsuitable for large-scale industrial use due to
complexity and performance limitations. Consequently, industrial ranking
systems often resort to computationally efficient yet simplistic retrieval or
candidate generation approaches, which overlook near real-time and
heterogeneous customer signals, which results in a less personalized and
relevant experience. Moreover, related customer experiences are served by
completely different systems, which increases complexity, maintenance, and
inconsistent experiences.
  In this paper, we present a personalized, adaptable near real-time ranking
platform that is reusable across various use cases, such as browsing and
search, and that is able to cater to millions of items and customers under
heavy load (thousands of requests per second). We employ transformer-based
models through different ranking layers which can learn complex behavior
patterns directly from customer action sequences while being able to
incorporate temporal (e.g. in-session) and contextual information. We validate
our system through a series of comprehensive offline and online real-world
experiments at a large online e-commerce platform, and we demonstrate its
superiority when compared to existing systems, both in terms of customer
experience as well as in net revenue. Finally, we share the lessons learned
from building a comprehensive, modern ranking platform for use in a large-scale
e-commerce environment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RouterRetriever: Exploring the Benefits of Routing over Multiple Expert
  Embedding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02685v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02685v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyunji Lee, Luca Soldaini, Arman Cohan, Minjoon Seo, Kyle Lo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval methods often rely on a single embedding model trained
on large, general-domain datasets like MSMARCO. While this approach can produce
a retriever with reasonable overall performance, models trained on
domain-specific data often yield better results within their respective
domains. While prior work in information retrieval has tackled this through
multi-task training, the topic of combining multiple domain-specific expert
retrievers remains unexplored, despite its popularity in language model
generation. In this work, we introduce RouterRetriever, a retrieval model that
leverages multiple domain-specific experts along with a routing mechanism to
select the most appropriate expert for each query. It is lightweight and allows
easy addition or removal of experts without additional training. Evaluation on
the BEIR benchmark demonstrates that RouterRetriever outperforms both
MSMARCO-trained (+2.1 absolute nDCG@10) and multi-task trained (+3.2) models.
This is achieved by employing our routing mechanism, which surpasses other
routing techniques (+1.8 on average) commonly used in language modeling.
Furthermore, the benefit generalizes well to other datasets, even in the
absence of a specific expert on the dataset. To our knowledge, RouterRetriever
is the first work to demonstrate the advantages of using multiple
domain-specific expert embedding models with effective routing over a single,
general-purpose embedding model in retrieval tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Fashion Item Recommendation Model in Hyperbolic Space <span class="chip">CVPR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02599v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02599v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryotaro Shimizu, Yu Wang, Masanari Kimura, Yuki Hirakawa, Takashi Wada, Yuki Saito, Julian McAuley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we propose a fashion item recommendation model that
incorporates hyperbolic geometry into user and item representations. Using
hyperbolic space, our model aims to capture implicit hierarchies among items
based on their visual data and users' purchase history. During training, we
apply a multi-task learning framework that considers both hyperbolic and
Euclidean distances in the loss function. Our experiments on three data sets
show that our model performs better than previous models trained in Euclidean
space only, confirming the effectiveness of our model. Our ablation studies
show that multi-task learning plays a key role, and removing the Euclidean loss
substantially deteriorates the model performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work was presented at the CVFAD Workshop at CVPR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AlignGroup: Learning and Aligning Group Consensus with Member
  Preferences for Group Recommendation <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02580v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02580v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinfeng Xu, Zheyu Chen, Jinze Li, Shuo Yang, Hewei Wang, Edith C. -H. Ngai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group activities are important behaviors in human society, providing
personalized recommendations for groups is referred to as the group
recommendation task. Existing methods can usually be categorized into two
strategies to infer group preferences: 1) determining group preferences by
aggregating members' personalized preferences, and 2) inferring group consensus
by capturing group members' coherent decisions after common compromises.
However, the former would suffer from the lack of group-level considerations,
and the latter overlooks the fine-grained preferences of individual users. To
this end, we propose a novel group recommendation method AlignGroup, which
focuses on both group consensus and individual preferences of group members to
infer the group decision-making. Specifically, AlignGroup explores group
consensus through a well-designed hypergraph neural network that efficiently
learns intra- and inter-group relationships. Moreover, AlignGroup innovatively
utilizes a self-supervised alignment task to capture fine-grained group
decision-making by aligning the group consensus with members' common
preferences. Extensive experiments on two real-world datasets validate that our
AlignGroup outperforms the state-of-the-art on both the group recommendation
task and the user recommendation task, as well as outperforms the efficiency of
most baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, accepted by CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ iRangeGraph: Improvising Range-dedicated Graphs for Range-filtering
  Nearest Neighbor Search <span class="chip">SIGMOD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuexuan Xu, Jianyang Gao, Yutong Gou, Cheng Long, Christian S. Jensen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Range-filtering approximate nearest neighbor (RFANN) search is attracting
increasing attention in academia and industry. Given a set of data objects,
each being a pair of a high-dimensional vector and a numeric value, an RFANN
query with a vector and a numeric range as parameters returns the data object
whose numeric value is in the query range and whose vector is nearest to the
query vector. To process this query, a recent study proposes to build $O(n^2)$
dedicated graph-based indexes for all possible query ranges to enable efficient
processing on a database of $n$ objects. As storing all these indexes is
prohibitively expensive, the study constructs compressed indexes instead, which
reduces the memory consumption considerably. However, this incurs suboptimal
performance because the compression is lossy. In this study, instead of
materializing a compressed index for every possible query range in preparation
for querying, we materialize graph-based indexes, called elemental graphs, for
a moderate number of ranges. We then provide an effective and efficient
algorithm that during querying can construct an index for any query range using
the elemental graphs. We prove that the time needed to construct such an index
is low. We also cover an experimental study on real-world datasets that
provides evidence that the materialized elemental graphs only consume moderate
space and that the proposed method is capable of superior and stable query
performance across different query workloads.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper has been accepted by SIGMOD 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Effective Tag Assignment Approach for Billboard Advertisement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02455v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02455v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dildar Ali, Harishchandra Kumar, Suman Banerjee, Yamuna Prasad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Billboard Advertisement has gained popularity due to its significant outrage
in return on investment. To make this advertisement approach more effective,
the relevant information about the product needs to be reached to the relevant
set of people. This can be achieved if the relevant set of tags can be mapped
to the correct slots. Formally, we call this problem the Tag Assignment Problem
in Billboard Advertisement. Given trajectory, billboard database, and a set of
selected billboard slots and tags, this problem asks to output a mapping of
selected tags to the selected slots so that the influence is maximized. We
model this as a variant of traditional bipartite matching called One-To-Many
Bipartite Matching (OMBM). Unlike traditional bipartite matching, a tag can be
assigned to only one slot; in the OMBM, a tag can be assigned to multiple slots
while the vice versa can not happen. We propose an iterative solution approach
that incrementally allocates the tags to the slots. The proposed methodology
has been explained with an illustrated example. A complexity analysis of the
proposed solution approach has also been conducted. The experimental results on
real-world trajectory and billboard datasets prove our claim on the
effectiveness and efficiency of the proposed solution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This Paper has been accepted at The 25th International Web
  Information Systems Engineering Conference (WISE-2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Adaptive Interest Network: Personalized Recommendation with
  Context-Aware Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02425v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02425v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuaishuai Huang, Haowei Yang, You Yao, Xueting Lin, Yuming Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In personalized recommendation systems, accurately capturing users' evolving
interests and combining them with contextual information is a critical research
area. This paper proposes a novel model called the Deep Adaptive Interest
Network (DAIN), which dynamically models users' interests while incorporating
context-aware learning mechanisms to achieve precise and adaptive personalized
recommendations. DAIN leverages deep learning techniques to build an adaptive
interest network structure that can capture users' interest changes in
real-time while further optimizing recommendation results by integrating
contextual information. Experiments conducted on several public datasets
demonstrate that DAIN excels in both recommendation performance and
computational efficiency. This research not only provides a new solution for
personalized recommendation systems but also offers fresh insights into the
application of context-aware learning in recommendation systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do We Trust What They Say or What They Do? A Multimodal User Embedding
  Provides Personalized Explanations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02965v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02965v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhicheng Ren, Zhiping Xiao, Yizhou Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of social media, the importance of analyzing
social network user data has also been put on the agenda. User representation
learning in social media is a critical area of research, based on which we can
conduct personalized content delivery, or detect malicious actors. Being more
complicated than many other types of data, social network user data has
inherent multimodal nature. Various multimodal approaches have been proposed to
harness both text (i.e. post content) and relation (i.e. inter-user
interaction) information to learn user embeddings of higher quality. The advent
of Graph Neural Network models enables more end-to-end integration of user text
embeddings and user interaction graphs in social networks. However, most of
those approaches do not adequately elucidate which aspects of the data - text
or graph structure information - are more helpful for predicting each specific
user under a particular task, putting some burden on personalized downstream
analysis and untrustworthy information filtering. We propose a simple yet
effective framework called Contribution-Aware Multimodal User Embedding (CAMUE)
for social networks. We have demonstrated with empirical evidence, that our
approach can provide personalized explainable predictions, automatically
mitigating the impact of unreliable information. We also conducted case studies
to show how reasonable our results are. We observe that for most users, graph
structure information is more trustworthy than text information, but there are
some reasonable cases where text helps more. Our work paves the way for more
explainable, reliable, and effective social media user embedding which allows
for better personalized content delivery.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02343v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02343v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sepanta Zeighami, Zac Wellmer, Aditya Parameswaran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  $k$-Nearest Neighbor search on dense vector embeddings ($k$-NN retrieval)
from pre-trained embedding models is the predominant retrieval method for text
and images, as well as Retrieval-Augmented Generation (RAG) pipelines. In
practice, application developers often fine-tune the embeddings to improve
their accuracy on the dataset and query workload in hand. Existing approaches
either fine-tune the pre-trained model itself or, more efficiently, but at the
cost of accuracy, train adaptor models to transform the output of the
pre-trained model. We present NUDGE, a family of novel non-parametric embedding
fine-tuning approaches that are significantly more accurate and efficient than
both sets of existing approaches. NUDGE directly modifies the embeddings of
data records to maximize the accuracy of $k$-NN retrieval. We present a
thorough theoretical and experimental study of NUDGE's non-parametric approach.
We show that even though the underlying problem is NP-Hard, constrained
variations can be solved efficiently. These constraints additionally ensure
that the changes to the embeddings are modest, avoiding large distortions to
the semantics learned during pre-training. In experiments across five
pre-trained models and nine standard text and image retrieval datasets, NUDGE
runs in minutes and often improves NDCG@10 by more than 10% over existing
fine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase
in accuracy and runs 200x and 3x faster, respectively, over fine-tuning the
pre-trained model and training adaptors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Design of an LLM-powered Unstructured Analytics System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00847v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00847v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eric Anderson, Jonathan Fritz, Austin Lee, Bohou Li, Mark Lindblad, Henry Lindeman, Alex Meyer, Parth Parmar, Tanvi Ranade, Mehul A. Shah, Benjamin Sowell, Dan Tecuci, Vinayak Thapliyal, Matt Welsh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs demonstrate an uncanny ability to process unstructured data, and as
such, have the potential to go beyond search and run complex, semantic analyses
at scale. We describe the design of an unstructured analytics system, Aryn, and
the tenets and use cases that motivate its design. With Aryn, users can specify
queries in natural language and the system automatically determines a semantic
plan and executes it to compute an answer from a large collection of
unstructured documents using LLMs. At the core of Aryn is Sycamore, a
declarative document processing engine, built using Ray, that provides a
reliable distributed abstraction called DocSets. Sycamore allows users to
analyze, enrich, and transform complex documents at scale. Aryn also comprises
Luna, a query planner that translates natural language queries to Sycamore
scripts, and the Aryn Partitioner, which takes raw PDFs and document images,
and converts them to DocSets for downstream processing. Using Aryn, we
demonstrate a real world use case for analyzing accident reports from the
National Transportation Safety Board (NTSB), and discuss some of the major
challenges we encountered in deploying Aryn in the wild.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 3 figures, fixed typos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Recommender Systems: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.03883v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.03883v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qidong Liu, Jiaxi Hu, Yutian Xiao, Xiangyu Zhao, Jingtong Gao, Wanyu Wang, Qing Li, Jiliang Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recommender system (RS) has been an integral toolkit of online services.
They are equipped with various deep learning techniques to model user
preference based on identifier and attribute information. With the emergence of
multimedia services, such as short videos, news and etc., understanding these
contents while recommending becomes critical. Besides, multimodal features are
also helpful in alleviating the problem of data sparsity in RS. Thus,
Multimodal Recommender System (MRS) has attracted much attention from both
academia and industry recently. In this paper, we will give a comprehensive
survey of the MRS models, mainly from technical views. First, we conclude the
general procedures and major challenges for MRS. Then, we introduce the
existing MRS models according to four categories, i.e., Modality Encoder,
Feature Interaction, Feature Enhancement and Model Optimization. Besides, to
make it convenient for those who want to research this field, we also summarize
the dataset and code resources. Finally, we discuss some promising future
directions of MRS and conclude this paper. To access more details of the
surveyed papers, such as implementation code, we open source a repository.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by CSUR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MARS: Matching Attribute-aware Representations for Text-based Sequential
  Recommendation <span class="chip">CIKM 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00702v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00702v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyunsoo Kim, Junyoung Kim, Minjin Choi, Sunkyung Lee, Jongwuk Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation aims to predict the next item a user is likely to
prefer based on their sequential interaction history. Recently, text-based
sequential recommendation has emerged as a promising paradigm that uses
pre-trained language models to exploit textual item features to enhance
performance and facilitate knowledge transfer to unseen datasets. However,
existing text-based recommender models still struggle with two key challenges:
(i) representing users and items with multiple attributes, and (ii) matching
items with complex user interests. To address these challenges, we propose a
novel model, Matching Attribute-aware Representations for Text-based Sequential
Recommendation (MARS). MARS extracts detailed user and item representations
through attribute-aware text encoding, capturing diverse user intents with
multiple attribute-aware representations. It then computes user-item scores via
attribute-wise interaction matching, effectively capturing attribute-level user
preferences. Our extensive experiments demonstrate that MARS significantly
outperforms existing sequential models, achieving improvements of up to 24.43%
and 29.26% in Recall@10 and NDCG@10 across five benchmark datasets. Code is
available at https://github.com/junieberry/MARS
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>CIKM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HIRO: Hierarchical Information Retrieval Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09979v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09979v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krish Goel, Mahek Chandak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has revolutionized natural language
processing by dynamically integrating external knowledge into Large Language
Models (LLMs), addressing their limitation of static training datasets. Recent
implementations of RAG leverage hierarchical data structures, which organize
documents at various levels of summarization and information density. This
complexity, however, can cause LLMs to "choke" on information overload,
necessitating more sophisticated querying mechanisms. In this context, we
introduce Hierarchical Information Retrieval Optimization (HIRO), a novel
querying approach that employs a Depth-First Search (DFS)-based recursive
similarity score calculation and branch pruning. This method uniquely minimizes
the context delivered to the LLM without informational loss, effectively
managing the challenge of excessive data. HIRO's refined approach is validated
by a 10.85% improvement in performance on the NarrativeQA dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models for Information Retrieval: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.07107v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.07107v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a primary means of information acquisition, information retrieval (IR)
systems, such as search engines, have integrated themselves into our daily
lives. These systems also serve as components of dialogue, question-answering,
and recommender systems. The trajectory of IR has evolved dynamically from its
origins in term-based methods to its integration with advanced neural models.
While the neural models excel at capturing complex contextual signals and
semantic nuances, thereby reshaping the IR landscape, they still face
challenges such as data scarcity, interpretability, and the generation of
contextually plausible yet potentially inaccurate responses. This evolution
requires a combination of both traditional methods (such as term-based sparse
retrieval methods with rapid response) and modern neural architectures (such as
language models with powerful language understanding capacity). Meanwhile, the
emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has
revolutionized natural language processing due to their remarkable language
understanding, generation, generalization, and reasoning abilities.
Consequently, recent research has sought to leverage LLMs to improve IR
systems. Given the rapid evolution of this research trajectory, it is necessary
to consolidate existing methodologies and provide nuanced insights through a
comprehensive overview. In this survey, we delve into the confluence of LLMs
and IR systems, including crucial aspects such as query rewriters, retrievers,
rerankers, and readers. Additionally, we explore promising directions, such as
search agents, within this expanding field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>updated to version 3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Smart E-commerce Recommendations with Semantic AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01137v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01137v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        M. Badouch, M. Boutaounte
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In e-commerce, web mining for page recommendations is widely used but often
fails to meet user needs. To address this, we propose a novel solution
combining semantic web mining with BP neural networks. We process user search
logs to extract five key features: content priority, time spent, user feedback,
recommendation semantics, and input deviation. These features are then fed into
a BP neural network to classify and prioritize web pages. The prioritized pages
are recommended to users. Using book sales pages for testing, our results
demonstrate that this solution can quickly and accurately identify the pages
users need. Our approach ensures that recommendations are more relevant and
tailored to individual preferences, enhancing the online shopping experience.
By leveraging advanced semantic analysis and neural network techniques, we
bridge the gap between user expectations and actual recommendations. This
innovative method not only improves accuracy but also speeds up the
recommendation process, making it a valuable tool for e-commerce platforms
aiming to boost user satisfaction and engagement. Additionally, our system
ability to handle large datasets and provide real-time recommendations makes it
a scalable and efficient solution for modern e-commerce challenges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NFARec: A Negative Feedback-Aware Recommender Model <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06900v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06900v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinfeng Wang, Fumiyo Fukumoto, Jin Cui, Yoshimi Suzuki, Dongjin Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph neural network (GNN)-based models have been extensively studied for
recommendations, as they can extract high-order collaborative signals
accurately which is required for high-quality recommender systems. However,
they neglect the valuable information gained through negative feedback in two
aspects: (1) different users might hold opposite feedback on the same item,
which hampers optimal information propagation in GNNs, and (2) even when an
item vastly deviates from users' preferences, they might still choose it and
provide a negative rating. In this paper, we propose a negative feedback-aware
recommender model (NFARec) that maximizes the leverage of negative feedback. To
transfer information to multi-hop neighbors along an optimal path effectively,
NFARec adopts a feedback-aware correlation that guides hypergraph convolutions
(HGCs) to learn users' structural representations. Moreover, NFARec
incorporates an auxiliary task - predicting the feedback sentiment polarity
(i.e., positive or negative) of the next interaction - based on the Transformer
Hawkes Process. The task is beneficial for understanding users by learning the
sentiment expressed in their previous sequential feedback patterns and
predicting future interactions. Extensive experiments demonstrate that NFARec
outperforms competitive baselines. Our source code and data are released at
https://github.com/WangXFng/NFARec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SIGIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CaDRec: Contextualized and Debiased Recommender Model <span class="chip">SIGIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06895v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06895v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinfeng Wang, Fumiyo Fukumoto, Jin Cui, Yoshimi Suzuki, Jiyi Li, Dongjin Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender models aimed at mining users' behavioral patterns have raised
great attention as one of the essential applications in daily life. Recent work
on graph neural networks (GNNs) or debiasing methods has attained remarkable
gains. However, they still suffer from (1) over-smoothing node embeddings
caused by recursive convolutions with GNNs, and (2) the skewed distribution of
interactions due to popularity and user-individual biases. This paper proposes
a contextualized and debiased recommender model (CaDRec). To overcome the
over-smoothing issue, we explore a novel hypergraph convolution operator that
can select effective neighbors during convolution by introducing both
structural context and sequential context. To tackle the skewed distribution,
we propose two strategies for disentangling interactions: (1) modeling
individual biases to learn unbiased item embeddings, and (2) incorporating item
popularity with positional encoding. Moreover, we mathematically show that the
imbalance of the gradients to update item embeddings exacerbates the popularity
bias, thus adopting regularization and weighting schemes as solutions.
Extensive experiments on four datasets demonstrate the superiority of the
CaDRec against state-of-the-art (SOTA) methods. Our source code and data are
released at https://github.com/WangXFng/CaDRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SIGIR 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Named Entity Recognition Using Few-Shot <span class="highlight-title">Prompt</span>ing with Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15796v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15796v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hédi Zeghidi, Ludovic Moncla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper evaluates Few-Shot Prompting with Large Language Models for Named
Entity Recognition (NER). Traditional NER systems rely on extensive labeled
datasets, which are costly and time-consuming to obtain. Few-Shot Prompting or
in-context learning enables models to recognize entities with minimal examples.
We assess state-of-the-art models like GPT-4 in NER tasks, comparing their
few-shot performance to fully supervised benchmarks. Results show that while
there is a performance gap, large models excel in adapting to new entity types
and domains with very limited data. We also explore the effects of prompt
engineering, guided output format and context length on performance. This study
underscores Few-Shot Learning's potential to reduce the need for large labeled
datasets, enhancing NER scalability and accessibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Github repo: https://github.com/GEODE-project/ner-llm</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Jina-Col<span class="highlight-title">BERT</span>-v2: A General-Purpose Multilingual Late Interaction
  Retriever <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16672v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16672v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohan Jha, Bo Wang, Michael Günther, Georgios Mastrapas, Saba Sturua, Isabelle Mohr, Andreas Koukounas, Mohammad Kalim Akram, Nan Wang, Han Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-vector dense models, such as ColBERT, have proven highly effective in
information retrieval. ColBERT's late interaction scoring approximates the
joint query-document attention seen in cross-encoders while maintaining
inference efficiency closer to traditional dense retrieval models, thanks to
its bi-encoder architecture and recent optimizations in indexing and search. In
this paper, we introduce a novel architecture and a training framework to
support long context window and multilingual retrieval. Our new model,
Jina-ColBERT-v2, demonstrates strong performance across a range of English and
multilingual retrieval tasks,
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, references at pp7,8; EMNLP workshop submission</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via
  Hybrid Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02889v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02889v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xidong Wang, Dingjie Song, Shunian Chen, Chen Zhang, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expanding the long-context capabilities of Multi-modal Large Language
Models~(MLLMs) is crucial for video understanding, high-resolution image
understanding, and multi-modal agents. This involves a series of systematic
optimizations, including model architecture, data construction and training
strategy, particularly addressing challenges such as \textit{degraded
performance with more images} and \textit{high computational costs}. In this
paper, we adapt the model architecture to a hybrid of Mamba and Transformer
blocks, approach data construction with both temporal and spatial dependencies
among multiple images and employ a progressive training strategy. The released
model \textbf{LongLLaVA}~(\textbf{Long}-Context \textbf{L}arge
\textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant) is the first
hybrid MLLM, which achieved a better balance between efficiency and
effectiveness. LongLLaVA not only achieves competitive results across various
benchmarks, but also maintains high throughput and low memory consumption.
Especially, it could process nearly a thousand images on a single A100 80GB
GPU, showing promising application prospects for a wide range of tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 7 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Track MusicLDM: Towards Versatile Music Generation with Latent
  Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02845v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02845v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tornike Karchkhadze, Mohammad Rasool Izadi, Ke Chen, Gerard Assayag, Shlomo Dubnov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have shown promising results in cross-modal generation tasks
involving audio and music, such as text-to-sound and text-to-music generation.
These text-controlled music generation models typically focus on generating
music by capturing global musical attributes like genre and mood. However,
music composition is a complex, multilayered task that often involves musical
arrangement as an integral part of the process. This process involves composing
each instrument to align with existing ones in terms of beat, dynamics,
harmony, and melody, requiring greater precision and control over tracks than
text prompts usually provide. In this work, we address these challenges by
extending the MusicLDM, a latent diffusion model for music, into a multi-track
generative model. By learning the joint probability of tracks sharing a
context, our model is capable of generating music across several tracks that
correspond well to each other, either conditionally or unconditionally.
Additionally, our model is capable of arrangement generation, where the model
can generate any subset of tracks given the others (e.g., generating a piano
track complementing given bass and drum tracks). We compared our model with an
existing multi-track generative model and demonstrated that our model achieves
considerable improvements across objective metrics for both total and
arrangement generation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ExpLLM: Towards Chain of Thought for Facial Expression Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02828v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02828v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xing Lan, Jian Xue, Ji Qi, Dongmei Jiang, Ke Lu, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Facial expression recognition (FER) is a critical task in multimedia with
significant implications across various domains. However, analyzing the causes
of facial expressions is essential for accurately recognizing them. Current
approaches, such as those based on facial action units (AUs), typically provide
AU names and intensities but lack insight into the interactions and
relationships between AUs and the overall expression. In this paper, we propose
a novel method called ExpLLM, which leverages large language models to generate
an accurate chain of thought (CoT) for facial expression recognition.
Specifically, we have designed the CoT mechanism from three key perspectives:
key observations, overall emotional interpretation, and conclusion. The key
observations describe the AU's name, intensity, and associated emotions. The
overall emotional interpretation provides an analysis based on multiple AUs and
their interactions, identifying the dominant emotions and their relationships.
Finally, the conclusion presents the final expression label derived from the
preceding analysis. Furthermore, we also introduce the Exp-CoT Engine, designed
to construct this expression CoT and generate instruction-description data for
training our ExpLLM. Extensive experiments on the RAF-DB and AffectNet datasets
demonstrate that ExpLLM outperforms current state-of-the-art FER methods.
ExpLLM also surpasses the latest GPT-4o in expression CoT generation,
particularly in recognizing micro-expressions where GPT-4o frequently fails.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>project page: https://starhiking.github.io/ExpLLM_Page/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for
  One-Shot Talking Head Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Ling, Yiwen Wang, Han Xue, Rong Xie, Li Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While previous audio-driven talking head generation (THG) methods generate
head poses from driving audio, the generated poses or lips cannot match the
audio well or are not editable. In this study, we propose \textbf{PoseTalk}, a
THG system that can freely generate lip-synchronized talking head videos with
free head poses conditioned on text prompts and audio. The core insight of our
method is using head pose to connect visual, linguistic, and audio signals.
First, we propose to generate poses from both audio and text prompts, where the
audio offers short-term variations and rhythm correspondence of the head
movements and the text prompts describe the long-term semantics of head
motions. To achieve this goal, we devise a Pose Latent Diffusion (PLD) model to
generate motion latent from text prompts and audio cues in a pose latent space.
Second, we observe a loss-imbalance problem: the loss for the lip region
contributes less than 4\% of the total reconstruction loss caused by both pose
and lip, making optimization lean towards head movements rather than lip
shapes. To address this issue, we propose a refinement-based learning strategy
to synthesize natural talking videos using two cascaded networks, i.e.,
CoarseNet, and RefineNet. The CoarseNet estimates coarse motions to produce
animated images in novel poses and the RefineNet focuses on learning finer lip
motions by progressively estimating lip motions from low-to-high resolutions,
yielding improved lip-synchronization performance. Experiments demonstrate our
pose prediction strategy achieves better pose diversity and realness compared
to text-only or audio-only, and our video generator model outperforms
state-of-the-art methods in synthesizing talking videos with natural head
motions. Project: https://junleen.github.io/projects/posetalk.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7+5 pages, 15 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-Resolution Object Recognition with Cross-Resolution Relational
  Contrastive Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangkai Zhang, Shiming Ge, Ruixin Shi, Dan Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recognizing objects in low-resolution images is a challenging task due to the
lack of informative details. Recent studies have shown that knowledge
distillation approaches can effectively transfer knowledge from a
high-resolution teacher model to a low-resolution student model by aligning
cross-resolution representations. However, these approaches still face
limitations in adapting to the situation where the recognized objects exhibit
significant representation discrepancies between training and testing images.
In this study, we propose a cross-resolution relational contrastive
distillation approach to facilitate low-resolution object recognition. Our
approach enables the student model to mimic the behavior of a well-trained
teacher model which delivers high accuracy in identifying high-resolution
objects. To extract sufficient knowledge, the student learning is supervised
with contrastive relational distillation loss, which preserves the similarities
in various relational structures in contrastive representation space. In this
manner, the capability of recovering missing details of familiar low-resolution
objects can be effectively enhanced, leading to a better knowledge transfer.
Extensive experiments on low-resolution object classification and
low-resolution face recognition clearly demonstrate the effectiveness and
adaptability of our approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted by IEEE Transactions on Circuits and Systems
  for Video Technology (TCSVT)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coral Model Generation from Single Images for Virtual Reality
  Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02376v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02376v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Fu, Shun Fu, Mick Grierson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of VR technology, the demand for high-quality 3D
models is increasing. Traditional methods struggle with efficiency and quality
in large-scale customization. This paper introduces a deep-learning framework
that generates high-precision 3D coral models from a single image. Using the
Coral dataset, the framework extracts geometric and texture features, performs
3D reconstruction, and optimizes design and material blending. Advanced
optimization and polygon count control ensure shape accuracy, detail retention,
and flexible output for various complexities, catering to high-quality
rendering and real-time interaction needs.The project incorporates Explainable
AI (XAI) to transform AI-generated models into interactive "artworks," best
viewed in VR and XR. This enhances model interpretability and human-machine
collaboration. Real-time feedback in VR interactions displays information like
coral species and habitat, enriching user experience. The generated models
surpass traditional methods in detail, visual quality, and efficiency. This
research offers an intelligent approach to 3D content creation for VR, lowering
production barriers, and promoting widespread VR applications. Additionally,
integrating XAI provides new insights into AI-generated visual content and
advances research in 3D vision interpretability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts
  2024) arXiv:2406.14485</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hand1000: Generating Realistic Hands from Text with Only 1,000 Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15461v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15461v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhuo Zhang, Bin Zhu, Yu Cao, Yanbin Hao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image generation models have achieved remarkable advancements in
recent years, aiming to produce realistic images from textual descriptions.
However, these models often struggle with generating anatomically accurate
representations of human hands. The resulting images frequently exhibit issues
such as incorrect numbers of fingers, unnatural twisting or interlacing of
fingers, or blurred and indistinct hands. These issues stem from the inherent
complexity of hand structures and the difficulty in aligning textual
descriptions with precise visual depictions of hands. To address these
challenges, we propose a novel approach named Hand1000 that enables the
generation of realistic hand images with target gesture using only 1,000
training samples. The training of Hand1000 is divided into three stages with
the first stage aiming to enhance the model's understanding of hand anatomy by
using a pre-trained hand gesture recognition model to extract gesture
representation. The second stage further optimizes text embedding by
incorporating the extracted hand gesture representation, to improve alignment
between the textual descriptions and the generated hand images. The third stage
utilizes the optimized embedding to fine-tune the Stable Diffusion model to
generate realistic hand images. In addition, we construct the first publicly
available dataset specifically designed for text-to-hand image generation.
Based on the existing hand gesture recognition dataset, we adopt advanced image
captioning models and LLaMA3 to generate high-quality textual descriptions
enriched with detailed gesture information. Extensive experiments demonstrate
that Hand1000 significantly outperforms existing models in producing
anatomically correct hand images while faithfully representing other details in
the text, such as faces, clothing, and colors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page https://haozhuo-zhang.github.io/Hand1000-project-page/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MCDubber: Multimodal Context-Aware Expressive Video Dubbing <span class="chip">SC2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11593v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11593v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuan Zhao, Zhenqi Jia, Rui Liu, De Hu, Feilong Bao, Guanglai Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic Video Dubbing (AVD) aims to take the given script and generate
speech that aligns with lip motion and prosody expressiveness. Current AVD
models mainly utilize visual information of the current sentence to enhance the
prosody of synthesized speech. However, it is crucial to consider whether the
prosody of the generated dubbing aligns with the multimodal context, as the
dubbing will be combined with the original context in the final video. This
aspect has been overlooked in previous studies. To address this issue, we
propose a Multimodal Context-aware video Dubbing model, termed
\textbf{MCDubber}, to convert the modeling object from a single sentence to a
longer sequence with context information to ensure the consistency of the
global context prosody. MCDubber comprises three main components: (1) A context
duration aligner aims to learn the context-aware alignment between the text and
lip frames; (2) A context prosody predictor seeks to read the global context
visual sequence and predict the context-aware global energy and pitch; (3) A
context acoustic decoder ultimately predicts the global context mel-spectrogram
with the assistance of adjacent ground-truth mel-spectrograms of the target
sentence. Through this process, MCDubber fully considers the influence of
multimodal context on the prosody expressiveness of the current sentence when
dubbing. The extracted mel-spectrogram belonging to the target sentence from
the output context mel-spectrograms is the final required dubbing audio.
Extensive experiments on the Chem benchmark dataset demonstrate that our
MCDubber significantly improves dubbing expressiveness compared to all advanced
baselines. The code and demos are available at
https://github.com/XiaoYuanJun-zy/MCDubber.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NCMMSC2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-09-03T00:00:00Z">2024-09-03</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SpannerLib: Embedding Declarative Information Extraction in an
  Imperative Workflow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dean Light, Ahmad Aiashy, Mahmoud Diab, Daniel Nachmias, Stijn Vansummeren, Benny Kimelfeld
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document spanners have been proposed as a formal framework for declarative
Information Extraction (IE) from text, following IE products from the industry
and academia. Over the past decade, the framework has been studied thoroughly
in terms of expressive power, complexity, and the ability to naturally combine
text analysis with relational querying. This demonstration presents SpannerLib
a library for embedding document spanners in Python code. SpannerLib
facilitates the development of IE programs by providing an implementation of
Spannerlog (Datalog-based documentspanners) that interacts with the Python code
in two directions: rules can be embedded inside Python, and they can invoke
custom Python code (e.g., calls to ML-based NLP models) via user-defined
functions. The demonstration scenarios showcase IE programs, with increasing
levels of complexity, within Jupyter Notebook.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Laser: Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation
  with Collaborative Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01605v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01605v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Zhang, Linmei Hu, Luhao Zhang, Dandan Song, Heyan Huang, Liqiang Nie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommender systems are essential for discerning user preferences
from historical interactions and facilitating targeted recommendations. Recent
innovations employing Large Language Models (LLMs) have advanced the field by
encoding item semantics, yet they often necessitate substantial parameter
tuning and are resource-demanding. Moreover, these works fails to consider the
diverse characteristics of different types of users and thus diminishes the
recommendation accuracy. In this paper, we propose a parameter-efficient Large
Language Model Bi-Tuning framework for sequential recommendation with
collaborative information (Laser). Specifically, Bi-Tuning works by inserting
trainable virtual tokens at both the prefix and suffix of the input sequence
and freezing the LLM parameters, thus optimizing the LLM for the sequential
recommendation. In our Laser, the prefix is utilized to incorporate user-item
collaborative information and adapt the LLM to the recommendation task, while
the suffix converts the output embeddings of the LLM from the language space to
the recommendation space for the follow-up item recommendation. Furthermore, to
capture the characteristics of different types of users when integrating the
collaborative information via the prefix, we introduce M-Former, a lightweight
MoE-based querying transformer that uses a set of query experts to integrate
diverse user-specific collaborative information encoded by frozen ID-based
sequential recommender systems, significantly improving the accuracy of
recommendations. Extensive experiments on real-world datasets demonstrate that
Laser can parameter-efficiently adapt LLMs to effective recommender systems,
significantly outperforming state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Blockchain-based Federated Recommendation with Incentive Mechanism 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01563v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01563v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianhai Chen, Yanlin Wu, Dazhong Rong, Guoyao Yu, Lingqi Jiang, Zhenguang Liu, Peng Zhou, Rui Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nowadays, federated recommendation technology is rapidly evolving to help
multiple organisations share data and train models while meeting user privacy,
data security and government regulatory requirements. However, federated
recommendation increases customer system costs such as power, computational and
communication resources. Besides, federated recommendation systems are also
susceptible to model attacks and data poisoning by participating malicious
clients. Therefore, most customers are unwilling to participate in federated
recommendation without any incentive. To address these problems, we propose a
blockchain-based federated recommendation system with incentive mechanism to
promote more trustworthy, secure, and efficient federated recommendation
service. First, we construct a federated recommendation system based on NeuMF
and FedAvg. Then we introduce a reverse auction mechanism to select optimal
clients that can maximize the social surplus. Finally, we employ blockchain for
on-chain evidence storage of models to ensure the safety of the federated
recommendation system. The experimental results show that our proposed
incentive mechanism can attract clients with superior training data to engage
in the federal recommendation at a lower cost, which can increase the economic
benefit of federal recommendation by 54.9\% while improve the recommendation
performance. Thus our work provides theoretical and technological support for
the construction of a harmonious and healthy ecological environment for the
application of federal recommendation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted on 2024 Blockchain and Web3 Technology
  Innovation and Application Exchange Conference (BWTAC 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ rerankers: A Lightweight Python Library to Unify Ranking Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.17344v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.17344v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Clavié
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents rerankers, a Python library which provides an easy-to-use
interface to the most commonly used re-ranking approaches. Re-ranking is an
integral component of many retrieval pipelines; however, there exist numerous
approaches to it, relying on different implementation methods. rerankers
unifies these methods into a single user-friendly interface, allowing
practitioners and researchers alike to explore different methods while only
changing a single line of Python code. Moreover ,rerankers ensures that its
implementations are done with the fewest dependencies possible, and re-uses the
original implementation whenever possible, guaranteeing that our simplified
interface results in no performance degradation compared to more complex ones.
The full source code and list of supported models are updated regularly and
available at https://github.com/answerdotai/rerankers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Impedance vs. Power Side-channel Vulnerabilities: A Comparative Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06242v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06242v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Sadik Awal, Buddhipriya Gayanath, Md Tauhidur Rahman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent times, impedance side-channel analysis has emerged as a potent
strategy for adversaries seeking to extract sensitive information from
computing systems. It leverages variations in the intrinsic impedance of a
chip's internal structure across different logic states. In this study, we
conduct a comparative analysis between the newly explored impedance side
channel and the well-established power side channel. Through experimental
evaluation, we investigate the efficacy of these two side channels in
extracting the cryptographic key from the Advanced Encryption Standard (AES)
and analyze their performance. Our results indicate that impedance analysis
demonstrates a higher potential for cryptographic key extraction compared to
power side-channel analysis. Moreover, we identify scenarios where power
side-channel analysis does not yield satisfactory results, whereas impedance
analysis proves to be more robust and effective. This work not only underscores
the significance of impedance side-channel analysis in enhancing cryptographic
security but also emphasizes the necessity for a deeper understanding of its
mechanisms and implications.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">9</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LSTMSE-Net: Long Short Term Speech Enhancement Network for Audio-visual
  Speech Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02266v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02266v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arnav Jain, Jasmer Singh Sanjotra, Harshvardhan Choudhary, Krish Agrawal, Rupal Shah, Rohan Jha, M. Sajid, Amir Hussain, M. Tanveer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose long short term memory speech enhancement network
(LSTMSE-Net), an audio-visual speech enhancement (AVSE) method. This innovative
method leverages the complementary nature of visual and audio information to
boost the quality of speech signals. Visual features are extracted with
VisualFeatNet (VFN), and audio features are processed through an encoder and
decoder. The system scales and concatenates visual and audio features, then
processes them through a separator network for optimized speech enhancement.
The architecture highlights advancements in leveraging multi-modal data and
interpolation techniques for robust AVSE challenge systems. The performance of
LSTMSE-Net surpasses that of the baseline model from the COG-MHEAR AVSE
Challenge 2024 by a margin of 0.06 in scale-invariant signal-to-distortion
ratio (SISDR), $0.03$ in short-time objective intelligibility (STOI), and
$1.32$ in perceptual evaluation of speech quality (PESQ). The source code of
the proposed LSTMSE-Net is available at
\url{https://github.com/mtanveer1/AVSEC-3-Challenge}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Deep Shadows: A <span class="highlight-title">Survey</span> on Image and Video Shadow Detection,
  Removal, and Generation in the Era of Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02108v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02108v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaowei Hu, Zhenghao Xing, Tianyu Wang, Chi-Wing Fu, Pheng-Ann Heng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Shadows are formed when light encounters obstacles, leading to areas of
diminished illumination. In computer vision, shadow detection, removal, and
generation are crucial for enhancing scene understanding, refining image
quality, ensuring visual consistency in video editing, and improving virtual
environments. This paper presents a comprehensive survey of shadow detection,
removal, and generation in images and videos within the deep learning landscape
over the past decade, covering tasks, deep models, datasets, and evaluation
metrics. Our key contributions include a comprehensive survey of shadow
analysis, standardization of experimental comparisons, exploration of the
relationships among model size, speed, and performance, a cross-dataset
generalization study, identification of open issues and future directions, and
provision of publicly available resources to support further research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Publicly available results, trained models, and evaluation metrics at
  https://github.com/xw-hu/Unveiling-Deep-Shadows</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Real-World Adverse Weather Image Restoration: Enhancing
  Clearness and Semantics with Vision-Language Models <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02101v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02101v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqi Xu, Mengyang Wu, Xiaowei Hu, Chi-Wing Fu, Qi Dou, Pheng-Ann Heng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper addresses the limitations of adverse weather image restoration
approaches trained on synthetic data when applied to real-world scenarios. We
formulate a semi-supervised learning framework employing vision-language models
to enhance restoration performance across diverse adverse weather conditions in
real-world settings. Our approach involves assessing image clearness and
providing semantics using vision-language models on real data, serving as
supervision signals for training restoration models. For clearness enhancement,
we use real-world data, utilizing a dual-step strategy with pseudo-labels
assessed by vision-language models and weather prompt learning. For semantic
enhancement, we integrate real-world data by adjusting weather conditions in
vision-language model descriptions while preserving semantic meaning.
Additionally, we introduce an effective training strategy to bootstrap
restoration performance. Our approach achieves superior results in real-world
adverse weather image restoration, demonstrated through qualitative and
quantitative comparisons with state-of-the-art works.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Low-Resolution Face Recognition via Adaptable Instance-Relation
  Distillation <span class="chip">IJCNN 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02049v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02049v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruixin Shi, Weijia Guo, Shiming Ge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-resolution face recognition is a challenging task due to the missing of
informative details. Recent approaches based on knowledge distillation have
proven that high-resolution clues can well guide low-resolution face
recognition via proper knowledge transfer. However, due to the distribution
difference between training and testing faces, the learned models often suffer
from poor adaptability. To address that, we split the knowledge transfer
process into distillation and adaptation steps, and propose an adaptable
instance-relation distillation approach to facilitate low-resolution face
recognition. In the approach, the student distills knowledge from
high-resolution teacher in both instance level and relation level, providing
sufficient cross-resolution knowledge transfer. Then, the learned student can
be adaptable to recognize low-resolution faces with adaptive batch
normalization in inference. In this manner, the capability of recovering
missing details of familiar low-resolution faces can be effectively enhanced,
leading to a better knowledge transfer. Extensive experiments on low-resolution
face recognition clearly demonstrate the effectiveness and adaptability of our
approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IJCNN 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PRoGS: Progressive Rendering of Gaussian Splats 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01761v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01761v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brent Zoomers, Maarten Wijnants, Ivan Molenaers, Joni Vanherck, Jeroen Put, Lode Jorissen, Nick Michiels
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past year, 3D Gaussian Splatting (3DGS) has received significant
attention for its ability to represent 3D scenes in a perceptually accurate
manner. However, it can require a substantial amount of storage since each
splat's individual data must be stored. While compression techniques offer a
potential solution by reducing the memory footprint, they still necessitate
retrieving the entire scene before any part of it can be rendered. In this
work, we introduce a novel approach for progressively rendering such scenes,
aiming to display visible content that closely approximates the final scene as
early as possible without loading the entire scene into memory. This approach
benefits both on-device rendering applications limited by memory constraints
and streaming applications where minimal bandwidth usage is preferred. To
achieve this, we approximate the contribution of each Gaussian to the final
scene and construct an order of prioritization on their inclusion in the
rendering process. Additionally, we demonstrate that our approach can be
combined with existing compression methods to progressively render (and stream)
3DGS scenes, optimizing bandwidth usage by focusing on the most important
splats within a scene. Overall, our work establishes a foundation for making
remotely hosted 3DGS content more quickly accessible to end-users in
over-the-top consumption scenarios, with our results showing significant
improvements in quality across all metrics compared to existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Privacy-Preserving Multimedia Mobile Cloud Computing Using Protective
  Perturbation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01710v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01710v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhongze Tang, Mengmei Ye, Yao Liu, Sheng Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mobile cloud computing has been adopted in many multimedia applications,
where the resource-constrained mobile device sends multimedia data (e.g.,
images) to remote cloud servers to request computation-intensive multimedia
services (e.g., image recognition). While significantly improving the
performance of the mobile applications, the cloud-based mechanism often causes
privacy concerns as the multimedia data and services are offloaded from the
trusted user device to untrusted cloud servers. Several recent studies have
proposed perturbation-based privacy preserving mechanisms, which obfuscate the
offloaded multimedia data to eliminate privacy exposures without affecting the
functionality of the remote multimedia services. However, the existing privacy
protection approaches require the deployment of computation-intensive
perturbation generation on the resource-constrained mobile devices. Also, the
obfuscated images are typically not compliant with the standard image
compression algorithms and suffer from significant bandwidth consumption. In
this paper, we develop a novel privacy-preserving multimedia mobile cloud
computing framework, namely $PMC^2$, to address the resource and bandwidth
challenges. $PMC^2$ employs secure confidential computing in the cloud to
deploy the perturbation generator, which addresses the resource challenge while
maintaining the privacy. Furthermore, we develop a neural compressor
specifically trained to compress the perturbed images in order to address the
bandwidth challenge. We implement $PMC^2$ in an end-to-end mobile cloud
computing system, based on which our evaluations demonstrate superior latency,
power efficiency, and bandwidth consumption achieved by $PMC^2$ while
maintaining high accuracy in the target multimedia service.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Think Twice Before Recognizing: Large Multimodal Models for General
  Fine-grained Traffic Sign Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaozong Gan, Guang Li, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose a new strategy called think twice before recognizing to improve
fine-grained traffic sign recognition (TSR). Fine-grained TSR in the wild is
difficult due to the complex road conditions, and existing approaches
particularly struggle with cross-country TSR when data is lacking. Our strategy
achieves effective fine-grained TSR by stimulating the multiple-thinking
capability of large multimodal models (LMM). We introduce context,
characteristic, and differential descriptions to design multiple thinking
processes for the LMM. The context descriptions with center coordinate prompt
optimization help the LMM to locate the target traffic sign in the original
road images containing multiple traffic signs and filter irrelevant answers
through the proposed prior traffic sign hypothesis. The characteristic
description is based on few-shot in-context learning of template traffic signs,
which decreases the cross-domain difference and enhances the fine-grained
recognition capability of the LMM. The differential descriptions of similar
traffic signs optimize the multimodal thinking capability of the LMM. The
proposed method is independent of training data and requires only simple and
uniform instructions. We conducted extensive experiments on three benchmark
datasets and two real-world datasets from different countries, and the proposed
method achieves state-of-the-art TSR results on all five datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IDNet: A Novel <span class="highlight-title">Dataset</span> for Identity Document Analysis and Fraud
  Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01690v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01690v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Guan, Yancheng Wang, Lulu Xie, Soham Nag, Rajeev Goel, Niranjan Erappa Narayana Swamy, Yingzhen Yang, Chaowei Xiao, Jonathan Prisby, Ross Maciejewski, Jia Zou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective fraud detection and analysis of government-issued identity
documents, such as passports, driver's licenses, and identity cards, are
essential in thwarting identity theft and bolstering security on online
platforms. The training of accurate fraud detection and analysis tools depends
on the availability of extensive identity document datasets. However, current
publicly available benchmark datasets for identity document analysis, including
MIDV-500, MIDV-2020, and FMIDV, fall short in several respects: they offer a
limited number of samples, cover insufficient varieties of fraud patterns, and
seldom include alterations in critical personal identifying fields like
portrait images, limiting their utility in training models capable of detecting
realistic frauds while preserving privacy.
  In response to these shortcomings, our research introduces a new benchmark
dataset, IDNet, designed to advance privacy-preserving fraud detection efforts.
The IDNet dataset comprises 837,060 images of synthetically generated identity
documents, totaling approximately 490 gigabytes, categorized into 20 types from
$10$ U.S. states and 10 European countries. We evaluate the utility and present
use cases of the dataset, illustrating how it can aid in training
privacy-preserving fraud detection methods, facilitating the generation of
camera and video capturing of identity documents, and testing schema
unification and other identity document management functionalities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>40 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TALDS-Net: Task-Aware Adaptive Local Descriptors Selection for Few-shot
  Image Classification <span class="chip">ICASSP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.05449v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.05449v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qian Qiao, Yu Xie, Ziyin Zeng, Fanzhang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Few-shot image classification aims to classify images from unseen novel
classes with few samples. Recent works demonstrate that deep local descriptors
exhibit enhanced representational capabilities compared to image-level
features. However, most existing methods solely rely on either employing all
local descriptors or directly utilizing partial descriptors, potentially
resulting in the loss of crucial information. Moreover, these methods primarily
emphasize the selection of query descriptors while overlooking support
descriptors. In this paper, we propose a novel Task-Aware Adaptive Local
Descriptors Selection Network (TALDS-Net), which exhibits the capacity for
adaptive selection of task-aware support descriptors and query descriptors.
Specifically, we compare the similarity of each local support descriptor with
other local support descriptors to obtain the optimal support descriptor subset
and then compare the query descriptors with the optimal support subset to
obtain discriminative query descriptors. Extensive experiments demonstrate that
our TALDS-Net outperforms state-of-the-art methods on both general and
fine-grained datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 1 figures, is accepted by ICASSP 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2024-09-11T05:27:13.484399986Z">
            2024-09-11 05:27:13 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
